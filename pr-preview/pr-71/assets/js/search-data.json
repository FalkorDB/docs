{"0": {
    "doc": "Building Docker",
    "title": "Building a Docker container",
    "content": "The Dockerfile examples in this directory are generated by the FalkorDB build system. The build uses a python script, to generate a dockerfile, on a per-platform basis, and build a docker container from that. The dockerfile, calls various scripts from the readies in order to further abstract everything away. ",
    "url": "/docker-examples/README.html#building-a-docker-container",
    
    "relUrl": "/docker-examples/README.html#building-a-docker-container"
  },"1": {
    "doc": "Building Docker",
    "title": "Requirements",
    "content": "In order to generate the dockerfile, or run the build system you need the following installed: . | python &gt; 3.6 | jinja (pip install jinja2) | docker | . ",
    "url": "/docker-examples/README.html#requirements",
    
    "relUrl": "/docker-examples/README.html#requirements"
  },"2": {
    "doc": "Building Docker",
    "title": "Manual Installation",
    "content": "As the docker build calls various scripts from within readies, the following are the series of commands triggered on a per-platform order. Note: these commands are literally what is run, meaning there is duplication. The command list is generated by running ./sbin/system-setup.py -n in the corresponding docker for each platform. In the case of any script run from the readies repository, the associated script is similarly run with the -n option, producing the list below. If manually installing packages, please ensure all commands are run via sudo, or through similar privilege escalation, ensuring that package installation will succeed. Centos 7 . In addition to the above-mentioned requirements, it is assumed that epel repositories have been enabled. yum install -q -y ca-certificates yum install -q -y curl wget unzip /usr/bin/python3 -m pip install --disable-pip-version-check wheel virtualenv /usr/bin/python3 -m pip install --disable-pip-version-check setuptools --upgrade /build/deps/readies/bin/enable-utf8 yum install -q -y git automake libtool autoconf yum install -q -y redhat-lsb-core yum groupinstall -y 'Development Tools' yum install -q -y centos-release-scl yum install -q -y devtoolset-10 yum install -q -y devtoolset-10-libatomic-devel rm -f /etc/profile.d/scl-devtoolset-*.sh yum install -q -y m4 libgomp cd /tmp; build_dir=$(mktemp -d); cd $build_dir; wget -q -O peg.tar.gz https://github.com/gpakosz/peg/archive/0.1.18.tar.gz; tar xzf peg.tar.gz; cd peg-0.1.18; make; make install MANDIR=.; cd /tmp; rm -rf $build_dir yum install -q -y valgrind yum install -q -y astyle yum install -q -y ca-certificates yum install -q -y curl wget unzip wget -q -O /tmp/cmake.sh https://github.com/Kitware/CMake/releases/download/v3.21.1/cmake-3.21.1-`uname`-`uname -m`.sh; sh /tmp/cmake.sh --skip-license --prefix=/usr/local; rm -f /tmp/cmake.sh /usr/bin/python3 -m pip install --disable-pip-version-check psutil /build/deps/readies/bin/getgcc yum install -q -y python3-devel /usr/bin/python3 -m pip install --disable-pip-version-check psutil yum install -q -y git /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/redisfab/redis-py.git@3.5 /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed redis-py-cluster /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/RedisLabsModules/RLTest.git@master /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/RedisLabs/RAMP@master /usr/bin/python3 -m pip install --disable-pip-version-check -r tests/requirements.txt . Ubuntu Bionic (18.04) . apt-get -qq update -y apt-get -qq install -y ca-certificates apt-get -qq install -y curl wget unzip /usr/bin/python3 -m pip install --disable-pip-version-check wheel virtualenv /usr/bin/python3 -m pip install --disable-pip-version-check setuptools --upgrade /build/deps/readies/bin/enable-utf8 apt-get -qq install -y git automake libtool autoconf apt-get -qq install -y locales apt-get -qq update -y apt-get -qq install -y build-essential apt-get -qq install -y peg apt-get -qq install -y valgrind apt-get -qq install -y astyle apt-get -qq update -y apt-get -qq install -y ca-certificates apt-get -qq install -y curl wget unzip wget -q -O /tmp/cmake.sh https://github.com/Kitware/CMake/releases/download/v3.21.1/cmake-3.21.1-`uname`-`uname -m`.sh; sh /tmp/cmake.sh --skip-license --prefix=/usr/local; rm -f /tmp/cmake.sh /usr/bin/python3 -m pip install --disable-pip-version-check psutil apt-get remove -y python3-psutil apt-get -qq update -y apt-get -qq install -y build-essential apt-get -qq install -y python3-dev /usr/bin/python3 -m pip install --disable-pip-version-check psutil apt-get -qq install -y git /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/redisfab/redis-py.git@3.5 /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed redis-py-cluster /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/RedisLabsModules/RLTest.git@master /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/RedisLabs/RAMP@master /usr/bin/python3 -m pip install --disable-pip-version-check -r tests/requirements.txt . Debian Buster (10) . apt-get -qq update -y apt-get -qq install -y ca-certificates apt-get -qq install -y curl wget unzip /usr/bin/python3 -m pip install --disable-pip-version-check wheel virtualenv /usr/bin/python3 -m pip install --disable-pip-version-check setuptools --upgrade /build/deps/readies/bin/enable-utf8 apt-get -qq install -y git automake libtool autoconf apt-get -qq install -y locales apt-get -qq update -y apt-get -qq install -y build-essential apt-get -qq install -y peg apt-get -qq install -y valgrind apt-get -qq install -y astyle /build/deps/readies/bin/getcmake apt-get -qq update -y /usr/bin/python3 -m pip install --disable-pip-version-check psutil apt-get remove -y python3-psutil apt-get -qq update -y apt-get -qq install -y build-essential apt-get -qq install -y python3-dev /usr/bin/python3 -m pip install --disable-pip-version-check psutil apt-get -qq install -y git /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/redisfab/redis-py.git@3.5 /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed redis-py-cluster /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/RedisLabsModules/RLTest.git@master /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/RedisLabs/RAMP@master /usr/bin/python3 -m pip install --disable-pip-version-check -r tests/requirements.txt . Alpine 3 . apk add bash busybox python3 apk add -q ca-certificates apk add -q curl wget unzip /usr/bin/python3 -m pip install --disable-pip-version-check wheel virtualenv /usr/bin/python3 -m pip install --disable-pip-version-check setuptools --upgrade /build/deps/readies/bin/enable-utf8 apk add -q git automake libtool autoconf apk add -q automake make autoconf libtool m4 apk add -q build-base musl-dev gcc g++ cd /tmp; build_dir=$(mktemp -d); cd $build_dir; wget -q -O peg.tar.gz https://github.com/gpakosz/peg/archive/0.1.18.tar.gz; tar xzf peg.tar.gz; cd peg-0.1.18; make; make install MANDIR=.; cd /tmp; rm -rf $build_dir apk add -q valgrind apk add -q astyle apk add -q ca-certificates apk add -q curl wget unzip wget -q -O /tmp/cmake.sh https://github.com/Kitware/CMake/releases/download/v3.21.1/cmake-3.21.1-`uname`-`uname -m`.sh; sh /tmp/cmake.sh --skip-license --prefix=/usr/local; rm -f /tmp/cmake.sh apk add -q linux-headers apk add -q git /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/redisfab/redis-py.git@3.5 /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed redis-py-cluster /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/RedisLabsModules/RLTest.git@master /usr/bin/python3 -m pip install --disable-pip-version-check --no-cache-dir --ignore-installed git+https://github.com/RedisLabs/RAMP@master /usr/bin/python3 -m pip install --disable-pip-version-check -r tests/requirements.txt . ",
    "url": "/docker-examples/README.html#manual-installation",
    
    "relUrl": "/docker-examples/README.html#manual-installation"
  },"3": {
    "doc": "Building Docker",
    "title": "Building Docker",
    "content": " ",
    "url": "/docker-examples/README.html",
    
    "relUrl": "/docker-examples/README.html"
  },"4": {
    "doc": "References",
    "title": "References",
    "content": ". | FalkorDB Blog . | Video . | Building a Multi-dimensional Analytics Engine with RedisGraph | A Practical Introduction to RedisGraph | Redis Graph with Roi Lipman | RedisGraph 2.2: The Fastest Way to Query Your Highly Connected Data in Redis | . | Slides . | RedisGraph A Low Latency Graph DB | . | Article - RedisGraph GraphBLAS Enabled Graph Database. Cailliau, Pieter &amp; Davis, Tim &amp; Gadepally, Vijay &amp; Kepner, Jeremy &amp; Lipman, Roi &amp; Lovitz, Jeffrey &amp; Ouaknine, Keren (IEEE IPDPS 2019 GrAPL workshop). (pdf) . | Blog . | RedisGraph 2.0 Boosts Performance Up to 6x | Investigating RedisGraph. alister | Getting Started with Knowledge Graphs in RedisGraph | Introducing RedisGraph 2.0 | RedisGraph Elixir client. Christopher Flynn | What’s New in RedisGraph 1.2.0. Roi Lipman. | Benchmarking RedisGraph 1.0. Pieter Cailliau. | . | Development Tutorial | . ",
    "url": "/References.html",
    
    "relUrl": "/References.html"
  },"5": {
    "doc": "Algorithms",
    "title": "Algorithms",
    "content": " ",
    "url": "/cypher/algorithms.html",
    
    "relUrl": "/cypher/algorithms.html"
  },"6": {
    "doc": "Algorithms",
    "title": "BFS",
    "content": "The breadth-first-search algorithm accepts 3 arguments: . source-node (node) - The root of the search. max-level (integer) - If greater than zero, this argument indicates how many levels should be traversed by BFS. 1 would retrieve only the source’s neighbors, 2 would retrieve all nodes within 2 hops, and so on. relationship-type (string) - If this argument is NULL, all relationship types will be traversed. Otherwise, it specifies a single relationship type to perform BFS over. It can yield two outputs: . nodes - An array of all nodes connected to the source without violating the input constraints. edges - An array of all edges traversed during the search. This does not necessarily contain all edges connecting nodes in the tree, as cycles or multiple edges connecting the same source and destination do not have a bearing on the reachability this algorithm tests for. These can be used to construct the directed acyclic graph that represents the BFS tree. Emitting edges incurs a small performance penalty. ",
    "url": "/cypher/algorithms.html#bfs",
    
    "relUrl": "/cypher/algorithms.html#bfs"
  },"7": {
    "doc": "BOLT protocol support",
    "title": "[EXPERIMENTAL] BOLT protocol support for FalkorDB",
    "content": "FalkorDB provides an experimental support for querying using BOLT drivers. We intend to extend the support in the future versions, the current version is not meant to be used in production. This guide will walk you through the process of connecting to FalkorDB using the BOLT protocol . ",
    "url": "/bolt_support.html#experimental-bolt-protocol-support-for-falkordb",
    
    "relUrl": "/bolt_support.html#experimental-bolt-protocol-support-for-falkordb"
  },"8": {
    "doc": "BOLT protocol support",
    "title": "Prerequisites",
    "content": "Before you begin, ensure that you have a FalkorDB instance up and running. You can use our Docker image for this purpose. docker run -p 6379:6379 -p 7678:7678 -p 3000:3000 -it -e REDIS_ARGS=\"--requirepass falkordb\" -e FALKORDB_ARGS=\"BOLT_PORT 7678\" --rm falkordb/falkordb:latest . Ports . | 6379 - FalkorDB | 7678 - Bolt | 3000 - Falkor-Browser | . Additionally, install the necessary BOLT drivers: . pip install neo4j . ",
    "url": "/bolt_support.html#prerequisites",
    
    "relUrl": "/bolt_support.html#prerequisites"
  },"9": {
    "doc": "BOLT protocol support",
    "title": "Step 1: Create a main.py File",
    "content": "Create a main.py file with the following content and adjust the connection uri, authentication parameters and database name according to your FalkorDB setup. This script demonstrates a simple query that returns the numbers from 1 to 10. Customize the query as needed for your specific use case. from neo4j import GraphDatabase driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"falkordb\", \"\")) records, summary, keys = driver.execute_query( \"UNWIND range(1, $n) AS i RETURN i\", n=10, database_=\"mygraph\", ) for record in records: print(record[\"i\"]) . ",
    "url": "/bolt_support.html#step-1-create-a-mainpy-file",
    
    "relUrl": "/bolt_support.html#step-1-create-a-mainpy-file"
  },"10": {
    "doc": "BOLT protocol support",
    "title": "Step 2: Run the script",
    "content": "Execute the script by running the following command in your terminal: . bash . python main.py . ",
    "url": "/bolt_support.html#step-2-run-the-script",
    
    "relUrl": "/bolt_support.html#step-2-run-the-script"
  },"11": {
    "doc": "BOLT protocol support",
    "title": "BOLT protocol support",
    "content": " ",
    "url": "/bolt_support.html",
    
    "relUrl": "/bolt_support.html"
  },"12": {
    "doc": "GRAPH.BULK endpoint specification",
    "title": "GRAPH.BULK endpoint specification",
    "content": "The FalkorDB bulk loader uses the GRAPH.BULK endpoint to build a new graph from 1 or more Redis queries. The bulk of these queries is binary data that is unpacked to create nodes, edges, and their properties. This endpoint could be used to write bespoke import tools for other data formats using the implementation details provided here. ",
    "url": "/design/bulk_spec.html",
    
    "relUrl": "/design/bulk_spec.html"
  },"13": {
    "doc": "GRAPH.BULK endpoint specification",
    "title": "Caveats",
    "content": "The main complicating factor in writing bulk importers is that Redis has a maximum string length of 512 megabytes and a default maximum query size of 1 gigabyte. As such, large imports must be written incrementally. The FalkorDB team will do their best to ensure that future updates to this logic do not break current implementations, but cannot guarantee it. ",
    "url": "/design/bulk_spec.html#caveats",
    
    "relUrl": "/design/bulk_spec.html#caveats"
  },"14": {
    "doc": "GRAPH.BULK endpoint specification",
    "title": "Query Format",
    "content": "GRAPH.BULK [graph name] [\"BEGIN\"] [node count] [edge count] ([binary blob] * N) . Arguments . graph name . The name of the graph to be inserted. BEGIN . The endpoint cannot be used to update existing graphs, only to create new ones. For this reason, the first query in a sequence of BULK commands should pass the string literal “BEGIN”. node count . Number of nodes being inserted in this query. edge count . Number of edges being inserted in this query. binary blob . A binary string of up to 512 megabytes that partially or completely describes a single label or relationship type. Any number of these blobs may be provided in a query provided that Redis’s 1-gigabyte query limit is not exceeded. Module behavior . The endpoint will parse binary blobs as nodes until the number of created nodes matches the node count, then will parse subsequent blobs as edges. The import tool is expected to correctly provide these counts. If the BEGIN token is found, the module will verify that the graph key is unused, and will emit an error if it is. Otherwise, the partially-constructed graph will be retrieved in order to resume building. ",
    "url": "/design/bulk_spec.html#query-format",
    
    "relUrl": "/design/bulk_spec.html#query-format"
  },"15": {
    "doc": "GRAPH.BULK endpoint specification",
    "title": "Binary Blob format",
    "content": "Node format . Nodes in node blobs do not need to specify their IDs. The ID of each node is an 8-byte unsigned integer corresponding to the node count at the time of its creation. (The first-created node has the ID of 0, the second has 1, and so forth.) . The blob consists of: . | header specification . | 1 or more property specifications . | . Edge format . The import tool is responsible for tracking the IDs of nodes used as edge endpoints. The blob consists of: . | header specification . | 1 or more: . | 8-byte unsigned integer representing source node ID | 8-byte unsigned integer representing destination node ID | property specification | . | . Header specification . | name - A null-terminated string representing the name of the label or relationship type. | property count - A 4-byte unsigned integer representing the number of properties each entry in this blob possesses. | property names - an ordered sequence of property count null-terminated strings, each representing the name for the property at that position. | . Property specification . | property type - A 1-byte integer corresponding to the TYPE enum: BI_NULL = 0, BI_BOOL = 1, BI_DOUBLE = 2, BI_STRING = 3, BI_LONG = 4, BI_ARRAY = 5, . | property: . | 1-byte true/false if type is boolean | 8-byte double if type is double | 8-byte integer if type is integer | Null-terminated C string if type is string | 8-byte array length followed by N values of this same type-property pair if type is array | . | . ",
    "url": "/design/bulk_spec.html#binary-blob-format",
    
    "relUrl": "/design/bulk_spec.html#binary-blob-format"
  },"16": {
    "doc": "GRAPH.BULK endpoint specification",
    "title": "Redis Reply",
    "content": "Redis will reply with a string of the format: . [N] nodes created, [M] edges created . ",
    "url": "/design/bulk_spec.html#redis-reply",
    
    "relUrl": "/design/bulk_spec.html#redis-reply"
  },"17": {
    "doc": "CALL",
    "title": "CALL {}",
    "content": "The CALL {} (subquery) clause allows local execution of subqueries, which opens the door for many comfortable and efficient actions on a graph. The subquery is executed once for each record in the input stream. The subquery may be a returning or non-returning subquery. A returning subquery may change the amount of records, while a non-returning subquery will not. The variables in the scope before the CALL {} clause are available after the clause, together with the variables returned by the subquery (in the case of a returning subquery). Variables may be imported from the outer scope only in an opening WITH clause, via simple projections (e.g. WITH n, m), or via WITH * (which imports all bound variables). The variables returned from a subquery may not override existing variables in the outer scope. The CALL {} clause may be used for numerous purposes, such as: Post-UNION processing, local environment for aggregations and actions on every input row, efficient operations using a limited namespace (via imports) and performing side-effects using non-returning subqueries. Let’s see some examples. | Post-UNION processing. | . We can easily get the cheapest and most expensive items in a store and set their of_interest property to true (to keep monitoring the ‘interesting’ items) using post-UNION processing: . GRAPH.QUERY DEMO_GRAPH CALL { MATCH (s:Store {name: 'Walmart'})-[:SELLS]-&gt;(i:Item) RETURN i AS item ORDER BY price ASC LIMIT 1 UNION MATCH (s:Store {name: 'Walmart'})-[:SELLS]-&gt;(i:Item) RETURN i AS item ORDER BY price DESC LIMIT 1 } SET item.of_interest = true RETURN item.name AS name, item.price AS price . We can utilize post-UNION processing to perform aggregations over differently-matched entities. For example, we can count the number of customers and vendors that a store interacts with: . GRAPH.QUERY DEMO_GRAPH CALL { MATCH (s:Store {name: 'Walmart'})-[:SELLS_TO]-&gt;(c:Customer) RETURN c AS interface UNION MATCH (s:Store {name: 'Walmart'})-[:BUYS_FROM]-&gt;(v:Vendor) RETURN v AS interface } RETURN count(interface) AS interfaces . | Local environment for aggregations and actions on every input row. | . Another key feature of the CALL {} clause is the ability to perform isolated aggregations on every input row. For example, let’s check if there is any correlation between the amount of sales per-product and the advertisement-intensity implemented for it in a particular month. GRAPH.QUERY DEMO_GRAPH MATCH (item:Item) CALL { WITH item MATCH (item)-[s:SOLD_TO {advertisement_intensity: 10}]-&gt;(c:Customer) WHERE s.date &gt; '01-01-2023' AND s.date &lt; '01-02-2023' RETURN count(s) AS item_sales_ads_high } CALL { WITH item MATCH (item)-[s:SOLD_TO {advertisement_intensity: 5}]-&gt;(c:Customer) WHERE s.date &gt; '01-01-2023' AND s.date &lt; '01-02-2023' RETURN count(s) AS item_sales_ads_low } RETURN item.name AS name, item_sales_ads_high as high_ads_sales, item_sales_ads_low as low_ads_sales . | Side-effects. | . We can comfortably perform side-effects using non-returning subqueries. For example, we can mark a sub-group of nodes in the graph withholding some shared property. Let’s mark all the items in a Walmart store that were sold more than 100 times as popular items, and return all items in the store: . GRAPH.QUERY DEMO_GRAPH MATCH (item:Item) CALL { WITH item MATCH (item)-[s:SOLD_TO]-&gt;(c:Customer) WITH item, count(s) AS item_sales WHERE item_sales &gt; 100 SET item.popular = true } RETURN item . ",
    "url": "/cypher/call.html#call-",
    
    "relUrl": "/cypher/call.html#call-"
  },"18": {
    "doc": "CALL",
    "title": "CALL",
    "content": " ",
    "url": "/cypher/call.html",
    
    "relUrl": "/cypher/call.html"
  },"19": {
    "doc": "Client Specification",
    "title": "Client Specification",
    "content": "By design, there is not a full standard for FalkorDB clients to adhere to. Areas such as pretty-print formatting, query validation, and transactional and multithreaded capabilities have no canonically correct behavior, and the implementer is free to choose the approach and complexity that suits them best. FalkorDB does, however, provide a compact result set format for clients that minimizes the amount of redundant data transmitted from the server. Implementers are encouraged to take advantage of this format, as it provides better performance and removes ambiguity from decoding certain data. This approach requires clients to be capable of issuing procedure calls to the server and performing a small amount of client-side caching. ",
    "url": "/design/client_spec.html",
    
    "relUrl": "/design/client_spec.html"
  },"20": {
    "doc": "Client Specification",
    "title": "Retrieving the compact result set",
    "content": "Appending the flag --compact to any query issued to the GRAPH.QUERY endpoint will cause the server to issue results in the compact format. Because we don’t store connection-specific configurations, all queries should be issued with this flag. GRAPH.QUERY demo \"MATCH (a) RETURN a\" --compact . ",
    "url": "/design/client_spec.html#retrieving-the-compact-result-set",
    
    "relUrl": "/design/client_spec.html#retrieving-the-compact-result-set"
  },"21": {
    "doc": "Client Specification",
    "title": "Formatting differences in the compact result set",
    "content": "Certain values are emitted as integer IDs rather than strings: . | Node labels | Relationship types | Property keys | . Instructions on how to efficiently convert these IDs in the Procedure Calls section below. Additionally, two enums are exposed: . ColumnType, which as of v2.1.0 will always be COLUMN_SCALAR. This enum is retained for backwards compatibility, and may be ignored by the client unless versions older than v2.1.0 must be supported. ValueType indicates the data type (such as Node, integer, or string) of each returned value. Each value is emitted as a 2-array, with this enum in the first position and the actual value in the second. Each property on a graph entity also has a scalar as its value, so this construction is nested in each value of the properties array when a column contains a node or relationship. ",
    "url": "/design/client_spec.html#formatting-differences-in-the-compact-result-set",
    
    "relUrl": "/design/client_spec.html#formatting-differences-in-the-compact-result-set"
  },"22": {
    "doc": "Client Specification",
    "title": "Decoding the result set",
    "content": "Given the graph created by the query: . GRAPH.QUERY demo \"CREATE (:plant {name: 'Tree'})-[:GROWS {season: 'Autumn'}]-&gt;(:fruit {name: 'Apple'})\" . Let’s formulate a query that returns 3 columns: nodes, relationships, and scalars, in that order. Verbose (default): . 127.0.0.1:6379&gt; GRAPH.QUERY demo \"MATCH (a)-[e]-&gt;(b) RETURN a, e, b.name\" 1) 1) \"a\" 2) \"e\" 3) \"b.name\" 2) 1) 1) 1) 1) \"id\" 2) (integer) 0 2) 1) \"labels\" 2) 1) \"plant\" 3) 1) \"properties\" 2) 1) 1) \"name\" 2) \"Tree\" 2) 1) 1) \"id\" 2) (integer) 0 2) 1) \"type\" 2) \"GROWS\" 3) 1) \"src_node\" 2) (integer) 0 4) 1) \"dest_node\" 2) (integer) 1 5) 1) \"properties\" 2) 1) 1) \"season\" 2) \"Autumn\" 3) \"Apple\" 3) 1) \"Query internal execution time: 1.326905 milliseconds\" . Compact: . 127.0.0.1:6379&gt; GRAPH.QUERY demo \"MATCH (a)-[e]-&gt;(b) RETURN a, e, b.name\" --compact 1) 1) 1) (integer) 1 2) \"a\" 2) 1) (integer) 1 2) \"e\" 3) 1) (integer) 1 2) \"b.name\" 2) 1) 1) 1) (integer) 8 2) 1) (integer) 0 2) 1) (integer) 0 3) 1) 1) (integer) 0 2) (integer) 2 3) \"Tree\" 2) 1) (integer) 7 2) 1) (integer) 0 2) (integer) 0 3) (integer) 0 4) (integer) 1 5) 1) 1) (integer) 1 2) (integer) 2 3) \"Autumn\" 3) 1) (integer) 2 2) \"Apple\" 3) 1) \"Query internal execution time: 1.085412 milliseconds\" . These results are being parsed by redis-cli, which adds such visual cues as array indexing and indentation, as well as type hints like (integer). The actual data transmitted is formatted using the RESP protocol. All of the current FalkorDB clients rely upon a stable Redis client in the same language (such as redis-rb for Ruby) which handles RESP decoding. Top-level array results . The result set above had 3 members in its top-level array: . 1) Header row 2) Result rows 3) Query statistics . All queries that have a RETURN clause will have these 3 members. Queries that don’t return results have only one member in the outermost array, the query statistics: . 127.0.0.1:6379&gt; GRAPH.QUERY demo \"CREATE (:plant {name: 'Tree'})-[:GROWS {season: 'Autumn'}]-&gt;(:fruit {name: 'Apple'})\" --compact 1) 1) \"Labels added: 2\" 2) \"Nodes created: 2\" 3) \"Properties set: 3\" 4) \"Relationships created: 1\" 5) \"Query internal execution time: 1.972868 milliseconds\" . Rather than introspecting on the query being emitted, the client implementation can check whether this array contains 1 or 3 elements to choose how to format data. Reading the header row . Our sample query MATCH (a)-[e]-&gt;(b) RETURN a, e, b.name generated the header: . 1) 1) (integer) 1 2) \"a\" 3) 1) (integer) 1 3) \"e\" 4) 1) (integer) 1 3) \"b.name\" . The 4 array members correspond, in order, to the 3 entities described in the RETURN clause. Each is emitted as a 2-array: . 1) ColumnType (enum) 2) column name (string) . The first element is the ColumnType enum, which as of RedisGraph v2.1.0 will always be COLUMN_SCALAR. This element is retained for backwards compatibility, and may be ignored by the client unless RedisGraph versions older than v2.1.0 must be supported. Reading result rows . The entity representations in this section will closely resemble those found in Result Set Graph Entities. Our query produced one row of results with 3 columns (as described by the header): . 1) 1) 1) (integer) 8 2) 1) (integer) 0 2) 1) (integer) 0 3) 1) 1) (integer) 0 2) (integer) 2 3) \"Tree\" 2) 1) (integer) 7 2) 1) (integer) 0 2) (integer) 0 3) (integer) 0 4) (integer) 1 5) 1) 1) (integer) 1 2) (integer) 2 3) \"Autumn\" 3) 1) (integer) 2 2) \"Apple\" . Each element is emitted as a 2-array - [ValueType, value]. It is the client’s responsibility to store the ValueType enum. FalkorDB guarantees that this enum may be extended in the future, but the existing values will not be altered. The ValueType for the first entry is VALUE_NODE. The node representation contains 3 top-level elements: . | The node’s internal ID. | An array of all label IDs associated with the node (currently, each node can have either 0 or 1 labels, though this restriction may be lifted in the future). | An array of all properties the node contains. Properties are represented as 3-arrays - [property key ID, ValueType, value]. | . [ Node ID (integer), [label ID (integer) X label count] [[property key ID (integer), ValueType (enum), value (scalar)] X property count] ] . The ValueType for the first entry is VALUE_EDGE. The edge representation differs from the node representation in two respects: . | Each relation has exactly one type, rather than the 0+ labels a node may have. | A relation is emitted with the IDs of its source and destination nodes. | . As such, the complete representation is as follows: . | The relation’s internal ID. | The relationship type ID. | The source node’s internal ID. | The destination node’s internal ID. | The key-value pairs of all properties the relation possesses. | . [ Relation ID (integer), type ID (integer), source node ID (integer), destination node ID (integer), [[property key ID (integer), ValueType (enum), value (scalar)] X property count] ] . The ValueType for the third entry is VALUE_STRING, and the other element in the array is the actual value, “Apple”. Reading statistics . The final top-level member of the GRAPH.QUERY reply is the execution statistics. This element is identical between the compact and standard response formats. The statistics always include query execution time, while any combination of the other elements may be included depending on how the graph was modified. | “Labels added: (integer)” | “Labels removed: (integer)” (since RedisGraph 2.10) | “Nodes created: (integer)” | “Nodes deleted: (integer)” | “Properties set: (integer)” | “Properties removed: (integer)” (since RedisGraph 2.10) | “Relationships created: (integer)” | “Relationships deleted: (integer)” | “Indices created: (integer)” | “Indices deleted: (integer)” | “Query internal execution time: (float) milliseconds” | . ",
    "url": "/design/client_spec.html#decoding-the-result-set",
    
    "relUrl": "/design/client_spec.html#decoding-the-result-set"
  },"23": {
    "doc": "Client Specification",
    "title": "Procedure Calls",
    "content": "Property keys, node labels, and relationship types are all returned as IDs rather than strings in the compact format. For each of these 3 string-ID mappings, IDs start at 0 and increase monotonically. As such, the client should store a string array for each of these 3 mappings, and print the appropriate string for the user by checking an array at position ID. If an ID greater than the array length is encountered, the local array should be updated with a procedure call. These calls are described generally in the Procedures documentation. To retrieve each full mapping, the appropriate calls are: . db.labels() . 127.0.0.1:6379&gt; GRAPH.QUERY demo \"CALL db.labels()\" 1) 1) \"label\" 2) 1) 1) \"plant\" 2) 1) \"fruit\" 3) 1) \"Query internal execution time: 0.321513 milliseconds\" . db.relationshipTypes() . 127.0.0.1:6379&gt; GRAPH.QUERY demo \"CALL db.relationshipTypes()\" 1) 1) \"relationshipType\" 2) 1) 1) \"GROWS\" 3) 1) \"Query internal execution time: 0.429677 milliseconds\" . db.propertyKeys() . 127.0.0.1:6379&gt; GRAPH.QUERY demo \"CALL db.propertyKeys()\" 1) 1) \"propertyKey\" 2) 1) 1) \"name\" 2) 1) \"season\" 3) 1) \"Query internal execution time: 0.318940 milliseconds\" . Because the cached values never become outdated, it is possible to just retrieve new values with slightly more complex constructions: . CALL db.propertyKeys() YIELD propertyKey RETURN propertyKey SKIP [cached_array_length] . Though the property calls are quite efficient regardless of whether this optimization is used. As an example, the Python client checks its local array of labels to resolve every label ID as seen here. In the case of an IndexError, it issues a procedure call to fully refresh its label cache as seen here. ",
    "url": "/design/client_spec.html#procedure-calls",
    
    "relUrl": "/design/client_spec.html#procedure-calls"
  },"24": {
    "doc": "Client Specification",
    "title": "Reference clients",
    "content": "All the logic described in this document has been implemented in most of the clients listed in Client Libraries. Among these, node-redis, redis-py and jedis are currently the most sophisticated. ",
    "url": "/design/client_spec.html#reference-clients",
    
    "relUrl": "/design/client_spec.html#reference-clients"
  },"25": {
    "doc": "Client Libraries",
    "title": "Official Clients",
    "content": "| Project | Docs | Language | License | Author | Package | . | falkordb-py | Pydoc | Python | MIT | FalkorDB | pypi | . | falkordb-ts | JSDoc | Node.JS | MIT | FalkorDB | npm | . | jfalkordb | javadocs | Java | BSD | FalkorDB | maven | . | falkordb-rs | docs.rs | Rust | MIT | FalkorDB | crates | . | falkordb-go | godoc | Go | BSD | FalkorDB | crates | . ",
    "url": "/clients.html#official-clients",
    
    "relUrl": "/clients.html#official-clients"
  },"26": {
    "doc": "Client Libraries",
    "title": "Additional Clients",
    "content": "| Project | Language | License | Author | Package | . | nredisstack | .NET | MIT | Redis | nuget | . | redisgraph-rb | Ruby | BSD | Redis | GitHub | . | redgraph | Ruby | MIT | pzac | GitHub | . | redisgraph-go | Go | BSD | Redis | GitHub | . | rueidis | Go | Apache 2.0 | Rueian | GitHub | . | ioredisgraph | JavaScript | ISC | Jonah | GitHub | . | @hydre/rgraph | JavaScript | MIT | Sceat | GitHub | . | php-redis-graph | PHP | MIT | KJDev | GitHub | . | redisgraph_php | PHP | MIT | jpbourbon | GitHub | . | redisgraph-ex | Elixir | MIT | crflynn | GitHub | . | redisgraph-rs | Rust | MIT | malte-v | GitHub | . | redis_graph | Rust | BSD | tompro | GitHub | . | rustis | Rust | MIT | Dahomey Technologies | Crate | . | NRedisGraph | C# | BSD | tombatron | GitHub | . | RedisGraph.jl | Julia | MIT | xyxel | GitHub | . ",
    "url": "/clients.html#additional-clients",
    
    "relUrl": "/clients.html#additional-clients"
  },"27": {
    "doc": "Client Libraries",
    "title": "Implementing a client",
    "content": "Information on some of the tasks involved in writing a FalkorDB client can be found in the Client Specification. ",
    "url": "/clients.html#implementing-a-client",
    
    "relUrl": "/clients.html#implementing-a-client"
  },"28": {
    "doc": "Client Libraries",
    "title": "Client Libraries",
    "content": " ",
    "url": "/clients.html",
    
    "relUrl": "/clients.html"
  },"29": {
    "doc": "Cluster",
    "title": "Setting Up a FalkorDB Cluster",
    "content": "Setting up a FalkorDB cluster enables you to distribute your data across multiple nodes, providing horizontal scalability and improved fault tolerance. This guide will walk you through the steps to configure a FalkorDB cluster with 3 masters and 1 replica for each, using Docker. ",
    "url": "/operations/cluster.html#setting-up-a-falkordb-cluster",
    
    "relUrl": "/operations/cluster.html#setting-up-a-falkordb-cluster"
  },"30": {
    "doc": "Cluster",
    "title": "Prerequisites",
    "content": "Before you begin, ensure you have the following: . | Docker installed on your machine. | A working FalkorDB Docker image. You can pull it from Docker Hub. | Basic knowledge of Docker networking and commands. | . ",
    "url": "/operations/cluster.html#prerequisites",
    
    "relUrl": "/operations/cluster.html#prerequisites"
  },"31": {
    "doc": "Cluster",
    "title": "Step 1: Network Configuration",
    "content": "First, create a Docker network to allow communication between the FalkorDB nodes. docker network create falkordb-cluster-network . This network will enable the containers to communicate with each other. ",
    "url": "/operations/cluster.html#step-1-network-configuration",
    
    "relUrl": "/operations/cluster.html#step-1-network-configuration"
  },"32": {
    "doc": "Cluster",
    "title": "Step 2: Launching FalkorDB Nodes",
    "content": "Next, you need to launch multiple FalkorDB instances that will form the cluster. For example, you can start six nodes: . 2.1 Start the nodes . docker run -d \\ --name node1 \\ --network falkordb-cluster-network \\ -p 6379:6379 \\ -e 'FALKORDB_ARGS=--cluster-enabled yes' \\ falkordb/falkordb . docker run -d \\ --name node2 \\ --network falkordb-cluster-network \\ -p 6380:6379 \\ -e 'FALKORDB_ARGS=--cluster-enabled yes' \\ falkordb/falkordb . docker run -d \\ --name node3 \\ --network falkordb-cluster-network \\ -p 6381:6379 \\ -e 'FALKORDB_ARGS=--cluster-enabled yes' \\ falkordb/falkordb . docker run -d \\ --name node4 \\ --network falkordb-cluster-network \\ -p 6382:6379 \\ -e 'FALKORDB_ARGS=--cluster-enabled yes' \\ falkordb/falkordb . docker run -d \\ --name node5 \\ --network falkordb-cluster-network \\ -p 6383:6379 \\ -e 'FALKORDB_ARGS=--cluster-enabled yes' \\ falkordb/falkordb . docker run -d \\ --name node6 \\ --network falkordb-cluster-network \\ -p 6384:6379 \\ -e 'FALKORDB_ARGS=--cluster-enabled yes' \\ falkordb/falkordb . In this command, the –network falkordb-cluster-network flag connects the container to the network created in Step 1. ",
    "url": "/operations/cluster.html#step-2-launching-falkordb-nodes",
    
    "relUrl": "/operations/cluster.html#step-2-launching-falkordb-nodes"
  },"33": {
    "doc": "Cluster",
    "title": "Step 3: Configuring the Cluster",
    "content": "Once all nodes are up, you need to connect them to form a cluster. Use the redis-cli tool inside one of the nodes to initiate the cluster setup. 3.1 Connect to a Node . docker exec -it node1 /bin/bash . 3.2 Initiate the Cluster . Inside the container, use the following command to form the cluster: . redis-cli --cluster create node1:6379 node2:6379 node3:6379 node4:6379 node5:6379 node6:6379 --cluster-replicas 1 . This command will join node1, node2, and node3 into a cluster. 3.3 Verify Cluster Status . You can verify the status of the cluster with: . redis-cli --cluster check node1:6379 . This command will display the status of each node and their roles (master/replica). ",
    "url": "/operations/cluster.html#step-3-configuring-the-cluster",
    
    "relUrl": "/operations/cluster.html#step-3-configuring-the-cluster"
  },"34": {
    "doc": "Cluster",
    "title": "Step 4: Scaling the Cluster",
    "content": "You can scale the cluster by adding more nodes as needed. Simply launch additional FalkorDB instances and add them to the cluster using the falkordb-cli tool. For example, to add a new node: . 4.1 Start a New Node . docker run -d \\ --name node7 \\ --network falkordb-cluster-network \\ -p 6385:6379 \\ -e 'FALKORDB_ARGS=--cluster-enabled yes' \\ falkordb/falkordb . 4.2 Add the Node to the Cluster . docker exec -it node1 /bin/bash redis-cli --cluster add-node node7:6379 node1:6379 . This will add node7 into the existing cluster. ",
    "url": "/operations/cluster.html#step-4-scaling-the-cluster",
    
    "relUrl": "/operations/cluster.html#step-4-scaling-the-cluster"
  },"35": {
    "doc": "Cluster",
    "title": "Conclusion",
    "content": "With your FalkorDB cluster set up, you now have a scalable, distributed environment that can handle increased loads and provide higher availability. ",
    "url": "/operations/cluster.html#conclusion",
    
    "relUrl": "/operations/cluster.html#conclusion"
  },"36": {
    "doc": "Cluster",
    "title": "Cluster",
    "content": " ",
    "url": "/operations/cluster.html",
    
    "relUrl": "/operations/cluster.html"
  },"37": {
    "doc": "Configuration Parameters",
    "title": "Configuration",
    "content": "FalkorDB supports Redis configuration and multiple module configuration parameters. Some of these parameters can only be set at load-time, while other parameters can be set either on load-time or on run-time. For example the following will run the server with global authentication password and 4 threads. docker run -p 6379:6379 -p 3000:3000 -it -e REDIS_ARGS=\"--requirepass falkordb\" -e FALKORDB_ARGS=\"THREAD_COUNT 4\" --rm falkordb/falkordb:latest . ",
    "url": "/configuration.html#configuration",
    
    "relUrl": "/configuration.html#configuration"
  },"38": {
    "doc": "Configuration Parameters",
    "title": "Setting configuration parameters on module load",
    "content": "Setting configuration parameters at load-time is done by appending arguments after the --loadmodule argument when starting a server from the command line or after the loadmodule directive in a Redis config file. For example: . In redis.conf: . loadmodule ./falkordb.so [OPT VAL]... From the Redis CLI, using the MODULE LOAD command: . 127.0.0.6379&gt; MODULE LOAD falkordb.so [OPT VAL]... From the command line: . $ redis-server --loadmodule ./falkordb.so [OPT VAL]... When running a docker container . docker run -p 6379:6379 -p 3000:3000 -it -e FALKORDB_ARGS=\"[OPT VAL]\" --rm falkordb/falkordb:latest . ",
    "url": "/configuration.html#setting-configuration-parameters-on-module-load",
    
    "relUrl": "/configuration.html#setting-configuration-parameters-on-module-load"
  },"39": {
    "doc": "Configuration Parameters",
    "title": "Setting configuration parameters at run-time (for supported parameters)",
    "content": "FalkorDB exposes the GRAPH.CONFIG command to allowing for the setting and retrieval of configuration parameters at run-time. To set the value of a configuration parameter at run-time (for supported parameters), simply run: . GRAPH.CONFIG SET OPT1 VAL1 . Similarly, current configuration parameter values can be retrieved using: . GRAPH.CONFIG GET OPT1 GRAPH.CONFIG GET * . Values set using GRAPH.CONFIG SET are not persisted after server restart. ",
    "url": "/configuration.html#setting-configuration-parameters-at-run-time-for-supported-parameters",
    
    "relUrl": "/configuration.html#setting-configuration-parameters-at-run-time-for-supported-parameters"
  },"40": {
    "doc": "Configuration Parameters",
    "title": "FalkorDB configuration parameters",
    "content": "The following table summarizes which configuration parameters can be set at module load-time and which can also be set at run-time: . | Configuration Parameter | Load-time | Run-time | . | THREAD_COUNT | V | X | . | CACHE_SIZE | V | X | . | OMP_THREAD_COUNT | V | X | . | NODE_CREATION_BUFFER | V | X | . | BOLT_PORT | V | X | . | MAX_QUEUED_QUERIES | V | V | . | TIMEOUT (deprecated in v2.10) | V | V | . | TIMEOUT_MAX (since v2.10) | V | V | . | TIMEOUT_DEFAULT (since v2.10) | V | V | . | RESULTSET_SIZE | V | V | . | QUERY_MEM_CAPACITY | V | V | . | VKEY_MAX_ENTITY_COUNT | V | V | . | EFFECTS_THRESHOLD | V | V | . THREAD_COUNT . The number of threads in FalkorDB’s thread pool. This is equivalent to the maximum number of queries that can be processed concurrently. Default . THREAD_COUNT defaults to the system’s hardware threads (logical cores). Example . $ redis-server --loadmodule ./falkordb.so THREAD_COUNT 4 . CACHE_SIZE . The max number of queries for FalkorDB to cache. When a new query is encountered and the cache is full, meaning the cache has reached the size of CACHE_SIZE, it will evict the least recently used (LRU) entry. Default . CACHE_SIZE default value is 25. Example . $ redis-server --loadmodule ./falkordb.so CACHE_SIZE 10 . OMP_THREAD_COUNT . The maximum number of threads that OpenMP may use for computation per query. These threads are used for parallelizing GraphBLAS computations, so may be considered to control concurrency within the execution of individual queries. Default . OMP_THREAD_COUNT is defined by GraphBLAS. Example . $ redis-server --loadmodule ./falkordb.so OMP_THREAD_COUNT 1 . NODE_CREATION_BUFFER . The node creation buffer is the number of new nodes that can be created without resizing matrices. For example, when set to 16,384, the matrices will have extra space for 16,384 nodes upon creation. Whenever the extra space is depleted, the matrices’ size will increase by 16,384. Reducing this value will reduce memory consumption, but cause performance degradation due to the increased frequency of matrix resizes. Conversely, increasing it might improve performance for write-heavy workloads but will increase memory consumption. If the passed argument was not a power of 2, it will be rounded to the next-greatest power of 2 to improve memory alignment. Default . NODE_CREATION_BUFFER is 16,384. Minimum . The minimum value for NODE_CREATION_BUFFER is 128. Values lower than this will be accepted as arguments, but will internally be converted to 128. Example . $ redis-server --loadmodule ./falkordb.so NODE_CREATION_BUFFER 200 . BOLT_PORT . The Bolt port configuration determines the port number on which FalkorDB handles the bolt protocol . Default . BOLT_PORT -1 (disabled). Example . $ redis-server --loadmodule ./falkordb.so BOLT_PORT 7687 . MAX_QUEUED_QUERIES . Setting the maximum number of queued queries allows the server to reject incoming queries with the error message Max pending queries exceeded. This reduces the memory overhead of pending queries on an overloaded server and avoids congestion when the server processes its backlog of queries. Default . MAX_QUEUED_QUERIES is effectively unlimited (config value of UINT64_MAX). Example . $ redis-server --loadmodule ./falkordb.so MAX_QUEUED_QUERIES 500 $ redis-cli GRAPH.CONFIG SET MAX_QUEUED_QUERIES 500 . TIMEOUT . (Deprecated in FalkorDB v2.10 It is recommended to use TIMEOUT_MAX and TIMEOUT_DEFAULT instead) . The TIMEOUT configuration parameter specifies the default maximal execution time for read queries, in milliseconds. Write queries do not timeout. When a read query execution time exceeds the maximal execution time, the query is aborted and the query reply is (error) Query timed out. The TIMEOUT query parameter of the GRAPH.QUERY, GRAPH.RO_QUERY, and GRAPH.PROFILE commands can be used to override this value. Default . | Before v2.10: TIMEOUT is off (set to 0). | Since v2.10: TIMEOUT is not specified; TIMEOUT_MAX and TIMEOUT_DEFAULT are specified instead. | . Example . $ redis-server --loadmodule ./falkordb.so TIMEOUT 1000 . TIMEOUT_MAX . (Since v2.10) . The TIMEOUT_MAX configuration parameter specifies the maximum execution time for both read and write queries, in milliseconds. The TIMEOUT query parameter value of the GRAPH.QUERY, GRAPH.RO_QUERY, and GRAPH.PROFILE commands cannot exceed the TIMEOUT_MAX value (the command would abort with a (error) The query TIMEOUT parameter value cannot exceed the TIMEOUT_MAX configuration parameter value reply). Similarly, the TIMEOUT_DEFAULT configuration parameter cannot exceed the TIMEOUT_MAX value. When a query execution time exceeds the maximal execution time, the query is aborted and the query reply is (error) Query timed out. For a write query - any change to the graph is undone (which may take additional time). Default . | Before v2.10: unspecified and unsupported. | Since v2.10: TIMEOUT_MAX is off (set to 0). | . Example . $ redis-server --loadmodule ./falkordb.so TIMEOUT_MAX 1000 . TIMEOUT_DEFAULT . (Since v2.10) . The TIMEOUT_DEFAULT configuration parameter specifies the default maximal execution time for both read and write queries, in milliseconds. For a given query, this default maximal execution time can be overridden by the TIMEOUT query parameter of the GRAPH.QUERY, GRAPH.RO_QUERY, and GRAPH.PROFILE commands. However, a query execution time cannot exceed TIMEOUT_MAX. Default . | Before v2.10: unspecified and unsupported. | Since v2.10: TIMEOUT_DEFAULT is equal to TIMEOUT_MAX (set to 0). | . Example . $ redis-server --loadmodule ./falkordb.so TIMEOUT_MAX 2000 TIMEOUT_DEFAULT 1000 . RESULTSET_SIZE . Result set size is a limit on the number of records that should be returned by any query. This can be a valuable safeguard against incurring a heavy IO load while running queries with unknown results. Default . RESULTSET_SIZE is unlimited (negative config value). Example . 127.0.0.1:6379&gt; GRAPH.CONFIG SET RESULTSET_SIZE 3 OK 127.0.0.1:6379&gt; GRAPH.QUERY G \"UNWIND range(1, 5) AS x RETURN x\" 1) 1) \"x\" 2) 1) 1) (integer) 1 2) 1) (integer) 2 3) 1) (integer) 3 3) 1) \"Cached execution: 0\" 2) \"Query internal execution time: 0.445790 milliseconds\" . QUERY_MEM_CAPACITY . Setting the memory capacity of a query allows the server to kill queries that are consuming too much memory and return with the error message Query's mem consumption exceeded capacity. This helps to avoid scenarios when the server becomes unresponsive due to an unbounded query exhausting system resources. The configuration argument is the maximum number of bytes that can be allocated by any single query. Default . QUERY_MEM_CAPACITY is unlimited; this default can be restored by setting QUERY_MEM_CAPACITY to zero or a negative value. Example . $ redis-server --loadmodule ./falkordb.so QUERY_MEM_CAPACITY 1048576 // 1 megabyte limit $ redis-cli GRAPH.CONFIG SET QUERY_MEM_CAPACITY 1048576 . VKEY_MAX_ENTITY_COUNT . To lower the time Redis is blocked when replicating large graphs, FalkorDB serializes the graph in a number of virtual keys. One virtual key is created for every N graph entities, where N is the value defined by this configuration. This configuration can be set when the module loads or at runtime. Default . VKEY_MAX_ENTITY_COUNT is 100,000. CMD_INFO . An on/off toggle for the GRAPH.INFO command. Disabling this command may increase performance and lower the memory usage and these are the main reasons for it to be disabled. It’s valid values are ‘yes’ and ‘no’ (i.e., on and off). Default . CMD_INFO is yes. MAX_INFO_QUERIES . A limit for the number of previously executed queries stored in the telemetry stream. A number within the range [0, 1000] . Default . MAX_INFO_QUERIES is 10000. ",
    "url": "/configuration.html#falkordb-configuration-parameters",
    
    "relUrl": "/configuration.html#falkordb-configuration-parameters"
  },"41": {
    "doc": "Configuration Parameters",
    "title": "Query Configurations",
    "content": "Query Timeout . | Before v2.10, or if TIMEOUT_DEFAULT and TIMEOUT_MAX are not specified: . TIMEOUT allows overriding the TIMEOUT configuration parameter for a single read query. Write queries do not timeout. | Since v2.10, if either TIMEOUT_DEFAULT or TIMEOUT_MAX are specified: . TIMEOUT allows overriding the TIMEOUT_DEFAULT configuration parameter value for a single GRAPH.QUERY, GRAPH.RO_QUERY, or GRAPH.PROFILE command. The TIMEOUT value cannot exceed the TIMEOUT_MAX value (the command would abort with a (error) The query TIMEOUT parameter value cannot exceed the TIMEOUT_MAX configuration parameter value reply). | . Example . Retrieve all paths in a graph with a timeout of 500 milliseconds. GRAPH.QUERY wikipedia \"MATCH p=()-[*]-&gt;() RETURN p\" TIMEOUT 500 . EFFECTS_THRESHOLD . Replicate modification via effect when average modification time &gt; EFFECTS_THRESHOLD . Default . EFFECTS_THRESHOLD is 300 μs. Example . Assume MATCH (n) WHERE n.id &lt; 100 SET n.v = n.v + 1 updated 5 nodes and the query total execution time is 5ms, the average modification time is: total execution time / number of changes: 5ms / 5 = 1ms. if the average modification time is greater then EFFECTS_THRESHOLD the query will be replicated to both replicas and AOF as a graph effect otherwise the original query will be replicated. ",
    "url": "/configuration.html#query-configurations",
    
    "relUrl": "/configuration.html#query-configurations"
  },"42": {
    "doc": "Configuration Parameters",
    "title": "Configuration Parameters",
    "content": " ",
    "url": "/configuration.html",
    
    "relUrl": "/configuration.html"
  },"43": {
    "doc": "CREATE",
    "title": "CREATE",
    "content": "CREATE is used to introduce new nodes and relationships. The simplest example of CREATE would be a single node creation: . CREATE (n) . It’s possible to create multiple entities by separating them with a comma. CREATE (n),(m) . CREATE (:Person {name: 'Kurt', age: 27}) . To add relations between nodes, in the following example we first find an existing source node. After it’s found, we create a new relationship and destination node. GRAPH.QUERY DEMO_GRAPH \"MATCH (a:Person) WHERE a.name = 'Kurt' CREATE (a)-[:MEMBER]-&gt;(:Band {name:'Nirvana'})\" . Here the source node is a bounded node, while the destination node is unbounded. As a result, a new node is created representing the band Nirvana and a new relation connects Kurt to the band. Lastly we create a complete pattern. All entities within the pattern which are not bounded will be created. GRAPH.QUERY DEMO_GRAPH \"CREATE (jim:Person{name:'Jim', age:29})-[:FRIENDS]-&gt;(pam:Person {name:'Pam', age:27})-[:WORKS]-&gt;(:Employer {name:'Dunder Mifflin'})\" . This query will create three nodes and two relationships. ",
    "url": "/cypher/create.html",
    
    "relUrl": "/cypher/create.html"
  },"44": {
    "doc": "Cypher coverage",
    "title": "Cypher coverage",
    "content": "This document is based on the Cypher Query Language Reference (version 9), available at OpenCypher Resources. ",
    "url": "/cypher/cypher_support.html",
    
    "relUrl": "/cypher/cypher_support.html"
  },"45": {
    "doc": "Cypher coverage",
    "title": "Patterns",
    "content": "Patterns are fully supported. ",
    "url": "/cypher/cypher_support.html#patterns",
    
    "relUrl": "/cypher/cypher_support.html#patterns"
  },"46": {
    "doc": "Cypher coverage",
    "title": "Types",
    "content": "Structural types . | Nodes | Relationships | Path variables (alternating sequence of nodes and relationships). | . Composite types . | Lists | Maps . Unsupported: . | Temporal types (Date, DateTime, LocalDateTime, Time, LocalTime, Duration) | . Literal types . | Numeric types (64-bit doubles and 64-bit signed integer representations) | String literals | Booleans . Unsupported: . | Hexadecimal and octal numerics | . Other . NULL is supported as a representation of a missing or undefined value. ",
    "url": "/cypher/cypher_support.html#types",
    
    "relUrl": "/cypher/cypher_support.html#types"
  },"47": {
    "doc": "Cypher coverage",
    "title": "Comparability, equality, orderability, and equivalence",
    "content": "This is a somewhat nebulous area in Cypher itself, with a lot of edge cases. Broadly speaking, FalkorDB behaves as expected with string and numeric values. There are likely some behaviors involving the numerics NaN, -inf, inf, and possibly -0.0 that deviate from the Cypher standard. We do not support any of these properties at the type level, meaning nodes and relationships are not internally comparable. ",
    "url": "/cypher/cypher_support.html#comparability-equality-orderability-and-equivalence",
    
    "relUrl": "/cypher/cypher_support.html#comparability-equality-orderability-and-equivalence"
  },"48": {
    "doc": "Cypher coverage",
    "title": "Clauses",
    "content": "Reading Clauses . | MATCH | OPTIONAL MATCH . Unsupported: . | Label expressions | . Projecting Clauses . | RETURN | AS | WITH | UNWIND | . Reading sub-clauses . | WHERE | ORDER BY | SKIP | LIMIT | . Writing Clauses . | CREATE | DELETE . | We actually implement DETACH DELETE, the distinction being that relationships invalidated by node deletions are automatically deleted. | . | SET . Unsupported: . | REMOVE (to modify properties) . | Properties can be deleted with SET [prop] = NULL. | . | . Reading/Writing Clauses . | MERGE | CALL (procedures) . | The currently-supported procedures are listed in the Procedures documentation. | . | . Set Operations . | UNION | UNION ALL | . ",
    "url": "/cypher/cypher_support.html#clauses",
    
    "relUrl": "/cypher/cypher_support.html#clauses"
  },"49": {
    "doc": "Cypher coverage",
    "title": "Functions",
    "content": "The currently-supported functions are listed in the Functions documentation. Unsupported: . | Temporal arithmetic functions | User-defined functions | . ",
    "url": "/cypher/cypher_support.html#functions",
    
    "relUrl": "/cypher/cypher_support.html#functions"
  },"50": {
    "doc": "Cypher coverage",
    "title": "Operators",
    "content": "Mathematical operators . The currently-supported functions are listed in the mathematical operators documentation. String operators . | String operators (STARTS WITH, ENDS WITH, CONTAINS) are supported. Unsupported: . | Regex operator . | . Boolean operators . | AND | OR | NOT | XOR | . ",
    "url": "/cypher/cypher_support.html#operators",
    
    "relUrl": "/cypher/cypher_support.html#operators"
  },"51": {
    "doc": "Cypher coverage",
    "title": "Parameters",
    "content": "Parameters may be specified to allow for more flexible query construction: . CYPHER name_param = \"Niccolò Machiavelli\" birth_year_param = 1469 MATCH (p:Person {name: $name_param, birth_year: $birth_year_param}) RETURN p . The example above shows the syntax used by redis-cli to set parameters, but each FalkorDB client introduces a language-appropriate method for setting parameters, and is described in their documentation. ",
    "url": "/cypher/cypher_support.html#parameters",
    
    "relUrl": "/cypher/cypher_support.html#parameters"
  },"52": {
    "doc": "Cypher coverage",
    "title": "Non-Cypher queries",
    "content": ". | FalkorDB provides the GRAPH.EXPLAIN command to print the execution plan of a provided query. | GRAPH.DELETE will remove a graph and all Redis keys associated with it. | We do not currently provide support for queries that retrieve schemas, though the LABELS and TYPE scalar functions may be used to get a graph overview. | . ",
    "url": "/cypher/cypher_support.html#non-cypher-queries",
    
    "relUrl": "/cypher/cypher_support.html#non-cypher-queries"
  },"53": {
    "doc": "Data types",
    "title": "Graph types",
    "content": "All graph types are either structural elements of the graph or projections thereof. None can be stored as a property value. ",
    "url": "/datatypes.html#graph-types",
    
    "relUrl": "/datatypes.html#graph-types"
  },"54": {
    "doc": "Data types",
    "title": "Nodes",
    "content": "Nodes are persistent graph elements that can be connected to each other via relationships. They can have any number of labels that describe their general type. For example, a node representing London may be created with the Place and City labels and retrieved by queries using either or both of them. Nodes have sets of properties to describe all of their salient characteristics. For example, our London node may have the property set: {name: 'London', capital: True, elevation: 11}. When querying nodes, multiple labels can be specified. Only nodes that hold all specified labels will be matched: . $ redis-cli GRAPH.QUERY G \"MATCH (n:Place:Continent) RETURN n\" . ",
    "url": "/datatypes.html#nodes",
    
    "relUrl": "/datatypes.html#nodes"
  },"55": {
    "doc": "Data types",
    "title": "Relationships",
    "content": "Relationships are persistent graph elements that connect one node to another. They must have exactly one type that describes what they represent. For example, a RESIDENT_OF relationship may be used to connect a Person node to a City node. Relationships are always directed, connecting a source node to its destination. Like nodes, relationships have sets of properties to describe all of their salient characteristics. When querying relationships, multiple types can be specified when separated by types. Relationships that hold any of the specified types will be matched: . $ redis-cli GRAPH.QUERY G \"MATCH (:Person)-[r:RESIDENT_OF|:VISITOR_TO]-&gt;(:Place {name: 'London'}) RETURN r\" . ",
    "url": "/datatypes.html#relationships",
    
    "relUrl": "/datatypes.html#relationships"
  },"56": {
    "doc": "Data types",
    "title": "Paths",
    "content": "Paths are alternating sequences of nodes and edges, starting and ending with a node. They are not structural elements in the graph, but can be created and returned by queries. For example, the following query returns all paths of any length connecting the node London to the node New York: . $ redis-cli GRAPH.QUERY G \"MATCH p=(:City {name: 'London'})-[*]-&gt;(:City {name: 'New York'}) RETURN p\" . ",
    "url": "/datatypes.html#paths",
    
    "relUrl": "/datatypes.html#paths"
  },"57": {
    "doc": "Data types",
    "title": "Scalar types",
    "content": "All scalar types may be provided by queries or stored as property values on node and relationship objects. Strings . FalkorDB strings are Unicode character sequences. When using Redis with a TTY (such as invoking FalkorDB commands from the terminal via redis-cli), some code points may not be decoded, as in: . $ redis-cli GRAPH.QUERY G \"RETURN '日本人' as stringval\" 1) 1) \"stringval\" 2) 1) 1) \"\\xe6\\x97\\xa5\\xe6\\x9c\\xac\\xe4\\xba\\xba\" . Output decoding can be forced using the --raw flag: . $ redis-cli --raw GRAPH.QUERY G \"RETURN '日本人' as stringval\" stringval 日本人 . Booleans . Boolean values are specified as true or false. Internally, they are stored as numerics, with 1 representing true and 0 representing false. As FalkorDB considers types in its comparisons, 1 is not considered equal to true: . $ redis-cli GRAPH.QUERY G \"RETURN 1 = true\" 1) 1) \"1 = true\" 2) 1) 1) \"false\" . Integers . All FalkorDB integers are treated as 64-bit signed integers. Floating-point values . All FalkorDB floating-point values are treated as 64-bit signed doubles. Geospatial Points . The Point data type is a set of latitude/longitude coordinates, stored within FalkorDB as a pair of 32-bit floats. It is instantiated using the point() function call. Nulls . In FalkorDB, null is used to stand in for an unknown or missing value. Since we cannot reason broadly about unknown values, null is an important part of FalkorDB’s 3-valued truth table. For example, the comparison null = null will evaluate to null, as we lack adequate information about the compared values. Similarly, null in [1,2,3] evaluates to null, since the value we’re looking up is unknown. Unlike all other scalars, null cannot be stored as a property value. ",
    "url": "/datatypes.html#scalar-types",
    
    "relUrl": "/datatypes.html#scalar-types"
  },"58": {
    "doc": "Data types",
    "title": "Collection types",
    "content": "Arrays . Arrays are ordered lists of elements. They can be provided as literals or generated by functions like collect(). Nested arrays are supported, as are many functions that operate on arrays such as list comprehensions. Arrays can be stored as property values provided that no array element is of an unserializable type, such as graph entities or null values. Maps . Maps are order-agnostic collections of key-value pairs. If a key is a string literal, the map can be accessed using dot notation. If it is instead an expression that evaluates to a string literal, bracket notation can be used: . $ redis-cli GRAPH.QUERY G \"WITH {key1: 'stringval', key2: 10} AS map RETURN map.key1, map['key' + 2]\" 1) 1) \"map.key1\"    2) \"map['key' + 2]\" 2) 1) 1) \"stringval\"       2) (integer) 10 . This aligns with the way that the properties of nodes and relationships can be accessed. Maps cannot be stored as property values. Map projections . Maps can be constructed as projections using the syntax alias {.key1 [, ...n]}. This can provide a useful format for returning graph entities. For example, given a graph with the node (name: 'Jeff', age: 32), we can build the projection: . $ redis-cli GRAPH.QUERY G \"MATCH (n) RETURN n {.name, .age} AS projection\" 1) 1) \"projection\" 2) 1) 1) \"{name: Jeff, age: 32}\" . Function calls in map values . The values in maps and map projections are flexible, and can generally refer either to constants or computed values: . $ redis-cli GRAPH.QUERY G \"RETURN {key1: 'constant', key2: rand(), key3: toLower('GENERATED') + '_string'} AS map\" 1) 1) \"map\" 2) 1) 1) \"{key1: constant, key2: 0.889656, key3: generated_string}\" . The exception to this is aggregation functions, which must be computed in a preceding WITH clause instead of being invoked within the map. This restriction is intentional, as it helps to clearly disambiguate the aggregate function calls and the key values they are grouped by: . $ redis-cli GRAPH.QUERY G \" MATCH (follower:User)-[:FOLLOWS]-&gt;(u:User) WITH u, COUNT(follower) AS count RETURN u {.name, follower_count: count} AS user\" 1) 1) \"user\" 2) 1) 1) \"{name: Jeff, follower_count: 12}\" 2) 1) \"{name: Roi, follower_count: 18}\" . ",
    "url": "/datatypes.html#collection-types",
    
    "relUrl": "/datatypes.html#collection-types"
  },"59": {
    "doc": "Data types",
    "title": "Data types",
    "content": " ",
    "url": "/datatypes.html",
    
    "relUrl": "/datatypes.html"
  },"60": {
    "doc": "DELETE",
    "title": "DELETE",
    "content": "DELETE is used to remove both nodes and relationships. Note that deleting a node also deletes all of its incoming and outgoing relationships. To delete a node and all of its relationships: . GRAPH.QUERY DEMO_GRAPH \"MATCH (p:Person {name:'Jim'}) DELETE p\" . To delete relationship: . GRAPH.QUERY DEMO_GRAPH \"MATCH (:Person {name:'Jim'})-[r:FRIENDS]-&gt;() DELETE r\" . This query will delete all friend outgoing relationships from the node with the name ‘Jim’. ",
    "url": "/cypher/delete.html",
    
    "relUrl": "/cypher/delete.html"
  },"61": {
    "doc": "FOREACH",
    "title": "FOREACH",
    "content": "The FOREACH clause feeds the components of a list to a sub-query comprised of updating clauses only (CREATE, MERGE, SET, REMOVE, DELETE and FOREACH), while passing on the records it receives without change. The clauses within the sub-query recognize the bound variables defined prior to the FOREACH clause, but are local in the sense that later clauses are not aware of the variables defined inside them. In other words, FOREACH uses the current context, and does not affect it. The FOREACH clause can be used for numerous purposes, such as: Updating and creating graph entities in a concise manner, marking nodes\\edges that satisfy some condition or are part of a path of interest and performing conditional queries. We show examples of queries performing the above 3 use-cases. The following query will create 5 nodes, each with property v with the values from 0 to 4 corresponding to the appropriate index in the list. GRAPH.QUERY DEMO_GRAPH \"FOREACH(i in [1, 2, 3, 4] | CREATE (n:N {v: i}))\" . The following query marks the nodes of all paths of length up to 15 km from a hotel in Toronto to a steakhouse with at least 2 Michelin stars. GRAPH.QUERY DEMO_GRAPH \"MATCH p = (hotel:HOTEL {City: 'Toronto'})-[r:ROAD*..5]-&gt;(rest:RESTAURANT {type: 'Steakhouse'}) WHERE sum(r.length) &lt;= 15 AND hotel.stars &gt;= 4 AND rest.Michelin_stars &gt;= 2 FOREACH(n in nodes(p) | SET n.part_of_path = true)\" . The following query searches for all the hotels, checks whether they buy directly from a bakery, and if not - makes sure they are marked as buying from a supplier that supplies bread, and that they do not buy directly from a bakery. GRAPH.QUERY DEMO_GRAPH \"MATCH (h:HOTEL) OPTIONAL MATCH (h)-[b:BUYS_FROM]-&gt;(bakery:BAKERY) FOREACH(do_perform IN CASE WHEN b = NULL THEN [1] ELSE [] END | MERGE (h)-[b2:BUYS_FROM]-&gt;(s:SUPPLIER {supplies_bread: true}) SET b2.direct = false)\" . ",
    "url": "/cypher/foreach.html",
    
    "relUrl": "/cypher/foreach.html"
  },"62": {
    "doc": "Functions",
    "title": "Functions",
    "content": "This section contains information on all supported functions from the Cypher query language. | Predicate functions | Scalar functions | Aggregating functions | List functions | Mathematical operators | Mathematical functions | Trigonometric functions | String functions | Point functions | Type conversion functions | Node functions | Path functions | Vector functions | . ",
    "url": "/cypher/functions.html",
    
    "relUrl": "/cypher/functions.html"
  },"63": {
    "doc": "Functions",
    "title": "Predicate functions",
    "content": "| Function | Description | . | all(var IN list WHERE predicate) | Returns true when predicate holds true for all elements in list | . | any(var IN list WHERE predicate) | Returns true when predicate holds true for at least one element in list | . | exists(pattern) | Returns true when at least one match for pattern exists | . | isEmpty(list|map|string) | Returns true if the input list or map contains no elements or if the input string contains no characters Returns null when the input evaluates to null | . | none(var IN list WHERE predicate) | Returns true when predicate holds false for all elements in list | . | single(var IN list WHERE predicate) | Returns true when predicate holds true for exactly one element in list | . ",
    "url": "/cypher/functions.html#predicate-functions",
    
    "relUrl": "/cypher/functions.html#predicate-functions"
  },"64": {
    "doc": "Functions",
    "title": "Scalar functions",
    "content": "| Function | Description | . | coalesce(expr[, expr…]) | Returns the evaluation of the first argument that evaluates to a non-null value Returns null when all arguments evaluate to null | . | endNode(relationship) | Returns the destination node of a relationship Returns null when relationship evaluates to null | . | hasLabels(node, labelsList) * | Returns true when node contains all labels in labelsList, otherwise false Return true when labelsList evaluates to an empty list | . | id(node|relationship) | Returns the internal ID of a node or relationship (which is not immutable) | . | labels(node) | Returns a list of strings: all labels of node Returns null when node evaluates to null | . | properties(expr) | When expr is a node or relationship: Returns a map containing all the properties of the given node or relationship When expr evaluates to a map: Returns expr unchanged Returns null when expr evaluates to null | . | randomUUID() | Returns a random UUID (Universal Unique IDentifier) | . | startNode(relationship) | Returns the source node of a relationship Returns null when relationship evaluates to null | . | timestamp() | Returns the current system timestamp (milliseconds since epoch) | . | type(relationship) | Returns a string: the type of relationship Returns null when relationship evaluates to null | . | typeOf(expr) * | Returns a string: the type of a literal, an expression’s evaluation, an alias, a node’s property, or a relationship’s property Return value is one of Map, String, Integer, Boolean, Float, Node, Edge, List, Path, Point, or Null | . * FalkorDB-specific extensions to Cypher . ",
    "url": "/cypher/functions.html#scalar-functions",
    
    "relUrl": "/cypher/functions.html#scalar-functions"
  },"65": {
    "doc": "Functions",
    "title": "Aggregating functions",
    "content": "| Function | Description | . | avg(expr) | Returns the average of a set of numeric values. null values are ignored Returns null when expr has no evaluations | . | collect(expr) | Returns a list containing all non-null elements which evaluated from a given expression | . | count(expr|*) | When argument is expr: returns the number of non-null evaluations of expr When argument is *: returns the total number of evaluations (including nulls) | . | max(expr) | Returns the maximum value in a set of values (taking into account type ordering). null values are ignored Returns null when expr has no evaluations | . | min(expr) | Returns the minimum value in a set of values (taking into account type ordering). null values are ignored Returns null when expr has no evaluations | . | percentileCont(expr, percentile) | Returns a linear-interpolated percentile (between 0.0 and 1.0) over a set of numeric values. null values are ignored Returns null when expr has no evaluations | . | percentileDisc(expr, percentile) | Returns a nearest-value percentile (between 0.0 and 1.0) over a set of numeric values. null values are ignored Returns null when expr has no evaluations | . | stDev(expr) | Returns the sample standard deviation over a set of numeric values. null values are ignored Returns null when expr has no evaluations | . | stDevP(expr) | Returns the population standard deviation over a set of numeric values. null values are ignored Returns null when expr has no evaluations | . | sum(expr) | Returns the sum of a set of numeric values. null values are ignored Returns 0 when expr has no evaluations | . ",
    "url": "/cypher/functions.html#aggregating-functions",
    
    "relUrl": "/cypher/functions.html#aggregating-functions"
  },"66": {
    "doc": "Functions",
    "title": "List functions",
    "content": "| Function | Description | . | head(expr) | Returns the first element of a list Returns null when expr evaluates to null or an empty list | . | keys(expr) | Returns a list of strings: all key names for given map or all property names for a given node or edge Returns null when expr evaluates to null | . | last(expr) | Returns the last element of a list Returns null when expr evaluates to null or an empty list | . | list.dedup(list) * | Given a list, returns a similar list after removing duplicate elements Order is preserved, duplicates are removed from the end of the list Returns null when list evaluates to null Emit an error when list does not evaluate to a list or to null | . | list.insert(list, idx, val[, dups = TRUE]) * | Given a list, returns a list after inserting a given value at a given index idx is 0-based when non-negative, or from the end of the list when negative Returns null when list evaluates to null Returns list when val evaluates to null Returns list when idx evaluates to an integer not in [-NumItems-1 .. NumItems] When dups evaluates to FALSE: returns list when val evaluates to a value that is already an element of list Emit an error when list does not evaluate to a list or to null Emit an error when idx does not evaluate to an integer Emit an error when dups, if specified, does not evaluate to a Boolean | . | list.insertListElements(list, list2, idx[, dups = TRUE]) * | Given a list, returns a list after inserting the elements of a second list at a given index idx is 0-based when non-negative, or from the end of the list when negative Returns null when list evaluates to null Returns list when list2 evaluates to null Returns list when idx evaluates to an integer not in [-NumItems-1 .. NumItems] When dups evaluates to FALSE: If an element of list2 evaluates to an element of list it would be skipped; If multiple elements of list2 evaluate to the same value - this value would be inserted at most once to list Emit an error when list does not evaluate to a list or to null Emit an error when list2 does not evaluate to a list or to null Emit an error when idx does not evaluate to an integer Emit an error when dups, if specified, does not evaluate to a Boolean | . | list.remove(list, idx[, count = 1]) * | Given a list, returns a list after removing a given number of consecutive elements (or less, if the end of the list has been reached). starting at a given index. idx is 0-based when non-negative, or from the end of the list when negative Returns null when list evaluates to null Returns list when idx evaluates to an integer not in [-NumItems .. NumItems-1] Returns list when count evaluates to a non-positive integer Emit an error when list does not evaluate to a list or to null Emit an error when idx does not evaluate to an integer Emit an error when count, if specified, does not evaluate to an integer | . | list.sort(list[, ascending = TRUE]) * | Given a list, returns a list with similar elements, but sorted (inversely-sorted if ascending is evaluated to FALSE) Returns null when list evaluates to null Emit an error when list does not evaluate to a list or to null Emit an error when ascending, if specified, does not evaluate to a Boolean | . | range(first, last[, step = 1]) | Returns a list of integers in the range of [start, end]. step, an optional integer argument, is the increment between consecutive elements | . | size(expr) | Returns the number of elements in a list Returns null with expr evaluates to null | . | tail(expr) | Returns a sublist of a list, which contains all its elements except the first Returns an empty list when expr contains less than 2 elements. Returns null when expr evaluates to null | . | reduce(…) | Returns a scalar produced by evaluating an expression against each list member | . * FalkorDB-specific extensions to Cypher . ",
    "url": "/cypher/functions.html#list-functions",
    
    "relUrl": "/cypher/functions.html#list-functions"
  },"67": {
    "doc": "Functions",
    "title": "Mathematical operators",
    "content": "| Function | Description | . | + | Add two values | . | - | Subtract second value from first | . | * | Multiply two values | . | / | Divide first value by the second | . | ^ | Raise the first value to the power of the second | . | % | Perform modulo division of the first value by the second | . ",
    "url": "/cypher/functions.html#mathematical-operators",
    
    "relUrl": "/cypher/functions.html#mathematical-operators"
  },"68": {
    "doc": "Functions",
    "title": "Mathematical functions",
    "content": "| Function | Description | . | abs(expr) | Returns the absolute value of a numeric value Returns null when expr evaluates to null | . | ceil(expr) ** | When expr evaluates to an integer: returns its evaluation When expr evaluates to floating point: returns a floating point equals to the smallest integer greater than or equal to expr Returns null when expr evaluates to null | . | e() | Returns the constant e, the base of the natural logarithm | . | exp(expr) | Returns e^expr, where e is the base of the natural logarithm Returns null when expr evaluates to null | . | floor(expr) ** | When expr evaluates to an integer: returns its evaluation When expr evaluates to a floating point: returns a floating point equals to the greatest integer less than or equal to expr Returns null when expr evaluates to null | . | log(expr) | Returns the natural logarithm of a numeric value Returns nan when expr evaluates to a negative numeric value, -inf when expr evaluates to 0, and null when expr evaluates to null | . | log10(expr) | Returns the base-10 logarithm of a numeric value Returns nan when expr evaluates to a negative numeric value, -inf when expr evaluates to 0, and null when expr evaluates to null | . | pow(base, exponent) * | Returns base raised to the power of exponent (equivalent to base^exponent) Returns null when either evaluates to null | . | rand() | Returns a random floating point in the range [0,1] | . | round(expr) ** *** | When expr evaluates to an integer: returns its evaluation When expr evaluates to a floating point: returns a floating point equals to the integer closest to expr Returns null when expr evaluates to null | . | sign(expr) | Returns the signum of a numeric value: 0 when expr evaluates to 0, -1 when expr evaluates to a negative numeric value, and 1 when expr evaluates to a positive numeric value Returns null when expr evaluates to null | . | sqrt(expr) | Returns the square root of a numeric value Returns nan when expr evaluates to a negative value and null when expr evaluates to null | . * FalkorDB-specific extensions to Cypher . ** FalkorDB-specific behavior: to avoid possible loss of precision, when expr evaluates to an integer - the result is an integer as well . *** FalkorDB-specific behavior: tie-breaking method is “half away from zero” . ",
    "url": "/cypher/functions.html#mathematical-functions",
    
    "relUrl": "/cypher/functions.html#mathematical-functions"
  },"69": {
    "doc": "Functions",
    "title": "Trigonometric functions",
    "content": "| Function | Description | . | acos(expr) | Returns the arccosine, in radians, of a numeric value Returns nan when expr evaluates to a numeric value not in [-1, 1] and null when expr evaluates to null | . | asin(expr) | Returns the arcsine, in radians, of a numeric value Returns nan when expr evaluates to a numeric value not in [-1, 1] and null when expr evaluates to null | . | atan(expr) | Returns the arctangent, in radians, of a numeric value Returns null when expr evaluates to null | . | atan2(expr, expr) | Returns the 2-argument arctangent, in radians, of a pair of numeric values (Cartesian coordinates) Returns 0 when both expressions evaluate to 0 Returns null when either expression evaluates to null | . | cos(expr) | Returns the cosine of a numeric value that represents an angle in radians Returns null when expr evaluates to null | . | cot(expr) | Returns the cotangent of a numeric value that represents an angle in radians Returns inf when expr evaluates to 0 and null when expr evaluates to null | . | degrees(expr) | Converts a numeric value from radians to degrees Returns null when expr evaluates to null | . | haversin(expr) | Returns half the versine of a numeric value that represents an angle in radians Returns null when expr evaluates to null | . | pi() | Returns the mathematical constant pi | . | radians(expr) | Converts a numeric value from degrees to radians Returns null when expr evaluates to null | . | sin(expr) | Returns the sine of a numeric value that represents an angle in radians Returns null when expr evaluates to null | . | tan(expr) | Returns the tangent of a numeric value that represents an angle in radians Returns null when expr evaluates to null | . ",
    "url": "/cypher/functions.html#trigonometric-functions",
    
    "relUrl": "/cypher/functions.html#trigonometric-functions"
  },"70": {
    "doc": "Functions",
    "title": "String functions",
    "content": "| Function | Description | . | left(str, len) | Returns a string containing the len leftmost characters of str Returns null when str evaluates to null, otherwise emit an error if len evaluates to null | . | lTrim(str) | Returns str with leading whitespace removed Returns null when str evaluates to null | . | replace(str, search, replace) | Returns str with all occurrences of search replaced with replace Returns null when any argument evaluates to null | . | reverse(str) | Returns a string in which the order of all characters in str are reversed Returns null when str evaluates to null | . | right(str, len) | Returns a string containing the len rightmost characters of str Returns null when str evaluates to null, otherwise emit an error if len evaluates to null | . | rTrim(str) | Returns str with trailing whitespace removed Returns null when str evaluates to null | . | split(str, delimiter) | Returns a list of strings from splitting str by delimiter Returns null when any argument evaluates to null | . | string.join(strList[, delimiter = ‘’]) * | Returns a concatenation of a list of strings using a given delimiter Returns null when strList evaluates to null Returns null when delimiter, if specified, evaluates to null Emit an error when strList does not evaluate to a list or to null Emit an error when an element of strList does not evaluate to a string Emit an error when delimiter, if specified, does not evaluate to a string or to null | . | string.matchRegEx(str, regex) * | Given a string and a regular expression, returns a list of all matches and matching regions Returns an empty list when str evaluates to null Returns an empty list when regex evaluates to null Emit an error when str does not evaluate to a string or to null Emit an error when regex does not evaluate to a valid regex string or to null | . | string.replaceRegEx(str, regex, replacement) * | Given a string and a regular expression, returns a string after replacing each regex match with a given replacement Returns null when str evaluates to null Returns null when regex evaluates to null Returns null when replacement evaluates to null Emit an error when str does not evaluate to a string or to null Emit an error when regex does not evaluate to a valid regex string or to null Emit an error when replacement does not evaluate to a string or to null | . | substring(str, start[, len]) | When len is specified: returns a substring of str beginning with a 0-based index start and with length len When len is not specified: returns a substring of str beginning with a 0-based index start and extending to the end of str Returns null when str evaluates to null Emit an error when start or len evaluate to null | . | toLower(str) | Returns str in lowercase Returns null when str evaluates to null | . | toJSON(expr) * | Returns a JSON representation of a value Returns null when expr evaluates to null | . | toUpper(str) | Returns str in uppercase Returns null when str evaluates to null | . | trim(str) | Returns str with leading and trailing whitespace removed Returns null when str evaluates to null | . | size(str) | Returns the number of characters in str Returns null when str evaluates to null | . * FalkorDB-specific extensions to Cypher . ",
    "url": "/cypher/functions.html#string-functions",
    
    "relUrl": "/cypher/functions.html#string-functions"
  },"71": {
    "doc": "Functions",
    "title": "Point functions",
    "content": "| Function | Description | . | point(map) | Returns a Point representing a lat/lon coordinates | . | distance(point1, point2) | Returns the distance in meters between the two given points Returns null when either evaluates to null | . ",
    "url": "/cypher/functions.html#point-functions",
    
    "relUrl": "/cypher/functions.html#point-functions"
  },"72": {
    "doc": "Functions",
    "title": "Type conversion functions",
    "content": "| Function | Description | . | toBoolean(expr) | Returns a Boolean when expr evaluates to a Boolean Converts a string to Boolean (\"true\" (case insensitive) to true, \"false\" (case insensitive) to false, any other value to null) Converts an integer to Boolean (0 to false, any other values to true) Returns null when expr evaluates to null Emit an error on other types | . | toBooleanList(exprList) | Converts a list to a list of Booleans. Each element in the list is converted using toBooleanOrNull() | . | toBooleanOrNull(expr) | Returns a Boolean when expr evaluates to a Boolean Converts a string to Boolean (\"true\" (case insensitive) to true, \"false\" (case insensitive) to false, any other value to null) Converts an integer to Boolean (0 to false, any other values to true) Returns null when expr evaluates to null Returns null for other types | . | toFloat(expr) | Returns a floating point when expr evaluates to a floating point Converts an integer to a floating point Converts a string to a floating point or null Returns null when expr evaluates to null Emit an error on other types | . | toFloatList(exprList) | Converts a list to a list of floating points. Each element in the list is converted using toFloatOrNull() | . | toFloatOrNull(expr) | Returns a floating point when expr evaluates to a floating point Converts an integer to a floating point Converts a string to a floating point or null Returns null when expr evaluates to null Returns null for other types | . | toInteger(expr) * | Returns an integer when expr evaluates to an integer Converts a floating point to integer Converts a string to an integer or null Converts a Boolean to an integer (false to 0, true to 1) Returns null when expr evaluates to null Emit an error on other types | . | toIntegerList(exprList) * | Converts a list to a list of integer values. Each element in the list is converted using toIntegerOrNull() | . | toIntegerOrNull(expr) * | Returns an integer when expr evaluates to an integer Converts a floating point to integer Converts a string to an integer or null Converts a Boolean to an integer (false to 0, true to 1) Returns null when expr evaluates to null Returns null for other types | . | toString(expr) | Returns a string when expr evaluates to a string Converts an integer, float, Boolean, string, or point to a string representation Returns null when expr evaluates to null Emit an error on other types | . | toStringList(exprList) | Converts a list to a list of strings. Each element in the list is converted using toStringOrNull() | . | toStringOrNull(expr) | Returns a string when expr evaluates to a string Converts an integer, float, Boolean, string, or point to a string representation Returns null when expr evaluates to null Returns null for other types | . * FalkorDB-specific behavior: rounding method when converting a floating point to an integer is “toward negative infinity (floor)” . ",
    "url": "/cypher/functions.html#type-conversion-functions",
    
    "relUrl": "/cypher/functions.html#type-conversion-functions"
  },"73": {
    "doc": "Functions",
    "title": "Node functions",
    "content": "| Function | Description | . | indegree(node [, reltype …]) * indegree(node [, reltypeList]) * | When no relationship types are specified: Returns the number of node’s incoming edges When one or more relationship types are specified: Returns the number of node’s incoming edges with one of the given relationship types Return null when node evaluates to null | . | outdegree(node [, reltype …]) * outdegree(node [, reltypeList]) * | When no relationship types are specified: Returns the number of node’s outgoing edges When one or more relationship types are specified: Returns the number of node’s outgoing edges with one of the given relationship types Return null when node evaluates to null | . * FalkorDB-specific extensions to Cypher . ",
    "url": "/cypher/functions.html#node-functions",
    
    "relUrl": "/cypher/functions.html#node-functions"
  },"74": {
    "doc": "Functions",
    "title": "Path functions",
    "content": "| Function | Description | . | nodes(path) | Returns a list containing all the nodes in path Returns null if path evaluates to null | . | relationships(path) | Returns a list containing all the relationships in path Returns null if path evaluates to null | . | length(path) | Return the length (number of edges) of path Returns null if path evaluates to null | . | shortestPath(…) * | Return the shortest path that resolves the given pattern | . * FalkorDB-specific extensions to Cypher . ",
    "url": "/cypher/functions.html#path-functions",
    
    "relUrl": "/cypher/functions.html#path-functions"
  },"75": {
    "doc": "Functions",
    "title": "Vector functions",
    "content": "| Function | Description | . | vecf32(array) | Creates a new float 32 vector all elements of input array must be of type float | . | vec.euclideanDistance(vector, vector) | Returns the Euclidean distance between the two input vectors | . | vec.cosineDistance(vector, vector) | Returns the Cosine distance between the two input vectors | . List comprehensions . List comprehensions are a syntactical construct that accepts an array and produces another based on the provided map and filter directives. They are a common construct in functional languages and modern high-level languages. In Cypher, they use the syntax: . [element IN array WHERE condition | output elem] . | array can be any expression that produces an array: a literal, a property reference, or a function call. | WHERE condition is an optional argument to only project elements that pass a certain criteria. If omitted, all elements in the array will be represented in the output. | | output elem is an optional argument that allows elements to be transformed in the output array. If omitted, the output elements will be the same as their corresponding inputs. | . The following query collects all paths of any length, then for each produces an array containing the name property of every node with a rank property greater than 10: . MATCH p=()-[*]-&gt;() RETURN [node IN nodes(p) WHERE node.rank &gt; 10 | node.name] . Existential comprehension functions . The functions any(), all(), single() and none() use a simplified form of the list comprehension syntax and return a boolean value. any(element IN array WHERE condition) . They can operate on any form of input array, but are particularly useful for path filtering. The following query collects all paths of any length in which all traversed edges have a weight less than 3: . MATCH p=()-[*]-&gt;() WHERE all(edge IN relationships(p) WHERE edge.weight &lt; 3) RETURN p . Pattern comprehensions . Pattern comprehensions are a method of producing a list composed of values found by performing the traversal of a given graph pattern. The following query returns the name of a Person node and a list of all their friends’ ages: . MATCH (n:Person) RETURN n.name, [(n)-[:FRIEND_OF]-&gt;(f:Person) | f.age] . Optionally, a WHERE clause may be embedded in the pattern comprehension to filter results. In this query, all friends’ ages will be gathered for friendships that started before 2010: . MATCH (n:Person) RETURN n.name, [(n)-[e:FRIEND_OF]-&gt;(f:Person) WHERE e.since &lt; 2010 | f.age] . CASE WHEN . The case statement comes in two variants. Both accept an input argument and evaluates it against one or more expressions. The first WHEN argument that specifies a value matching the result will be accepted, and the value specified by the corresponding THEN keyword will be returned. Optionally, an ELSE argument may also be specified to indicate what to do if none of the WHEN arguments match successfully. In its simple form, there is only one expression to evaluate and it immediately follows the CASE keyword: . MATCH (n) RETURN CASE n.title WHEN 'Engineer' THEN 100 WHEN 'Scientist' THEN 80 ELSE n.privileges END . In its generic form, no expression follows the CASE keyword. Instead, each WHEN statement specifies its own expression: . MATCH (n) RETURN CASE WHEN n.age &lt; 18 THEN '0-18' WHEN n.age &lt; 30 THEN '18-30' ELSE '30+' END . Reduce . The reduce() function accepts a starting value and updates it by evaluating an expression against each element of the list: . RETURN reduce(sum = 0, n IN [1,2,3] | sum + n) . sum will successively have the values 0, 1, 3, and 6, with 6 being the output of the function call. Point . The point() function expects one map argument of the form: . RETURN point({latitude: lat_value, longitude: lon_val}) . The key names latitude and longitude are case-sensitive. The point constructed by this function can be saved as a node/relationship property or used within the query, such as in a distance function call. shortestPath . The shortestPath() function is invoked with the form: . MATCH (a {v: 1}), (b {v: 4}) RETURN shortestPath((a)-[:L*]-&gt;(b)) . The sole shortestPath argument is a traversal pattern. This pattern’s endpoints must be resolved prior to the function call, and no property filters may be introduced in the pattern. The relationship pattern may specify any number of relationship types (including zero) to be considered. If a minimum number of edges to traverse is specified, it may only be 0 or 1, while any number may be used for the maximum. If 0 is specified as the minimum, the source node will be included in the returned path. If no shortest path can be found, NULL is returned. JSON format . toJSON() returns the input value in JSON formatting. For primitive data types and arrays, this conversion is conventional. Maps and map projections (toJSON(node { .prop} )) are converted to JSON objects, as are nodes and relationships. The format for a node object in JSON is: . { \"type\": \"node\", \"id\": id(int), \"labels\": [label(string) X N], \"properties\": { property_key(string): property_value X N } } . The format for a relationship object in JSON is: . { \"type\": \"relationship\", \"id\": id(int), \"relationship\": type(string), \"properties\": { property_key(string): property_value X N } \"start\": src_node(node), \"end\": dest_node(node) } . ",
    "url": "/cypher/functions.html#vector-functions",
    
    "relUrl": "/cypher/functions.html#vector-functions"
  },"76": {
    "doc": "GRAPH.CONFIG-GET",
    "title": "GRAPH.CONFIG-GET",
    "content": "Retrieves the current value of a FalkorDB configuration parameter. FalkorDB configuration parameters are detailed here. * can be used to retrieve the value of all FalkorDB configuration parameters. 127.0.0.1:6379&gt; graph.config get * 1) 1) \"TIMEOUT\" 2) (integer) 0 2) 1) \"CACHE_SIZE\" 2) (integer) 25 3) 1) \"ASYNC_DELETE\" 2) (integer) 1 4) 1) \"OMP_THREAD_COUNT\" 2) (integer) 8 5) 1) \"THREAD_COUNT\" 2) (integer) 8 6) 1) \"RESULTSET_SIZE\" 2) (integer) -1 7) 1) \"VKEY_MAX_ENTITY_COUNT\" 2) (integer) 100000 8) 1) \"MAX_QUEUED_QUERIES\" 2) (integer) 4294967295 9) 1) \"QUERY_MEM_CAPACITY\" 2) (integer) 0 10) 1) \"DELTA_MAX_PENDING_CHANGES\" 2) (integer) 10000 11) 1) \"NODE_CREATION_BUFFER\" 2) (integer) 16384 . 127.0.0.1:6379&gt; graph.config get TIMEOUT 1) \"TIMEOUT\" 2) (integer) 0 . ",
    "url": "/commands/graph.config-get.html",
    
    "relUrl": "/commands/graph.config-get.html"
  },"77": {
    "doc": "GRAPH.CONFIG-SET",
    "title": "GRAPH.CONFIG-SET",
    "content": "Set the value of a FalkorDB configuration parameter. Values set using GRAPH.CONFIG SET are not persisted after server restart. FalkorDB configuration parameters are detailed here. Note: As detailed in the link above, not all FalkorDB configuration parameters can be set at run-time. 127.0.0.1:6379&gt; graph.config get TIMEOUT 1) \"TIMEOUT\" 2) (integer) 0 127.0.0.1:6379&gt; graph.config set TIMEOUT 10000 OK 127.0.0.1:6379&gt; graph.config get TIMEOUT 1) \"TIMEOUT\" 2) (integer) 10000 . 127.0.0.1:6379&gt; graph.config set THREAD_COUNT 10 (error) This configuration parameter cannot be set at run-time . ",
    "url": "/commands/graph.config-set.html",
    
    "relUrl": "/commands/graph.config-set.html"
  },"78": {
    "doc": "GRAPH.CONSTRAINT CREATE",
    "title": "GRAPH.CONSTRAINT CREATE",
    "content": ". syntax: | GRAPH.CONSTRAINT CREATE key MANDATORY|UNIQUE NODE label | RELATIONSHIP reltype PROPERTIES propCount prop [prop…] — . Creates a graph constraint. Examples . ",
    "url": "/commands/graph.constraint-create.html",
    
    "relUrl": "/commands/graph.constraint-create.html"
  },"79": {
    "doc": "GRAPH.CONSTRAINT CREATE",
    "title": "Introduction to constraints",
    "content": "A constraint is a rule enforced on graph nodes or relationships, used to guarantee a certain structure of the data. FalkorDB supports two types of constraints: . | Mandatory constraints | Unique constraints | . Mandatory constraints . A mandatory constraint enforces existence of given attributes for all nodes with a given label or for all edges with a given relationship-type. Consider a mandatory constraint over the attribute id of all nodes with the label Person. This constraint will enforce that any Person node in the graph has an id attribute. Any attempt to create or modify a Person node, such that the resulting node does not have an id attribute, will fail. Unique constraints . A unique constraint enforces uniqueness of values of a given set of attributes for all nodes with a given label or for all edges with a given relationship-type. I.e., no duplicates are allowed. Consider a unique constraint over the attributes: first_name and last_name of all nodes with the label Person This constraint will enforce that any combination of first_name, last_name is unique. E.g., a graph can contain the following Person nodes: . (:Person {first_name:'Frank', last_name:'Costanza'}) (:Person {first_name:'Estelle', last_name:'Costanza'}) . But trying to create a third node with first_name Frank and last_name Costanza, will issue an error and the query will fail. Notes: - A unique constraint requires the existence of an exact-match index prior to its creation. For example, trying to create a unique constraint governing attributes: `first_name` and `last_name` of nodes with label `Person` without having an exact-match index over `Person`'s `first_name` and `last_name` attributes will fail. - A unique constraint is enforced for a given node or edge only if all the constrained properties are defined (non-null). - Unique constraints are not enforced for array-valued properties. - Trying to delete an index that supports a constraint will fail. ",
    "url": "/commands/graph.constraint-create.html#introduction-to-constraints",
    
    "relUrl": "/commands/graph.constraint-create.html#introduction-to-constraints"
  },"80": {
    "doc": "GRAPH.CONSTRAINT CREATE",
    "title": "Creating a constraint",
    "content": "To create a constraint, use the GRAPH.CONSTRAINT CREATE command as follows: . GRAPH.CONSTRAINT CREATE key constraintType {NODE label | RELATIONSHIP reltype} PROPERTIES propCount prop [prop...] . ",
    "url": "/commands/graph.constraint-create.html#creating-a-constraint",
    
    "relUrl": "/commands/graph.constraint-create.html#creating-a-constraint"
  },"81": {
    "doc": "GRAPH.CONSTRAINT CREATE",
    "title": "Required arguments",
    "content": "key is key name for the graph. constraintType is the constraint type: either `MANDATORY` or `UNIQUE`. NODE label | RELATIONSHIP reltype is the graph entity type (`NODE` or `RELATIONSHIP`) and the name of the node label or relationship type on which the constraint should be enforced. propCount is the number of properties following. Valid values are between 1 and 255. prop... is a list of `propCount` property names. Notes: - Constraints are created asynchronously. The constraint creation command will reply with `PENDING` and the newly created constraint is enforced gradually on all relevant nodes or relationships. During its creation phase, a constraint's status is `UNDER CONSTRUCTION`. When all governed nodes or relationships confirm to the constraint - its status is updated to `OPERATIONAL`, otherwise, if a conflict is detected, the constraint status is updated to `FAILED` and the constraint is not enforced. The caller may try to resolve the conflict and recreate the constraint. To retrieve the status of all constraints - use the `db.constraints()` procedure. - A constraint creation command may fail synchronously due to the following reasons: 1. Syntax error 2. Constraint already exists 3. Missing supporting index (for unique constraint) In addition, a constraint creation command may fail asynchronously due to the following reasons: 1. The graph contains data which violates the constraint ",
    "url": "/commands/graph.constraint-create.html#required-arguments",
    
    "relUrl": "/commands/graph.constraint-create.html#required-arguments"
  },"82": {
    "doc": "GRAPH.CONSTRAINT CREATE",
    "title": "Return value",
    "content": "@simple-string-reply - PENDING if executed correctly and the constraint is being created asynchronously, or @error-reply otherwise. ",
    "url": "/commands/graph.constraint-create.html#return-value",
    
    "relUrl": "/commands/graph.constraint-create.html#return-value"
  },"83": {
    "doc": "GRAPH.CONSTRAINT CREATE",
    "title": "Examples",
    "content": "Creating a unique constraint for a node label . To create a unique constraint for all nodes with label Person enforcing uniqueness on the combination of values of attributes first_name and last_name, issue the following commands: . redis&gt; GRAPH.QUERY g \"CREATE INDEX FOR (p:Person) ON (p.first_name, p.last_name)\" 1) 1) \"Indices created: 2\" 2) \"Cached execution: 0\" 3) \"Query internal execution time: 25.779500 milliseconds\" redis&gt; GRAPH.CONSTRAINT CREATE g UNIQUE NODE Person PROPERTIES 2 first_name last_name PENDING . Since v2.12 indexes are constructed asynchronously. The constraint construction will start once the index is fully constructed. Creating a mandatory constraint for a relationship type . To create a mandatory constraint for all edges with relationship-type Visited, enforcing the existence of a date attribute, issue the following command: . redis&gt; GRAPH.CONSTRAINT CREATE g MANDATORY RELATIONSHIP Visited PROPERTIES 1 date PENDING . ",
    "url": "/commands/graph.constraint-create.html#examples",
    
    "relUrl": "/commands/graph.constraint-create.html#examples"
  },"84": {
    "doc": "GRAPH.CONSTRAINT CREATE",
    "title": "Deleting a constraint",
    "content": "See GRAPH.CONSTRAINT DROP . ",
    "url": "/commands/graph.constraint-create.html#deleting-a-constraint",
    
    "relUrl": "/commands/graph.constraint-create.html#deleting-a-constraint"
  },"85": {
    "doc": "GRAPH.CONSTRAINT CREATE",
    "title": "Listing constraints",
    "content": "To list all constraints enforced on a given graph, use the db.constraints procedure: . GRAPH.RO_QUERY &lt;key&gt; \"CALL db.constraints()\" . For each constraint the procedure will yield the following fields: . | Field | Description | . | type | type of constraint, either UNIQUE or MANDATORY | . | label | label or relationship-type enforced by the constraint | . | properties | list of properties enforced by the constraint | . | entitytype | type of entity, either NODE or RELATIONSHIP | . | status | either UNDER CONSTRUCTION, OPERATIONAL or FAILED | . Example: . redis&gt; GRAPH.RO_QUERY g \"call db.constraints()\" 1) 1) \"type\" 2) \"label\" 3) \"properties\" 4) \"entitytype\" 5) \"status\" 2) 1) 1) \"UNIQUE\" 2) \"Person\" 3) \"[birthdate]\" 4) \"NODE\" 5) \"UNDER CONSTRUCTION\" 2) 1) \"MANDATORY\" 2) \"Person\" 3) \"[first_name, last_name]\" 4) \"NODE\" 5) \"OPERATIONAL\" . ",
    "url": "/commands/graph.constraint-create.html#listing-constraints",
    
    "relUrl": "/commands/graph.constraint-create.html#listing-constraints"
  },"86": {
    "doc": "GRAPH.CONSTRAINT DROP",
    "title": "GRAPH.CONSTRAINT DROP",
    "content": ". syntax: | GRAPH.CONSTRAINT DROP key MANDATORY|UNIQUE NODE label | RELATIONSHIP reltype PROPERTIES propCount prop [prop…] — . Deleted a graph constraint. Examples . For an introduction to constraints see GRAPH.CONSTRAINT CREATE . ",
    "url": "/commands/graph.constraint-drop.html",
    
    "relUrl": "/commands/graph.constraint-drop.html"
  },"87": {
    "doc": "GRAPH.CONSTRAINT DROP",
    "title": "Required arguments",
    "content": "key is key name for the graph. constraintType is the constraint type: either `MANDATORY` or `UNIQUE`. NODE label | RELATIONSHIP reltype is the graph entity type (`NODE` or `RELATIONSHIP`) and the name of the node label or relationship type on which the constraint is enforced. propCount is the number of properties following. Valid values are between 1 and 255. prop... is a list of `propCount` property names. ",
    "url": "/commands/graph.constraint-drop.html#required-arguments",
    
    "relUrl": "/commands/graph.constraint-drop.html#required-arguments"
  },"88": {
    "doc": "GRAPH.CONSTRAINT DROP",
    "title": "Return value",
    "content": "@simple-string-reply - OK if executed correctly, or @error-reply otherwise. ",
    "url": "/commands/graph.constraint-drop.html#return-value",
    
    "relUrl": "/commands/graph.constraint-drop.html#return-value"
  },"89": {
    "doc": "GRAPH.CONSTRAINT DROP",
    "title": "Examples",
    "content": "To delete a unique constraint for all nodes with label Person enforcing uniqueness on the combination of values of attributes first_name and last_name, issue the following command: . redis&gt; GRAPH.CONSTRAINT DROP g UNIQUE NODE Person PROPERTIES 2 first_name last_name OK . ",
    "url": "/commands/graph.constraint-drop.html#examples",
    
    "relUrl": "/commands/graph.constraint-drop.html#examples"
  },"90": {
    "doc": "GRAPH.COPY",
    "title": "GRAPH.COPY",
    "content": "Usage: GRAPH.COPY &lt;src&gt; &lt;dest&gt; . The GRAPH.COPY command creates a copy of a graph, while the copy is performed the src graph is fully accessible. Example: . 127.0.0.1:6379&gt; keys * (empty array) 127.0.0.1:6379&gt; GRAPH.QUERY A \"CREATE (:Account {number: 516637})\" 1) 1) \"Labels added: 1\" 2) \"Nodes created: 1\" 3) \"Properties set: 1\" 4) \"Cached execution: 0\" 5) \"Query internal execution time: 0.588084 milliseconds\" 127.0.0.1:6379&gt; GRAPH.COPY A Z \"OK\" 127.0.0.1:6379&gt; keys * 1) \"Z\" 2) \"telemetry{A}\" 3) \"A\" 127.0.0.1:6379&gt; GRAPH.QUERY Z \"MATCH (a:Account) RETURN a.number\" 1) 1) \"a.number\" 2) 1) 1) (integer) 516637 3) 1) \"Cached execution: 0\" 2) \"Query internal execution time: 0.638375 milliseconds\" . ",
    "url": "/commands/graph.copy.html",
    
    "relUrl": "/commands/graph.copy.html"
  },"91": {
    "doc": "GRAPH.DELETE",
    "title": "GRAPH.DELETE",
    "content": "Completely removes the graph and all of its entities. Arguments: Graph name . Returns: String indicating if operation succeeded or failed. GRAPH.DELETE us_government . Note: To delete a node from the graph (not the entire graph), execute a MATCH query and pass the alias to the DELETE clause: . GRAPH.QUERY DEMO_GRAPH \"MATCH (x:Y {propname: propvalue}) DELETE x\" . WARNING: When you delete a node, all of the node’s incoming/outgoing relationships are also removed. ",
    "url": "/commands/graph.delete.html",
    
    "relUrl": "/commands/graph.delete.html"
  },"92": {
    "doc": "GRAPH.EXPLAIN",
    "title": "GRAPH.EXPLAIN",
    "content": "Constructs a query execution plan but does not run it. Inspect this execution plan to better understand how your query will get executed. Arguments: Graph name, Query . Returns: String representation of a query execution plan . GRAPH.EXPLAIN us_government \"MATCH (p:President)-[:BORN]-&gt;(h:State {name:'Hawaii'}) RETURN p\" . ",
    "url": "/commands/graph.explain.html",
    
    "relUrl": "/commands/graph.explain.html"
  },"93": {
    "doc": "GRAPH.INFO",
    "title": "GRAPH.INFO [Section [Section …]]",
    "content": "Returns information and statistics about the current executing commands. 127.0.0.1:6379&gt; GRAPH.INFO 1) \"# Running queries\" 2) (empty array) 3) \"# Waiting queries\" 4) (empty array) 127.0.0.1:6379&gt; GRAPH.INFO RunningQueries 1) \"# Running queries\" 2) (empty array) 127.0.0.1:6379&gt; GRAPH.INFO WaitingQueries 1) \"# Waiting queries\" 2) (empty array) . ",
    "url": "/commands/graph.info.html#graphinfo-section-section-",
    
    "relUrl": "/commands/graph.info.html#graphinfo-section-section-"
  },"94": {
    "doc": "GRAPH.INFO",
    "title": "GRAPH.INFO",
    "content": " ",
    "url": "/commands/graph.info.html",
    
    "relUrl": "/commands/graph.info.html"
  },"95": {
    "doc": "GRAPH.LIST",
    "title": "GRAPH.LIST",
    "content": "Lists all graph keys in the keyspace. 127.0.0.1:6379&gt; GRAPH.LIST 2) G 3) resources 4) players . ",
    "url": "/commands/graph.list.html",
    
    "relUrl": "/commands/graph.list.html"
  },"96": {
    "doc": "GRAPH.PROFILE",
    "title": "GRAPH.PROFILE",
    "content": "Executes a query and produces an execution plan augmented with metrics for each operation’s execution. Arguments: Graph name, Query . Returns: String representation of a query execution plan, with details on results produced by and time spent in each operation. GRAPH.PROFILE is a parallel entrypoint to GRAPH.QUERY. It accepts and executes the same queries, but it will not emit results, instead returning the operation tree structure alongside the number of records produced and total runtime of each operation. It is important to note that this blends elements of GRAPH.QUERY and GRAPH.EXPLAIN. It is not a dry run and will perform all graph modifications expected of the query, but will not output results produced by a RETURN clause or query statistics. GRAPH.PROFILE imdb \"MATCH (actor_a:Actor)-[:ACT]-&gt;(:Movie)&lt;-[:ACT]-(actor_b:Actor) WHERE actor_a &lt;&gt; actor_b CREATE (actor_a)-[:COSTARRED_WITH]-&gt;(actor_b)\" 1) \"Create | Records produced: 11208, Execution time: 168.208661 ms\" 2) \" Filter | Records produced: 11208, Execution time: 1.250565 ms\" 3) \" Conditional Traverse | Records produced: 12506, Execution time: 7.705860 ms\" 4) \" Node By Label Scan | (actor_a:Actor) | Records produced: 1317, Execution time: 0.104346 ms\" . ",
    "url": "/commands/graph.profile.html",
    
    "relUrl": "/commands/graph.profile.html"
  },"97": {
    "doc": "GRAPH.QUERY",
    "title": "GRAPH.QUERY",
    "content": "Executes the given query against a specified graph. Arguments: Graph name, Query, Timeout [optional] . Returns: Result set . Queries and Parameterized Queries . The execution plans of queries, both regular and parameterized, are cached (up to CACHE_SIZE unique queries are cached). Therefore, it is recommended to use parameterized queries when executing many queries with the same pattern but different constants. Query-level timeouts can be set as described in the configuration section. Command structure . GRAPH.QUERY graph_name \"query\" . example: . GRAPH.QUERY us_government \"MATCH (p:president)-[:born]-&gt;(:state {name:'Hawaii'}) RETURN p\" . Parametrized query structure: . GRAPH.QUERY graph_name \"CYPHER param=val [param=val ...] query\" . example: . GRAPH.QUERY us_government \"CYPHER state_name='Hawaii' MATCH (p:president)-[:born]-&gt;(:state {name:$state_name}) RETURN p\" . Query language . The syntax is based on Cypher. Most of the language is supported. See Cypher documentation. ",
    "url": "/commands/graph.query.html",
    
    "relUrl": "/commands/graph.query.html"
  },"98": {
    "doc": "GRAPH.RO_QUERY",
    "title": "GRAPH.RO_QUERY",
    "content": "Executes a given read only query against a specified graph. Arguments: Graph name, Query, Timeout [optional] . Returns: Result set for a read only query or an error if a write query was given. GRAPH.RO_QUERY us_government \"MATCH (p:president)-[:born]-&gt;(:state {name:'Hawaii'}) RETURN p\" . Query-level timeouts can be set as described in the configuration section. ",
    "url": "/commands/graph.ro_query.html",
    
    "relUrl": "/commands/graph.ro_query.html"
  },"99": {
    "doc": "GRAPH.SLOWLOG",
    "title": "GRAPH.SLOWLOG",
    "content": "Returns a list containing up to 10 of the slowest queries issued against the given graph ID. Each item in the list has the following structure: . | A Unix timestamp at which the log entry was processed. | The issued command. | The issued query. | The amount of time needed for its execution, in milliseconds. | . GRAPH.SLOWLOG graph_id 1) 1) \"1581932396\" 2) \"GRAPH.QUERY\" 3) \"MATCH (a:Person)-[:FRIEND]-&gt;(e) RETURN e.name\" 4) \"0.831\" 2) 1) \"1581932396\" 2) \"GRAPH.QUERY\" 3) \"MATCH (me:Person)-[:FRIEND]-&gt;(:Person)-[:FRIEND]-&gt;(fof:Person) RETURN fof.name\" 4) \"0.288\" . To reset a graph’s slowlog issue the following command: . GRAPH.SLOWLOG graph_id RESET . Once cleared the information is lost forever. ",
    "url": "/commands/graph.slowlog.html",
    
    "relUrl": "/commands/graph.slowlog.html"
  },"100": {
    "doc": "The FalkorDB Design",
    "title": "The FalkorDB Design",
    "content": " ",
    "url": "/design/",
    
    "relUrl": "/design/"
  },"101": {
    "doc": "The FalkorDB Design",
    "title": "Abstract",
    "content": "Graph-based data is everywhere nowadays. Facebook, Google, Twitter and Pinterest are just a few who’ve realize the power behind relationship data and are utilizing it to its fullest. As a direct result, we see a rise both in interest for and the variety of graph data solutions. With the introduction of Redis Modules we’ve recognized the great potential of introducing a graph data structure to the Redis arsenal, and developed FalkorDB. Bringing new graph capabilities to Redis through a native C implementation with an emphasis on performance, FalkorDB is now available as an open source project. In this documentation, we’ll discuss the internal design and features of FalkorDB and demonstrate its current capabilities. ",
    "url": "/design/#abstract",
    
    "relUrl": "/design/#abstract"
  },"102": {
    "doc": "The FalkorDB Design",
    "title": "FalkorDB At-a-Glance",
    "content": "FalkorDB is a graph database developed from scratch on top of Redis, using the new Redis Modules API to extend Redis with new commands and capabilities. Its main features include: . | Simple, fast indexing and querying | Data stored in RAM using memory-efficient custom data structures | On-disk persistence | Tabular result sets | Uses the popular graph query language openCypher | . ",
    "url": "/design/#falkordb-at-a-glance",
    
    "relUrl": "/design/#falkordb-at-a-glance"
  },"103": {
    "doc": "The FalkorDB Design",
    "title": "A Little Taste: FalkorDB in Action",
    "content": "Let’s look at some of the key concepts of FalkorDB using this example over the redis-cli tool: . Constructing a graph . It is common to represent entities as nodes within a graph. In this example, we’ll create a small graph with both actors and movies as its entities, and an “act” relation that will connect actors to the movies they acted in. We’ll use the graph.QUERY command to issue a CREATE query, which will introduce new entities and relations to our graph. graph.QUERY &lt;graph_id&gt; 'CREATE (:&lt;label&gt; {&lt;attribute_name&gt;:&lt;attribute_value&gt;,...})' . graph.QUERY &lt;graph_id&gt; 'CREATE (&lt;source_node_alias&gt;)-[&lt;relation&gt; {&lt;attribute_name&gt;:&lt;attribute_value&gt;,...}]-&gt;(&lt;dest_node_alias&gt;)' . We’ll construct our graph in one command: . graph.QUERY IMDB 'CREATE (aldis:actor {name: \"Aldis Hodge\", birth_year: 1986}), (oshea:actor {name: \"OShea Jackson\", birth_year: 1991}), (corey:actor {name: \"Corey Hawkins\", birth_year: 1988}), (neil:actor {name: \"Neil Brown\", birth_year: 1980}), (compton:movie {title: \"Straight Outta Compton\", genre: \"Biography\", votes: 127258, rating: 7.9, year: 2015}), (neveregoback:movie {title: \"Never Go Back\", genre: \"Action\", votes: 15821, rating: 6.4, year: 2016}), (aldis)-[:act]-&gt;(neveregoback), (aldis)-[:act]-&gt;(compton), (oshea)-[:act]-&gt;(compton), (corey)-[:act]-&gt;(compton), (neil)-[:act]-&gt;(compton)' . Querying the graph . FalkorDB exposes a subset of the openCypher graph language. Although only some language capabilities are supported, there’s enough functionality to extract valuable insights from your graphs. To execute a query, we’ll use the GRAPH.QUERY command: . GRAPH.QUERY &lt;graph_id&gt; &lt;query&gt; . Let’s execute a number of queries against our movies graph. Find the sum, max, min and avg age of the ‘Straight Outta Compton’ cast: . GRAPH.QUERY IMDB 'MATCH (a:actor)-[:act]-&gt;(m:movie {title:\"Straight Outta Compton\"}) RETURN m.title, SUM(2020-a.birth_year), MAX(2020-a.birth_year), MIN(2020-a.birth_year), AVG(2020-a.birth_year)' . FalkorDB will reply with: . 1) 1) \"m.title\" 2) \"SUM(2020-a.birth_year)\" 3) \"MAX(2020-a.birth_year)\" 4) \"MIN(2020-a.birth_year)\" 5) \"AVG(2020-a.birth_year)\" 2) 1) 1) \"Straight Outta Compton\" 2) \"135\" 3) (integer) 40 4) (integer) 29 5) \"33.75\" . | The first row is our result-set header which names each column according to the return clause. | The second row contains our query result. | . Let’s try another query. This time, we’ll find out how many movies each actor played in. GRAPH.QUERY IMDB \"MATCH (actor)-[:act]-&gt;(movie) RETURN actor.name, COUNT(movie.title) AS movies_count ORDER BY movies_count DESC\" 1) \"actor.name, movies_count\" 2) \"Aldis Hodge,2.000000\" 3) \"O'Shea Jackson,1.000000\" 4) \"Corey Hawkins,1.000000\" 5) \"Neil Brown,1.000000\" . ",
    "url": "/design/#a-little-taste-falkordb-in-action",
    
    "relUrl": "/design/#a-little-taste-falkordb-in-action"
  },"104": {
    "doc": "The FalkorDB Design",
    "title": "The Theory: Ideas behind FalkorDB",
    "content": "Representation . FalkorDB uses sparse adjacency matrices to represent graphs. As directed relationship connecting source node S to destination node T is recorded within an adjacency matrix M, by setting M’s S,T entry to 1 (M[S,T]=1). As a rule of thumb, matrix rows represent source nodes while matrix columns represent destination nodes. Every graph stored within FalkorDB has at least one matrix, referred to as THE adjacency matrix (relation-type agnostic). In addition, every relation with a type has its own dedicated matrix. Consider a graph with two relationships types: . | visits | friend | . The underlying graph data structure maintains three matrices: . | THE adjacency matrix - marking every connection within the graph | visit matrix - marking visit connections | friend matrix - marking friend connections | . A ‘visit’ relationship E that connects node A to node B, sets THE adjacency matrix at position [A,B] to 1. Also, the visit matrix V sets position V[A,B] to the corresponding relationship-id. To accommodate typed nodes, one additional matrix is allocated per label, and a label matrix is symmetric with ones along the main diagonal. Assume that node N was labeled as a Person, then the Person matrix P sets position P[N,N] to 1. This design lets FalkorDB modify its graph easily, including: . | Adding new nodes simply extends matrices, adding additional rows and columns | Adding new relationships by setting the relevant entries at the relevant matrices | Removing relationships clears relevant entries | Deleting nodes by deleting matrix row/column. | . One of the main reasons we chose to represent our graphs as sparse matrices is graph traversal. Traversal . Graph traversal is done by matrix multiplication. For example, if we wanted to find friends of friends for every node in the graph, this traversal can be expressed by FOF = F^2. F stands for the friendship relation matrix, and the result matrix FOF summarizes the traversal. The rows of the FOF represent source nodes and its columns represent friends who are two hops away: if FOF[i,j] = 1 then j is a friend of a friend of i. Algebraic expression . When a search pattern such as (N0)-[A]-&gt;(N1)-[B]-&gt;(N2)&lt;-[A]-(N3) is used as part of a query, we translate it into a set of matrix multiplications. For the given example, one possible expression would be: A * B * Transpose(A). Note that matrix multiplication is an associative and distributive operation. This gives us the freedom to choose which terms we want to multiply first (preferring terms that will produce highly sparse intermediate matrices). It also enables concurrency when evaluating an expression, e.g. we could compute AZ and BY in parallel. GraphBLAS . To perform all of these operations for sparse matrices, FalkorDB uses GraphBLAS - a standard API similar to BLAS. The current implementation uses the CSC sparse matrix format (compressed sparse columns), although the underlying format is subject to change. ",
    "url": "/design/#the-theory-ideas-behind-falkordb",
    
    "relUrl": "/design/#the-theory-ideas-behind-falkordb"
  },"105": {
    "doc": "The FalkorDB Design",
    "title": "Query language: openCypher",
    "content": "There are a number of graph query languages, so we didn’t want to reinvent the wheel. We decided to implement a subset of one of the most popular graph query languages out there: openCypher While the openCypher project provides a parser for the language, we decided to create our own parser. We used Lex as a tokenizer and Lemon to generate a C target parser. As mentioned earlier, only a subset of the language is currently supported, but we plan to continue adding new capabilities and extend FalkorDB’s openCypher capabilities. ",
    "url": "/design/#query-language-opencypher",
    
    "relUrl": "/design/#query-language-opencypher"
  },"106": {
    "doc": "The FalkorDB Design",
    "title": "Runtime: query execution",
    "content": "Let’s review the steps FalkorDB takes when executing a query. Consider this query that finds all actors who played alongside Aldis Hodge and are over 30 years old: . MATCH (aldis::actor {name:\"Aldis Hodge\"})-[:act]-&gt;(m:movie)&lt;-[:act]-(a:actor) WHERE a.age &gt; 30 RETURN m.title, a.name . FalkorDB will: . | Parse the query, and build an abstract syntax tree (AST) | Compose traversal algebraic expressions | Build filter trees | Construct an optimized query execution plan composed of: . | Filtered traverse | Conditional traverse | Filter | Project | . | Execute the plan | Populate a result set with matching entity attributes | . Filter tree . A query can filter out entities by creating predicates. In our example, we filter actors younger then 30. It’s possible to combine predicates using OR and AND keywords to form granular conditions. During runtime, the WHERE clause is used to construct a filter tree, and each node within the tree is either a condition (e.g. A &gt; B) or an operation (AND/OR). When finding candidate entities, they are passed through the tree and evaluated. ",
    "url": "/design/#runtime-query-execution",
    
    "relUrl": "/design/#runtime-query-execution"
  },"107": {
    "doc": "The FalkorDB Design",
    "title": "Benchmarks",
    "content": "Depending on the underlying hardware results may vary. However, inserting a new relationship is done in O(1). FalkorDB is able to create over 1 million nodes under half a second and form 500K relations within 0.3 of a second. ",
    "url": "/design/#benchmarks",
    
    "relUrl": "/design/#benchmarks"
  },"108": {
    "doc": "The FalkorDB Design",
    "title": "License",
    "content": "FalkorDB is published under the Server Side Public License v1 (SSPLv1). ",
    "url": "/design/#license",
    
    "relUrl": "/design/#license"
  },"109": {
    "doc": "The FalkorDB Design",
    "title": "Conclusion",
    "content": "Although FalkorDB is still a young project, it can be an alternative to other graph databases. With its subset of operations, you can use it to analyze and explore graph data. Being a Redis Module, this project is accessible from every Redis client without adjustments. It’s our intention to keep on improving and extending FalkorDB with the help of the open source community. ",
    "url": "/design/#conclusion",
    
    "relUrl": "/design/#conclusion"
  },"110": {
    "doc": "Operations",
    "title": "Operations",
    "content": "The Operations chapter provides essential guides for configuring and managing FalkorDB in production environments. These guides cover critical aspects like data persistence, replication for high availability, and setting up clusters for horizontal scalability. Table of Contents . ",
    "url": "/operations/",
    
    "relUrl": "/operations/"
  },"111": {
    "doc": "Operations",
    "title": "1. Configuring Persistence",
    "content": "Learn how to set up FalkorDB with data persistence, ensuring that your data remains intact even after server restarts. ",
    "url": "/operations/#1-configuring-persistence",
    
    "relUrl": "/operations/#1-configuring-persistence"
  },"112": {
    "doc": "Operations",
    "title": "2. Configuring Replication",
    "content": "Set up replication in FalkorDB to achieve high availability and data redundancy across multiple nodes. ",
    "url": "/operations/#2-configuring-replication",
    
    "relUrl": "/operations/#2-configuring-replication"
  },"113": {
    "doc": "Operations",
    "title": "3. Setting Up a Cluster",
    "content": "Discover how to configure a FalkorDB cluster for horizontal scalability and improved fault tolerance, distributing your data across multiple nodes. ",
    "url": "/operations/#3-setting-up-a-cluster",
    
    "relUrl": "/operations/#3-setting-up-a-cluster"
  },"114": {
    "doc": "Operations",
    "title": "4. Deploy FalkorDB to Kubernetes",
    "content": "Learn how falkorDB can be deployed on Kubernetes using Helm charts and Docker images. ",
    "url": "/operations/#4-deploy-falkordb-to-kubernetes",
    
    "relUrl": "/operations/#4-deploy-falkordb-to-kubernetes"
  },"115": {
    "doc": "Commands",
    "title": "Commands",
    "content": " ",
    "url": "/commands/",
    
    "relUrl": "/commands/"
  },"116": {
    "doc": "Commands",
    "title": "FalkorDB Features",
    "content": "FalkorDB exposes graph database functionality within Redis using the openCypher query language. Its basic commands accept openCypher queries, while additional commands are exposed for configuration or metadata retrieval. ",
    "url": "/commands/#falkordb-features",
    
    "relUrl": "/commands/#falkordb-features"
  },"117": {
    "doc": "Commands",
    "title": "FalkorDB API",
    "content": "Command details can be retrieved by filtering for the module or for a specific command, e.g., GRAPH.QUERY. The details include the syntax for the commands, where: . | Optional arguments are enclosed in square brackets, for example [timeout]. | Additional optional arguments are indicated by an ellipsis: ... | . Most commands require a graph key name as their first argument. ",
    "url": "/commands/#falkordb-api",
    
    "relUrl": "/commands/#falkordb-api"
  },"118": {
    "doc": "Management",
    "title": "Management",
    "content": "FalkorDB persistence How FalkorDB writes data to disk . ",
    "url": "/management/",
    
    "relUrl": "/management/"
  },"119": {
    "doc": "Cypher Language",
    "title": "Clauses",
    "content": "Cypher query consists of one or more clauses . | MATCH | OPTIONAL MATCH | WHERE | RETURN | ORDER BY | SKIP | LIMIT | CREATE | MERGE | DELETE | SET | WITH | UNION | UNWIND | FOREACH | CALL {} | . ",
    "url": "/cypher/#clauses",
    
    "relUrl": "/cypher/#clauses"
  },"120": {
    "doc": "Cypher Language",
    "title": "Functions",
    "content": "See list of available Functions . ",
    "url": "/cypher/#functions",
    
    "relUrl": "/cypher/#functions"
  },"121": {
    "doc": "Cypher Language",
    "title": "Procedures",
    "content": "See list of available Procedures . ",
    "url": "/cypher/#procedures",
    
    "relUrl": "/cypher/#procedures"
  },"122": {
    "doc": "Cypher Language",
    "title": "Algorithms",
    "content": "See list of available graph Algorithms . ",
    "url": "/cypher/#algorithms",
    
    "relUrl": "/cypher/#algorithms"
  },"123": {
    "doc": "Cypher Language",
    "title": "Indexing",
    "content": "See how to utilize Indexing . ",
    "url": "/cypher/#indexing",
    
    "relUrl": "/cypher/#indexing"
  },"124": {
    "doc": "Cypher Language",
    "title": "Cypher Language",
    "content": " ",
    "url": "/cypher/",
    
    "relUrl": "/cypher/"
  },"125": {
    "doc": "Home",
    "title": "FalkorDB",
    "content": ". FalkorDB is a blazing fast graph database used for low latency &amp; high throughput scenarios, under the hood it runs GraphBLAS to perform graph operations using sparse linear algebra. ",
    "url": "/#falkordb",
    
    "relUrl": "/#falkordb"
  },"126": {
    "doc": "Home",
    "title": "Primary features",
    "content": ". | Adopting the Property Graph Model | Supports OpenCypher query language with proprietary extensions | Offers Full-Text Search, Vector Similarly &amp; Numeric indexing. | Interacts via either RESP and Bolt protocols | Graphs represented as sparse adjacency matrices | . ",
    "url": "/#primary-features",
    
    "relUrl": "/#primary-features"
  },"127": {
    "doc": "Home",
    "title": "Give it a try",
    "content": "Launch an instance using docker, or use FalkorDB Clouds . docker run -p 6379:6379 -p 3000:3000 -it --rm falkordb/falkordb:latest . Once loaded you can interact with FalkorDB using any of the supported client libraries . Here we’ll use FalkorDB Python client to create a small graph representing a subset of motorcycle riders and teams taking part in the MotoGP league, once created we’ll start querying our data. from falkordb import FalkorDB # Connect to FalkorDB db = FalkorDB(host='localhost', port=6379) # Create the 'MotoGP' graph g = db.select_graph('MotoGP') # Clear out this graph in case you've run this script before. g.delete() g.query(\"\"\"CREATE (:Rider {name:'Valentino Rossi'})-[:rides]-&gt;(:Team {name:'Yamaha'}), (:Rider {name:'Dani Pedrosa'})-[:rides]-&gt;(:Team {name:'Honda'}), (:Rider {name:'Andrea Dovizioso'})-[:rides]-&gt;(:Team {name:'Ducati'})\"\"\") # Query which riders represents Yamaha? res = g.query(\"\"\"MATCH (r:Rider)-[:rides]-&gt;(t:Team) WHERE t.name = 'Yamaha' RETURN r.name\"\"\") for row in res.result_set: print(row[0]) # Prints: \"Valentino Rossi\" # Query how many riders represent team Ducati ? res = g.query(\"\"\"MATCH (r:Rider)-[:rides]-&gt;(t:Team {name:'Ducati'}) RETURN count(r)\"\"\") print(res.result_set[0][0]) # Prints: 1 . For additional demos please see visit Demos. ",
    "url": "/#give-it-a-try",
    
    "relUrl": "/#give-it-a-try"
  },"128": {
    "doc": "Home",
    "title": "Client libraries",
    "content": "Language-specific clients have been written by the community and the FalkorDB team. The full list and links can be found on the Clients page. ",
    "url": "/#client-libraries",
    
    "relUrl": "/#client-libraries"
  },"129": {
    "doc": "Home",
    "title": "Data import",
    "content": "When loading large graphs from CSV files, we recommend using falkordb-bulk-loader . ",
    "url": "/#data-import",
    
    "relUrl": "/#data-import"
  },"130": {
    "doc": "Home",
    "title": "Mailing List / Forum",
    "content": "Got questions? Please contact us at the FalkorDB forum. ",
    "url": "/#mailing-list--forum",
    
    "relUrl": "/#mailing-list--forum"
  },"131": {
    "doc": "Home",
    "title": "License",
    "content": "FalkorDB is licensed under the the Server Side Public License v1 (SSPLv1). ",
    "url": "/#license",
    
    "relUrl": "/#license"
  },"132": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "/",
    
    "relUrl": "/"
  },"133": {
    "doc": "Indexing",
    "title": "Indexing",
    "content": "FalkorDB supports single-property indexes for node labels and for relationship type. String, numeric, and geospatial data types can be indexed. ",
    "url": "/cypher/indexing.html",
    
    "relUrl": "/cypher/indexing.html"
  },"134": {
    "doc": "Indexing",
    "title": "Creating an index for a node label",
    "content": "For a node label, the index creation syntax is: . GRAPH.QUERY DEMO_GRAPH \"CREATE INDEX FOR (p:Person) ON (p.age)\" . An old syntax is also supported: . GRAPH.QUERY DEMO_GRAPH \"CREATE INDEX ON :Person(age)\" . After an index is explicitly created, it will automatically be used by queries that reference that label and any indexed property in a filter. GRAPH.EXPLAIN DEMO_GRAPH \"MATCH (p:Person) WHERE p.age &gt; 80 RETURN p\" 1) \"Results\" 2) \" Project\" 3) \" Index Scan | (p:Person)\" . This can significantly improve the runtime of queries with very specific filters. An index on :employer(name), for example, will dramatically benefit the query: . GRAPH.QUERY DEMO_GRAPH \"MATCH (:Employer {name: 'Dunder Mifflin'})-[:EMPLOYS]-&gt;(p:Person) RETURN p\" . An example of utilizing a geospatial index to find Employer nodes within 5 kilometers of Scranton are: . GRAPH.QUERY DEMO_GRAPH \"WITH point({latitude:41.4045886, longitude:-75.6969532}) AS scranton MATCH (e:Employer) WHERE distance(e.location, scranton) &lt; 5000 RETURN e\" . Geospatial indexes can currently only be leveraged with &lt; and &lt;= filters; matching nodes outside of the given radius is performed using conventional matching. ",
    "url": "/cypher/indexing.html#creating-an-index-for-a-node-label",
    
    "relUrl": "/cypher/indexing.html#creating-an-index-for-a-node-label"
  },"135": {
    "doc": "Indexing",
    "title": "Creating an index for a relationship type",
    "content": "For a relationship type, the index creation syntax is: . GRAPH.QUERY DEMO_GRAPH \"CREATE INDEX FOR ()-[f:FOLLOW]-() ON (f.created_at)\" . Then the execution plan for using the index: . GRAPH.EXPLAIN DEMO_GRAPH \"MATCH (p:Person {id: 0})-[f:FOLLOW]-&gt;(fp) WHERE 0 &lt; f.created_at AND f.created_at &lt; 1000 RETURN fp\" 1) \"Results\" 2) \" Project\" 3) \" Edge By Index Scan | [f:FOLLOW]\" 4) \" Node By Index Scan | (p:Person)\" . This can significantly improve the runtime of queries that traverse super nodes or when we want to start traverse from relationships. ",
    "url": "/cypher/indexing.html#creating-an-index-for-a-relationship-type",
    
    "relUrl": "/cypher/indexing.html#creating-an-index-for-a-relationship-type"
  },"136": {
    "doc": "Indexing",
    "title": "Deleting an index for a node label",
    "content": "For a node label, the index deletion syntax is: . GRAPH.QUERY DEMO_GRAPH \"DROP INDEX ON :Person(age)\" . ",
    "url": "/cypher/indexing.html#deleting-an-index-for-a-node-label",
    
    "relUrl": "/cypher/indexing.html#deleting-an-index-for-a-node-label"
  },"137": {
    "doc": "Indexing",
    "title": "Deleting an index for a relationship type",
    "content": "For a relationship type, the index deletion syntax is: . GRAPH.QUERY DEMO_GRAPH \"DROP INDEX ON :FOLLOW(created_at)\" . ",
    "url": "/cypher/indexing.html#deleting-an-index-for-a-relationship-type",
    
    "relUrl": "/cypher/indexing.html#deleting-an-index-for-a-relationship-type"
  },"138": {
    "doc": "Indexing",
    "title": "Full-text indexing",
    "content": "FalkorDB leverages the indexing capabilities of RediSearch to provide full-text indices through procedure calls. ",
    "url": "/cypher/indexing.html#full-text-indexing",
    
    "relUrl": "/cypher/indexing.html#full-text-indexing"
  },"139": {
    "doc": "Indexing",
    "title": "Creating a full-text index for a node label",
    "content": "To construct a full-text index on the title property of all nodes with label Movie, use the syntax: . GRAPH.QUERY DEMO_GRAPH \"CALL db.idx.fulltext.createNodeIndex('Movie', 'title')\" . More properties can be added to this index by adding their names to the above set of arguments, or using this syntax again with the additional names. GRAPH.QUERY DEMO_GRAPH \"CALL db.idx.fulltext.createNodeIndex('Person', 'firstName', 'lastName')\" . RediSearch provide 2 index configuration options: . | Language - Define which language to use for stemming text, which is adding the base form of a word to the index. This allows the query for “going” to also return results for “go” and “gone”, for example. | Stopwords - These are words that are usually so common that they do not add much information to search, but take up a lot of space and CPU time in the index. | . To construct a full-text index on the title property using German language and using custom stopwords of all nodes with label Movie, use the syntax: . GRAPH.QUERY DEMO_GRAPH \"CALL db.idx.fulltext.createNodeIndex({ label: 'Movie', language: 'German', stopwords: ['a', 'ab'] }, 'title')\" . RediSearch provide 3 additional field configuration options: . | Weight - The importance of the text in the field | Nostem - Skip stemming when indexing text | Phonetic - Enable phonetic search on the text | . To construct a full-text index on the title property with phonetic search of all nodes with label Movie, use the syntax: . GRAPH.QUERY DEMO_GRAPH \"CALL db.idx.fulltext.createNodeIndex('Movie', {field: 'title', phonetic: 'dm:en'})\" . ",
    "url": "/cypher/indexing.html#creating-a-full-text-index-for-a-node-label",
    
    "relUrl": "/cypher/indexing.html#creating-a-full-text-index-for-a-node-label"
  },"140": {
    "doc": "Indexing",
    "title": "Utilizing a full-text index for a node label",
    "content": "An index can be invoked to match any whole words contained within: . GRAPH.QUERY DEMO_GRAPH \"CALL db.idx.fulltext.queryNodes('Movie', 'Book') YIELD node RETURN node.title\" 1) 1) \"node.title\" 2) 1) 1) \"The Jungle Book\" 2) 1) \"The Book of Life\" 3) 1) \"Query internal execution time: 0.927409 milliseconds\" . This CALL clause can be interleaved with other Cypher clauses to perform more elaborate manipulations: . GRAPH.QUERY DEMO_GRAPH \"CALL db.idx.fulltext.queryNodes('Movie', 'Book') YIELD node AS m WHERE m.genre = 'Adventure' RETURN m ORDER BY m.rating\" 1) 1) \"m\" 2) 1) 1) 1) 1) \"id\" 2) (integer) 1168 2) 1) \"labels\" 2) 1) \"Movie\" 3) 1) \"properties\" 2) 1) 1) \"genre\" 2) \"Adventure\" 2) 1) \"rating\" 2) \"7.6\" 3) 1) \"votes\" 2) (integer) 151342 4) 1) \"year\" 2) (integer) 2016 5) 1) \"title\" 2) \"The Jungle Book\" 3) 1) \"Query internal execution time: 0.226914 milliseconds\" . In addition to yielding matching nodes, full-text index scans will return the score of each node. This is the TF-IDF score of the node, which is informed by how many times the search terms appear in the node and how closely grouped they are. This can be observed in the example: . GRAPH.QUERY DEMO_GRAPH \"CALL db.idx.fulltext.queryNodes('Node', 'hello world') YIELD node, score RETURN score, node.val\" 1) 1) \"score\" 2) \"node.val\" 2) 1) 1) \"2\" 2) \"hello world\" 2) 1) \"1\" 2) \"hello to a different world\" 3) 1) \"Cached execution: 1\" 2) \"Query internal execution time: 0.335401 milliseconds\" . ",
    "url": "/cypher/indexing.html#utilizing-a-full-text-index-for-a-node-label",
    
    "relUrl": "/cypher/indexing.html#utilizing-a-full-text-index-for-a-node-label"
  },"141": {
    "doc": "Indexing",
    "title": "Deleting a full-text index for a node label",
    "content": "For a node label, the full-text index deletion syntax is: . GRAPH.QUERY DEMO_GRAPH \"CALL db.idx.fulltext.drop('Movie')\" . ",
    "url": "/cypher/indexing.html#deleting-a-full-text-index-for-a-node-label",
    
    "relUrl": "/cypher/indexing.html#deleting-a-full-text-index-for-a-node-label"
  },"142": {
    "doc": "Indexing",
    "title": "Vector indexing",
    "content": "With the introduction of the vector data-type a new type of index was introduced. A vector index is a dedicated index for indexing and searching through vectors. To create this type of index use the following syntax: . CREATE VECTOR INDEX FOR &lt;entity_pattern&gt; ON &lt;entity_attribute&gt; OPTIONS &lt;options&gt; . The options are: . { dimension: INT, // Requiered, length of the vector to be indexed similarityFunction: STRING, // Requiered, currently only euclidean or cosine are allowed M: INT, // Optional, maximum number of outgoing edges per node. default 16 efConstruction: INT, // Optional, number of candidates during construction. default 200 efRuntime: INT // Optional, number of candidates during search. default 10 } . For example, to create a vector index over all Product nodes description attribute use the following syntax: . CREATE VECTOR INDEX FOR (p:Product) ON (p.description) OPTIONS {dimension:128, similarityFunction:'euclidean'} . Similarly to create a vector index over all Call relationships summary attribute use the following syntax: . CREATE VECTOR INDEX FOR ()-[e:Call]-&gt;() ON (e.summary) OPTIONS {dimension:128, similarityFunction:'euclidean'} . Please note, when creating a vector index, both the vector dimension and similarity function must be provided. At the moment the only supported similarity function is ‘euclidean’. ",
    "url": "/cypher/indexing.html#vector-indexing",
    
    "relUrl": "/cypher/indexing.html#vector-indexing"
  },"143": {
    "doc": "Indexing",
    "title": "Inserting vectors",
    "content": "To create a new vector use the vecf32 function as follows: . CREATE (p: Product {description: vecf32([2.1, 0.82, 1.3])}) . The above query creates a new Product node with a description attribute containing a vector. ",
    "url": "/cypher/indexing.html#inserting-vectors",
    
    "relUrl": "/cypher/indexing.html#inserting-vectors"
  },"144": {
    "doc": "Indexing",
    "title": "Query vector index",
    "content": "Vector indices are used to search for similar vectors to a given query vector using the similarity function as a measure of “distance”. To query the index use either db.idx.vector.queryNodes for node retrieval or db.idx.vector.queryRelationships for relationships. CALL db.idx.vector.queryNodes( label: STRING, attribute: STRING, k: INTEGER, query: VECTOR ) YIELD node, score . CALL db.idx.vector.queryRelationships( relationshipType: STRING, attribute: STRING, k: INTEGER, query: VECTOR ) YIELD relationship, score . To query up to 10 similar Product descriptions to a given query description vector issue the following procedure call: . CALL db.idx.vector.queryNodes( 'Product', 'description', 10, vecf32(&lt;array_of_vector_elements&gt;), ) YIELD node . The procedure can yield both the indexed entity assigned to the found similar vector in addition to a similarity score of that entity. ",
    "url": "/cypher/indexing.html#query-vector-index",
    
    "relUrl": "/cypher/indexing.html#query-vector-index"
  },"145": {
    "doc": "Indexing",
    "title": "Deleting a vector index",
    "content": "To remove a vector index, simply issue the drop index command as follows: . DROP VECTOR INDEX FOR &lt;entity_pattern&gt; (&lt;entity_attribute&gt;) . For example, to drop the vector index over Product description, invoke: . DROP VECTOR INDEX FOR (p:Product) ON (p.description) . ",
    "url": "/cypher/indexing.html#deleting-a-vector-index",
    
    "relUrl": "/cypher/indexing.html#deleting-a-vector-index"
  },"146": {
    "doc": "Kubernetes support",
    "title": "Kubernetes support for FalkorDB",
    "content": "FalkorDB can be deployed on Kubernetes using Helm charts and Docker images. This guide will walk you through the process. ",
    "url": "/operations/k8s_support.html#kubernetes-support-for-falkordb",
    
    "relUrl": "/operations/k8s_support.html#kubernetes-support-for-falkordb"
  },"147": {
    "doc": "Kubernetes support",
    "title": "Prerequisites",
    "content": "Before you begin, make sure you have Helm installed on your Kubernetes cluster. To deploy FalkorDB to Kubernetes we need to use: . | Helm charts | Docker image | . And follow these steps: . ",
    "url": "/operations/k8s_support.html#prerequisites",
    
    "relUrl": "/operations/k8s_support.html#prerequisites"
  },"148": {
    "doc": "Kubernetes support",
    "title": "Step 1: Create a values.yaml File",
    "content": "Create a values.yaml file with the following content: . image: registry: docker.io repository: falkordb/falkordb tag: \"4.0\" master: extraFlags: - \"--loadmodule /FalkorDB/bin/linux-x64-release/src/falkordb.so\" replica: extraFlags: - \"--loadmodule /FalkorDB/bin/linux-x64-release/src/falkordb.so\" . This file specify the FalkorDB image(you can choose different tags) and configure the master and slave to load the FalkorDB module. For additional configurations see the official Helm chart documentation . ",
    "url": "/operations/k8s_support.html#step-1-create-a-valuesyaml-file",
    
    "relUrl": "/operations/k8s_support.html#step-1-create-a-valuesyaml-file"
  },"149": {
    "doc": "Kubernetes support",
    "title": "Step 2: Install FalkorDB Helm Charts",
    "content": "Install the helm charts using the following command: . helm install -f values.yaml my-falkordb oci://registry-1.docker.io/bitnamicharts/redis . This command deploys FalkorDB with the configuration from values.yaml. After running this command, instructions on how to connect to the FalkorDB server will be displayed. ",
    "url": "/operations/k8s_support.html#step-2-install-falkordb-helm-charts",
    
    "relUrl": "/operations/k8s_support.html#step-2-install-falkordb-helm-charts"
  },"150": {
    "doc": "Kubernetes support",
    "title": "Step 3: Retrieve the FalkorDB Password",
    "content": "To connect to FalkorDB, you need the Redis password. Retrieve it using the following command: . export REDIS_PASSWORD=$(kubectl get secret --namespace default my-release-redis -o jsonpath=\"{.data.redis-password}\" | base64 -d) . ",
    "url": "/operations/k8s_support.html#step-3-retrieve-the-falkordb-password",
    
    "relUrl": "/operations/k8s_support.html#step-3-retrieve-the-falkordb-password"
  },"151": {
    "doc": "Kubernetes support",
    "title": "Step 4: Enable External Connections",
    "content": "In a new terminal, run the following command to port-forward to the FalkorDB server, allowing external connections: . kubectl port-forward --namespace default svc/my-falkordb-redis-master 6379:6379 . ",
    "url": "/operations/k8s_support.html#step-4-enable-external-connections",
    
    "relUrl": "/operations/k8s_support.html#step-4-enable-external-connections"
  },"152": {
    "doc": "Kubernetes support",
    "title": "Step 5: Connect to FalkorDB Using redis-cli",
    "content": "You can now connect to FalkorDB using redis-cli with the following command: . REDISCLI_AUTH=\"$REDIS_PASSWORD\" redis-cli -h 127.0.0.1 -p 6379 . ",
    "url": "/operations/k8s_support.html#step-5-connect-to-falkordb-using-redis-cli",
    
    "relUrl": "/operations/k8s_support.html#step-5-connect-to-falkordb-using-redis-cli"
  },"153": {
    "doc": "Kubernetes support",
    "title": "Step 6: Run a Simple Cypher Query",
    "content": "To test your FalkorDB installation, run a simple Cypher query: . GRAPH.QUERY mygraph \"UNWIND range(1, 10) AS i RETURN i\" . The output should resemble the following: . 127.0.0.1:6379&gt; GRAPH.QUERY mygraph \"UNWIND range(1, 10) AS i RETURN i\" 1) 1) \"i\" 2) 1) 1) (integer) 1 2) 1) (integer) 2 3) 1) (integer) 3 4) 1) (integer) 4 5) 1) (integer) 5 6) 1) (integer) 6 7) 1) (integer) 7 8) 1) (integer) 8 9) 1) (integer) 9 10) 1) (integer) 10 3) 1) \"Cached execution: 0\" 2) \"Query internal execution time: 0.290600 milliseconds\" . In summary, this guide provides steps for deploying FalkorDB on Kubernetes using Helm charts and Docker images. It covers the creation of a values.yaml file for configuration, Helm chart installation, password retrieval, enabling external connections, connecting to FalkorDB with redis-cli, and running a basic Cypher query for verification. We hope this documentation helped you to set up FalkorDB in your Kubernetes environment. If you have any questions or encounter any issues during the process, please don’t hesitate to reach out for assistance. Thank you for choosing FalkorDB! . ",
    "url": "/operations/k8s_support.html#step-6-run-a-simple-cypher-query",
    
    "relUrl": "/operations/k8s_support.html#step-6-run-a-simple-cypher-query"
  },"154": {
    "doc": "Kubernetes support",
    "title": "Kubernetes support",
    "content": " ",
    "url": "/operations/k8s_support.html",
    
    "relUrl": "/operations/k8s_support.html"
  },"155": {
    "doc": "Known limitations",
    "title": "Known limitations",
    "content": " ",
    "url": "/cypher/known_limitations.html",
    
    "relUrl": "/cypher/known_limitations.html"
  },"156": {
    "doc": "Known limitations",
    "title": "Relationship uniqueness in patterns",
    "content": "When a relation in a match pattern is not referenced elsewhere in the query, FalkorDB will only verify that at least one matching relation exists (rather than operating on every matching relation). In some queries, this will cause unexpected behaviors. Consider a graph with 2 nodes and 2 relations between them: . CREATE (a)-[:e {val: '1'}]-&gt;(b), (a)-[:e {val: '2'}]-&gt;(b) . Counting the number of explicit edges returns 2, as expected. MATCH (a)-[e]-&gt;(b) RETURN COUNT(e) . However, if we count the nodes in this pattern without explicitly referencing the relation, we receive a value of 1. MATCH (a)-[e]-&gt;(b) RETURN COUNT(b) . We are researching designs that resolve this problem without negatively impacting performance. As a temporary workaround, queries that must operate on every relation matching a pattern should explicitly refer to that relation’s alias elsewhere in the query. Two options for this are: . MATCH (a)-[e]-&gt;(b) WHERE ID(e) &gt;= 0 RETURN COUNT(b) MATCH (a)-[e]-&gt;(b) RETURN COUNT(b), e.dummyval . ",
    "url": "/cypher/known_limitations.html#relationship-uniqueness-in-patterns",
    
    "relUrl": "/cypher/known_limitations.html#relationship-uniqueness-in-patterns"
  },"157": {
    "doc": "Known limitations",
    "title": "LIMIT clause does not affect eager operations",
    "content": "When a WITH or RETURN clause introduces a LIMIT value, this value ought to be respected by all preceding operations. For example, given the query: . UNWIND [1,2,3] AS value CREATE (a {property: value}) RETURN a LIMIT 1 . One node should be created with its ‘property’ set to 1. FalkorDB will currently create three nodes, and only return the first. This limitation affects all eager operations: CREATE, SET, DELETE, MERGE, and projections with aggregate functions. ",
    "url": "/cypher/known_limitations.html#limit-clause-does-not-affect-eager-operations",
    
    "relUrl": "/cypher/known_limitations.html#limit-clause-does-not-affect-eager-operations"
  },"158": {
    "doc": "Known limitations",
    "title": "Indexing limitations",
    "content": "One way in which FalkorDB will optimize queries is by introducing index scans when a filter is specified on an indexed label-property pair. The current index implementation, however, does not handle not-equal (&lt;&gt;) filters. To profile a query and see whether index optimizations have been introduced, use the GRAPH.EXPLAIN endpoint: . $ redis-cli GRAPH.EXPLAIN social \"MATCH (p:person) WHERE p.id &lt; 5 RETURN p\" 1) \"Results\" 2) \" Project\" 3) \" Index Scan | (p:person)\" . ",
    "url": "/cypher/known_limitations.html#indexing-limitations",
    
    "relUrl": "/cypher/known_limitations.html#indexing-limitations"
  },"159": {
    "doc": "LIMIT",
    "title": "LIMIT",
    "content": "Although not mandatory, you can use the limit clause to limit the number of records returned by a query: . LIMIT &lt;max records to return&gt; . If not specified, there’s no limit to the number of records returned by a query. ",
    "url": "/cypher/limit.html",
    
    "relUrl": "/cypher/limit.html"
  },"160": {
    "doc": "LLM frameworks support",
    "title": "LLM frameworks support",
    "content": "We are working on adding support for FalkorDB in most of the LLM frameworks including: . | GraphRAG-SDK - Facilitate the creation of graph-based Retrieval-Augmented Generation (RAG), seamless integration with OpenAI to enable advanced data querying and knowledge graph construction. | LlamaIndex - FalkorDB Graph Store | LangChain - FalkorDBQAChain | . ",
    "url": "/llm_support.html",
    
    "relUrl": "/llm_support.html"
  },"161": {
    "doc": "MATCH",
    "title": "MATCH",
    "content": "Match describes the relationship between queried entities, using ascii art to represent pattern(s) to match against. Nodes are represented by parentheses (), and Relationships are represented by brackets []. Each graph entity node/relationship can contain an alias and a label/relationship type, but both can be left empty if necessary. Entity structure: alias:label {filters}. Alias, label/relationship type, and filters are all optional. Example: . (a:Actor)-[:ACT]-&gt;(m:Movie {title:\"straight outta compton\"}) . a is an alias for the source node, which we’ll be able to refer to at different places within our query. Actor is the label under which this node is marked. ACT is the relationship type. m is an alias for the destination node. Movie destination node is of “type” movie. {title:\"straight outta compton\"} requires the node’s title attribute to equal “straight outta compton”. In this example, we’re interested in actor entities which have the relation “act” with the entity representing the “straight outta compton” movie. It is possible to describe broader relationships by composing a multi-hop query such as: . (me {name:'swilly'})-[:FRIENDS_WITH]-&gt;()-[:FRIENDS_WITH]-&gt;(foaf) . Here we’re interested in finding out who my friends’ friends are. Nodes can have more than one relationship coming in or out of them, for instance: . (me {name:'swilly'})-[:VISITED]-&gt;(c:Country)&lt;-[:VISITED]-(friend)&lt;-[:FRIENDS_WITH]-(me) . Here we’re interested in knowing which of my friends have visited at least one country I’ve been to. ",
    "url": "/cypher/match.html",
    
    "relUrl": "/cypher/match.html"
  },"162": {
    "doc": "MATCH",
    "title": "Variable length relationships",
    "content": "Nodes that are a variable number of relationship→node hops away can be found using the following syntax: . -[:TYPE*minHops..maxHops]-&gt; . TYPE, minHops and maxHops are all optional and default to type agnostic, 1 and infinity, respectively. When no bounds are given the dots may be omitted. The dots may also be omitted when setting only one bound and this implies a fixed length pattern. Example: . GRAPH.QUERY DEMO_GRAPH \"MATCH (charlie:Actor { name: 'Charlie Sheen' })-[:PLAYED_WITH*1..3]-&gt;(colleague:Actor) RETURN colleague\" . Returns all actors related to ‘Charlie Sheen’ by 1 to 3 hops. ",
    "url": "/cypher/match.html#variable-length-relationships",
    
    "relUrl": "/cypher/match.html#variable-length-relationships"
  },"163": {
    "doc": "MATCH",
    "title": "Bidirectional path traversal",
    "content": "If a relationship pattern does not specify a direction, it will match regardless of which node is the source and which is the destination: . -[:TYPE]- . Example: . GRAPH.QUERY DEMO_GRAPH \"MATCH (person_a:Person)-[:KNOWS]-(person_b:Person) RETURN person_a, person_b\" . Returns all pairs of people connected by a KNOWS relationship. Note that each pair will be returned twice, once with each node in the person_a field and once in the person_b field. The syntactic sugar (person_a)&lt;-[:KNOWS]-&gt;(person_b) will return the same results. The bracketed edge description can be omitted if all relations should be considered: (person_a)--(person_b). ",
    "url": "/cypher/match.html#bidirectional-path-traversal",
    
    "relUrl": "/cypher/match.html#bidirectional-path-traversal"
  },"164": {
    "doc": "MATCH",
    "title": "Named paths",
    "content": "Named path variables are created by assigning a path in a MATCH clause to a single alias with the syntax: MATCH named_path = (path)-[to]-&gt;(capture) . The named path includes all entities in the path, regardless of whether they have been explicitly aliased. Named paths can be accessed using designated built-in functions or returned directly if using a language-specific client. Example: . GRAPH.QUERY DEMO_GRAPH \"MATCH p=(charlie:Actor { name: 'Charlie Sheen' })-[:PLAYED_WITH*1..3]-&gt;(:Actor) RETURN nodes(p) as actors\" . This query will produce all the paths matching the pattern contained in the named path p. All of these paths will share the same starting point, the actor node representing Charlie Sheen, but will otherwise vary in length and contents. Though the variable-length traversal and (:Actor) endpoint are not explicitly aliased, all nodes and edges traversed along the path will be included in p. In this case, we are only interested in the nodes of each path, which we’ll collect using the built-in function nodes(). The returned value will contain, in order, Charlie Sheen, between 0 and 2 intermediate nodes, and the unaliased endpoint. ",
    "url": "/cypher/match.html#named-paths",
    
    "relUrl": "/cypher/match.html#named-paths"
  },"165": {
    "doc": "MATCH",
    "title": "All shortest paths",
    "content": "The allShortestPaths function returns all the shortest paths between a pair of entities. allShortestPaths() is a MATCH mode in which only the shortest paths matching all criteria are captured. Both the source and the target nodes must be bound in an earlier WITH-demarcated scope to invoke allShortestPaths(). | A minimal length (must be 1) and maximal length (must be at least 1) for the search may be specified. Zero or more relationship types may be specified (e.g. [:R | Q*1..3]). No property filters may be introduced in the pattern. | . allShortestPaths() can have any number of hops for its minimum and maximum, including zero. This number represents how many edges can be traversed in fulfilling the pattern, with a value of 0 entailing that the source node will be included in the returned path. Filters on properties are supported, and any number of labels may be specified. Example: . GRAPH.QUERY DEMO_GRAPH \"MATCH (charlie:Actor {name: 'Charlie Sheen'}), (kevin:Actor {name: 'Kevin Bacon'}) WITH charlie, kevin MATCH p=allShortestPaths((charlie)-[:PLAYED_WITH*]-&gt;(kevin)) RETURN nodes(p) as actors\" . This query will produce all paths of the minimum length connecting the actor node representing Charlie Sheen to the one representing Kevin Bacon. There are several 2-hop paths between the two actors, and all of these will be returned. The computation of paths then terminates, as we are not interested in any paths of length greater than 2. ",
    "url": "/cypher/match.html#all-shortest-paths",
    
    "relUrl": "/cypher/match.html#all-shortest-paths"
  },"166": {
    "doc": "MATCH",
    "title": "Single-Pair minimal-weight bounded-cost bounded-length paths",
    "content": "The algo.SPpaths procedure returns one, n, or all minimal-weight, [optionally] bounded-cost, [optionally] bounded-length distinct paths between a pair of entities. Each path is a sequence of distinct nodes connected by distinct edges. algo.SPpaths() is a MATCH mode in which only the paths matching all criteria are captured. Both the source and the target nodes must be bound in an earlier WITH-demarcated scope to invoke algo.SPpaths(). Input arguments: . | A map containing: . | sourceNode: Mandatory. Must be of type node | targetNode: Mandatory. Must be of type node | relTypes: Optional. Array of zero or more relationship types. A relationship must have one of these types to be part of the path. If not specified or empty: the path may contain any relationship. | relDirection: Optional. string. one of 'incoming', 'outgoing', 'both'. If not specified: 'outgoing'. | pathCount: Optional. Number of minimal-weight paths to retrieve. Non-negative integer. If not specified: 1 . | 0: retrieve all minimal-weight paths (all reported paths have the same weight) . Order: 1st : minimal cost, 2nd: minimal length. | 1: retrieve a single minimal-weight path . When multiple equal-weight paths exist: (preferences: 1st : minimal cost, 2nd: minimal length) . | n &gt; 1: retrieve up to n minimal-weight paths (reported paths may have different weights) . When multiple equal-weight paths exist: (preferences: 1st : minimal cost, 2nd: minimal length) . | . | weightProp: Optional. If not specified: use the default weight: 1 for each relationship. The name of the property that represents the weight of each relationship (integer / float) . If such property doesn’t exist, of if its value is not a positive numeric - use the default weight: 1 . Note: when all weights are equal: minimal-weight ≡ shortest-path. | costProp: Optional. If not specified: use the default cost: 1 for each relationship. The name of the property that represents the cost of each relationship (integer / float) . If such property doesn’t exist, or if its value is not a positive numeric - use the default cost: 1 . | maxLen: Optional. Maximal path length (number of relationships along the path). Positive integer. If not specified: no maximal length constraint. | maxCost: Optional. Positive numeric. If not specified: no maximal cost constraint. The maximal cumulative cost for the relationships along the path. | . | . Result: . | Paths conforming to the input arguments. For each reported path: . | path - the path . | pathWeight - the path’s weight . | pathCost - the path’s cost . | . To retrieve additional information: . | The path’s length can be retrieved with length(path) . | An array of the nodes along the path can be retrieved with nodes(path) . | The path’s first node can be retrieved with nodes(path)[0] . | The path’s last node can be retrieved with nodes(path)[-1] . | An array of the relationship’s costs along the path can be retrieved with [r in relationships(path) | r.cost] where cost is the name of the cost property . | An array of the relationship’s weights along the path can be retrieved with [r in relationships(path) | r.weight] where weight is the name of the weight property . | . | . Behavior in presence on multiple-edges: . | multi-edges are two or more edges connecting the same pair of vertices (possibly with different weights and costs). | All matching edges are considered. Paths with identical vertices and different edges are different paths. The following are 3 different paths (‘n1’, ‘n2’, and ‘n3’ are nodes; ‘e1’, ‘e2’, ‘e3’, and ‘e4’ are edges): (n1)-[e1]-(n2)-[e2]-(n3), (n1)-[e1]-(n2)-[e3]-(n3), (n1)-[e4]-(n2)-[e3]-(n3) . | . Example: . GRAPH.QUERY DEMO_GRAPH \"MATCH (s:Actor {name: 'Charlie Sheen'}), (t:Actor {name: 'Kevin Bacon'}) CALL algo.SPpaths( {sourceNode: s, targetNode: t, relTypes: ['r1', 'r2', 'r3'], relDirection: 'outgoing', pathCount: 1, weightProp: 'weight', costProp: 'cost', maxLen: 3, maxCost: 100} ) YIELD path, pathCost, pathWeight RETURN path ORDER BY pathCost\" . ",
    "url": "/cypher/match.html#single-pair-minimal-weight-bounded-cost-bounded-length-paths",
    
    "relUrl": "/cypher/match.html#single-pair-minimal-weight-bounded-cost-bounded-length-paths"
  },"167": {
    "doc": "MATCH",
    "title": "Single-Source minimal-weight bounded-cost bounded-length paths",
    "content": "The algo.SSpaths procedure returns one, n, or all minimal-weight, [optionally] bounded-cost, [optionally] bounded-length distinct paths from a given entity. Each path is a sequence of distinct nodes connected by distinct edges. algo.SSpaths() is a MATCH mode in which only the paths matching all criteria are captured. The source node must be bound in an earlier WITH-demarcated scope to invoke algo.SSpaths(). Input arguments: . | A map containing: . | sourceNode: Mandatory. Must be of type node | relTypes: Optional. Array of zero or more relationship types. A relationship must have one of these types to be part of the path. If not specified or empty: the path may contain any relationship. | relDirection: Optional. string. one of 'incoming', 'outgoing', 'both'. If not specified: 'outgoing'. | pathCount: Optional. Number of minimal-weight paths to retrieve. Non-negative integer. If not specified: 1 . This number is global (not per source-target pair); all returned paths may be with the same target. | 0: retrieve all minimal-weight paths (all reported paths have the same weight) . Order: 1st : minimal cost, 2nd: minimal length. | 1: retrieve a single minimal-weight path . When multiple equal-weight paths exist: (preferences: 1st : minimal cost, 2nd: minimal length) . | n &gt; 1: retrieve up to n minimal-weight paths (reported paths may have different weights) . When multiple equal-weight paths exist: (preferences: 1st : minimal cost, 2nd: minimal length) . | . | weightProp: Optional. If not specified: use the default weight: 1 for each relationship. The name of the property that represents the weight of each relationship (integer / float) . If such property doesn’t exist, of if its value is not a positive numeric - use the default weight: 1 . Note: when all weights are equal: minimal-weight ≡ shortest-path. | costProp: Optional. If not specified: use the default cost: 1 for each relationship. The name of the property that represents the cost of each relationship (integer / float) . If such property doesn’t exist, or if its value is not a positive numeric - use the default cost: 1 . | maxLen: Optional. Maximal path length (number of relationships along the path). Positive integer. If not specified: no maximal length constraint. | maxCost: Optional. Positive numeric. If not specified: no maximal cost constraint. The maximal cumulative cost for the relationships along the path. | . | . Result: . | Paths conforming to the input arguments. For each reported path: . | path - the path | pathWeight - the path’s weight | pathCost - the path’s cost | . To retrieve additional information: . | The path’s length can be retrieved with length(path) | An array of the nodes along the path can be retrieved with nodes(path) | The path’s first node can be retrieved with nodes(path)[0] | The path’s last node can be retrieved with nodes(path)[-1] | An array of the relationship’s costs along the path can be retrieved with [r in relationships(path) | r.cost] where cost is the name of the cost property | An array of the relationship’s weights along the path can be retrieved with [r in relationships(path) | r.weight] where weight is the name of the weight property | . | . ",
    "url": "/cypher/match.html#single-source-minimal-weight-bounded-cost-bounded-length-paths",
    
    "relUrl": "/cypher/match.html#single-source-minimal-weight-bounded-cost-bounded-length-paths"
  },"168": {
    "doc": "MATCH",
    "title": "Behavior in presence on multiple-edges:",
    "content": ". | multi-edges are two or more edges connecting the same pair of vertices (possibly with different weights and costs). | All matching edges are considered. Paths with identical vertices and different edges are different paths. The following are 3 different paths (‘n1’, ‘n2’, and ‘n3’ are nodes; ‘e1’, ‘e2’, ‘e3’, and ‘e4’ are edges): (n1)-[e1]-(n2)-[e2]-(n3), (n1)-[e1]-(n2)-[e3]-(n3), (n1)-[e4]-(n2)-[e3]-(n3) | . Example: . GRAPH.QUERY DEMO_GRAPH \"MATCH (s:Actor {name: 'Charlie Sheen'}) CALL algo.SSpaths( {sourceNode: s, relTypes: ['r1', 'r2', 'r3'], relDirection: 'outgoing', pathCount: 1, weightProp: 'weight', costProp: 'cost', maxLen: 3, maxCost: 100} ) YIELD path, pathCost, pathWeight RETURN path ORDER BY pathCost\" . ",
    "url": "/cypher/match.html#behavior-in-presence-on-multiple-edges",
    
    "relUrl": "/cypher/match.html#behavior-in-presence-on-multiple-edges"
  },"169": {
    "doc": "MERGE",
    "title": "MERGE",
    "content": "The MERGE clause ensures that a path exists in the graph (either the path already exists, or it needs to be created). MERGE either matches existing nodes and binds them, or it creates new data and binds that. It’s like a combination of MATCH and CREATE that also allows you to specify what happens if the data was matched or created. For example, you can specify that the graph must contain a node for a user with a certain name. If there isn’t a node with the correct name, a new node will be created and its name property set. Any aliases in the MERGE path that were introduced by earlier clauses can only be matched; MERGE will not create them. When the MERGE path doesn’t rely on earlier clauses, the whole path will always either be matched or created. If all path elements are introduced by MERGE, a match failure will cause all elements to be created, even if part of the match succeeded. The MERGE path can be followed by ON MATCH SET and ON CREATE SET directives to conditionally set properties depending on whether or not the match succeeded. ",
    "url": "/cypher/merge.html",
    
    "relUrl": "/cypher/merge.html"
  },"170": {
    "doc": "MERGE",
    "title": "Merging nodes",
    "content": "To merge a single node with a label: . GRAPH.QUERY DEMO_GRAPH \"MERGE (robert:Critic)\" . To merge a single node with properties: . GRAPH.QUERY DEMO_GRAPH \"MERGE (charlie { name: 'Charlie Sheen', age: 10 })\" . To merge a single node, specifying both label and property: . GRAPH.QUERY DEMO_GRAPH \"MERGE (michael:Person { name: 'Michael Douglas' })\" . ",
    "url": "/cypher/merge.html#merging-nodes",
    
    "relUrl": "/cypher/merge.html#merging-nodes"
  },"171": {
    "doc": "MERGE",
    "title": "Merging paths",
    "content": "Because MERGE either matches or creates a full path, it is easy to accidentally create duplicate nodes. For example, if we run the following query on our sample graph: . GRAPH.QUERY DEMO_GRAPH \"MERGE (charlie { name: 'Charlie Sheen '})-[r:ACTED_IN]-&gt;(wallStreet:Movie { name: 'Wall Street' })\" . Even though a node with the name ‘Charlie Sheen’ already exists, the full pattern does not match, so 1 relation and 2 nodes - including a duplicate ‘Charlie Sheen’ node - will be created. We should use multiple MERGE clauses to merge a relation and only create non-existent endpoints: . GRAPH.QUERY DEMO_GRAPH \"MERGE (charlie { name: 'Charlie Sheen' }) MERGE (wallStreet:Movie { name: 'Wall Street' }) MERGE (charlie)-[r:ACTED_IN]-&gt;(wallStreet)\" . If we don’t want to create anything if pattern elements don’t exist, we can combine MATCH and MERGE clauses. The following query merges a relation only if both of its endpoints already exist: . GRAPH.QUERY DEMO_GRAPH \"MATCH (charlie { name: 'Charlie Sheen' }) MATCH (wallStreet:Movie { name: 'Wall Street' }) MERGE (charlie)-[r:ACTED_IN]-&gt;(wallStreet)\" . ",
    "url": "/cypher/merge.html#merging-paths",
    
    "relUrl": "/cypher/merge.html#merging-paths"
  },"172": {
    "doc": "MERGE",
    "title": "On Match and On Create directives",
    "content": "Using ON MATCH and ON CREATE, MERGE can set properties differently depending on whether a pattern is matched or created. In this query, we’ll merge paths based on a list of properties and conditionally set a property when creating new entities: . GRAPH.QUERY DEMO_GRAPH \"UNWIND ['Charlie Sheen', 'Michael Douglas', 'Tamara Tunie'] AS actor_name MATCH (movie:Movie { name: 'Wall Street' }) MERGE (person {name: actor_name})-[:ACTED_IN]-&gt;(movie) ON CREATE SET person.first_role = movie.name\" . ",
    "url": "/cypher/merge.html#on-match-and-on-create-directives",
    
    "relUrl": "/cypher/merge.html#on-match-and-on-create-directives"
  },"173": {
    "doc": "OPTIONAL MATCH",
    "title": "OPTIONAL MATCH",
    "content": "The OPTIONAL MATCH clause is a MATCH variant that produces null values for elements that do not match successfully, rather than the all-or-nothing logic for patterns in MATCH clauses. It can be considered to fill the same role as LEFT/RIGHT JOIN does in SQL, as MATCH entities must be resolved but nodes and edges introduced in OPTIONAL MATCH will be returned as nulls if they cannot be found. OPTIONAL MATCH clauses accept the same patterns as standard MATCH clauses, and may similarly be modified by WHERE clauses. Multiple MATCH and OPTIONAL MATCH clauses can be chained together, though a mandatory MATCH cannot follow an optional one. GRAPH.QUERY DEMO_GRAPH \"MATCH (p:Person) OPTIONAL MATCH (p)-[w:WORKS_AT]-&gt;(c:Company) WHERE w.start_date &gt; 2016 RETURN p, w, c\" . All Person nodes are returned, as well as any WORKS_AT relations and Company nodes that can be resolved and satisfy the start_date constraint. For each Person that does not resolve the optional pattern, the person will be returned as normal and the non-matching elements will be returned as null. Cypher is lenient in its handling of null values, so actions like property accesses and function calls on null values will return null values rather than emit errors. GRAPH.QUERY DEMO_GRAPH \"MATCH (p:Person) OPTIONAL MATCH (p)-[w:WORKS_AT]-&gt;(c:Company) RETURN p, w.department, ID(c) as ID\" . In this case, w.department and ID will be returned if the OPTIONAL MATCH was successful, and will be null otherwise. Clauses like SET, CREATE, MERGE, and DELETE will ignore null inputs and perform the expected updates on real inputs. One exception to this is that attempting to create a relation with a null endpoint will cause an error: . GRAPH.QUERY DEMO_GRAPH \"MATCH (p:Person) OPTIONAL MATCH (p)-[w:WORKS_AT]-&gt;(c:Company) CREATE (c)-[:NEW_RELATION]-&gt;(:NEW_NODE)\" . If c is null for any record, this query will emit an error. In this case, no changes to the graph are committed, even if some values for c were resolved. ",
    "url": "/cypher/optional_match.html",
    
    "relUrl": "/cypher/optional_match.html"
  },"174": {
    "doc": "ORDER BY",
    "title": "ORDER BY",
    "content": "Order by specifies that the output be sorted and how. You can order by multiple properties by stating each variable in the ORDER BY clause. Each property may specify its sort order with ASC/ASCENDING or DESC/DESCENDING. If no order is specified, it defaults to ascending. The result will be sorted by the first variable listed. For equal values, it will go to the next property in the ORDER BY clause, and so on. ORDER BY &lt;alias.property [ASC/DESC] list&gt; . Below we sort our friends by height. For equal heights, weight is used to break ties. ORDER BY friend.height, friend.weight DESC . ",
    "url": "/cypher/order_by.html",
    
    "relUrl": "/cypher/order_by.html"
  },"175": {
    "doc": "Path algorithms",
    "title": "Path algorithms",
    "content": "In v2.10 introduced two new path-finding algorithms, or more accurately, minimum-weight, optionally bounded-cost, and optionally bounded-length path-finding algorithms, algo.SPpaths and algo.SSpaths. algo.SPpaths and algo.SSpaths can solve a wide range of real-world problems, where minimum-weight paths need to be found. algo.SPpaths finds paths between a given pair of nodes, while algo.SSpaths finds paths from a given source node. Weight can represent time, distance, price, or any other measurement. A bound can be set on another property (e.g., finding a minimum-time bounded-price way to reach from point A to point B). Both algorithms are performant and have low memory requirements. For both algorithms, you can set: . | A list of relationship types to traverse (relTypes). | The relationships’ property whose sum you want to minimize (weight). | A optional relationships’ property whose sum you want to bound (cost) and the optional bound (maxCost). | An optional bound on the path length - the number of relationships along the path (maxLen). | The number of paths you want to retrieve: either all minimal-weight paths (pathCount is 0), a single minimal-weight path (pathCount is 1), or n minimal-weight paths with potentially different weights (pathCount is n). | . This topic explains which problems you can solve using these algorithms and demonstrates how to use them. Let’s start with the following graph. This graph represents a road network with 7 cities (A, B, C, and so on) and 11 one-way roads. Each road has a distance (say, in kilometers) and trip time (say, in minutes). Let’s create the graph. GRAPH.QUERY g \"CREATE (a:City{name:'A'}), (b:City{name:'B'}), (c:City{name:'C'}), (d:City{name:'D'}), (e:City{name:'E'}), (f:City{name:'F'}), (g:City{name:'G'}), (a)-[:Road{time:4, dist:3}]-&gt;(b), (a)-[:Road{time:3, dist:8}]-&gt;(c), (a)-[:Road{time:4, dist:2}]-&gt;(d), (b)-[:Road{time:5, dist:7}]-&gt;(e), (b)-[:Road{time:5, dist:5}]-&gt;(d), (d)-[:Road{time:4, dist:5}]-&gt;(e), (c)-[:Road{time:3, dist:6}]-&gt;(f), (d)-[:Road{time:1, dist:4}]-&gt;(c), (d)-[:Road{time:2, dist:12}]-&gt;(f), (e)-[:Road{time:5, dist:5}]-&gt;(g), (f)-[:Road{time:4, dist:2}]-&gt;(g)\" . If you’re using RedisInsight v2, you can create and visualize the graph by slightly modifying the above query: you’ll have to assign aliases to all nodes and relationships, and return them: . GRAPH.QUERY g \"CREATE (a:City{name:'A'}), (b:City{name:'B'}), (c:City{name:'C'}), (d:City{name:'D'}), (e:City{name:'E'}), (f:City{name:'F'}), (g:City{name:'G'}), (a)-[r1:Road{time:4, dist:3}]-&gt;(b), (a)-[r2:Road{time:3, dist:8}]-&gt;(c), (a)-[r3:Road{time:4, dist:2}]-&gt;(d), (b)-[r4:Road{time:5, dist:7}]-&gt;(e), (b)-[r5:Road{time:5, dist:5}]-&gt;(d), (d)-[r6:Road{time:4, dist:5}]-&gt;(e), (c)-[r7:Road{time:3, dist:6}]-&gt;(f), (d)-[r8:Road{time:1, dist:4}]-&gt;(c), (d)-[r9:Road{time:2, dist:12}]-&gt;(f), (e)-[r10:Road{time:5, dist:5}]-&gt;(g), (f)-[r11:Road{time:4, dist:2}]-&gt;(g) RETURN a,b,c,d,e,f,g,r1,r2,r3,r4,r5,r6,r7,r8,r9,r10,r11\" . ",
    "url": "/path_algorithm.html",
    
    "relUrl": "/path_algorithm.html"
  },"176": {
    "doc": "Path algorithms",
    "title": "Before v2.10",
    "content": "Before v2.10, you were able to solve these queries: . | Find the shortest path (by number of roads) from A to G | Find all the shortest paths (by number of roads) from A to G | Find 5 shortest paths (by number of roads) from A to G | Find 5 shortest paths (in kilometers) from A to G | . Find the shortest path (by number of roads) from A to G . GRAPH.QUERY g \"MATCH (a:City{name:'A'}),(g:City{name:'G'}) WITH shortestPath((a)-[*]-&gt;(g)) as p RETURN length(p), [n in nodes(p) | n.name] as pathNodes\" 1) 1) \"length(p)\" 2) \"pathNodes\" 2) 1) 1) (integer) 3 2) \"[A, D, F, G]\" . shortestPath returns one of the shortest paths. If there is more than one, only one is retrieved. With RedisInsight v2, you can visualize a path simply by returning it. Find all the shortest paths (by number of roads) from A to G . GRAPH.QUERY g \"MATCH (a:City{name:'A'}),(g:City{name:'G'}) WITH a,g MATCH p=allShortestPaths((a)-[*]-&gt;(g)) RETURN length(p), [n in nodes(p) | n.name] as pathNodes\" 1) 1) \"length(p)\" 2) \"pathNodes\" 2) 1) 1) (integer) 3 2) \"[A, D, F, G]\" 2) 1) (integer) 3 2) \"[A, C, F, G]\" 3) 1) (integer) 3 2) \"[A, D, E, G]\" 4) 1) (integer) 3 2) \"[A, B, E, G]\" . All allShortestPaths results have, by definition, the same length (number of roads). Find 5 shortest paths (by number of roads) from A to G . GRAPH.QUERY g \"MATCH p = (a:City{name:'A'})-[*]-&gt;(g:City{name:'G'}) RETURN length(p), [n in nodes(p) | n.name] as pathNodes ORDER BY length(p) LIMIT 5\" 1) 1) \"length(p)\" 2) \"pathNodes\" 2) 1) 1) (integer) 3 2) \"[A, B, E, G]\" 2) 1) (integer) 3 2) \"[A, D, E, G]\" 3) 1) (integer) 3 2) \"[A, D, F, G]\" 4) 1) (integer) 3 2) \"[A, C, F, G]\" 5) 1) (integer) 4 2) \"[A, D, C, F, G]\" . Using the unbounded traversal pattern (a:City{name:'A'})-[*]-&gt;(g:City{name:'G'}), FalkorDB traverses all possible paths from A to G. ORDER BY length(p) LIMIT 5 ensures that you collect only [up to 5 shortest paths (minimal number of relationships). This approach is very inefficient because all possible paths would have to be traversed. Ideally, you would want to abort some traversals as soon as you are sure they would not result in the discovery of shorter paths. Find 5 shortest paths (in kilometers) from A to G . In a similarly inefficient manner, you can traverse all possible paths and collect the 5 shortest paths (in kilometers). GRAPH.QUERY g \"MATCH p = (a:City{name:'A'})-[*]-&gt;(g:City{name:'G'}) WITH p,reduce(dist=0, n IN relationships(p) | dist+n.dist) as dist return dist,[n IN nodes(p) | n.name] as pathNodes ORDER BY dist LIMIT 5\" 1) 1) \"dist\" 2) \"pathNodes\" 2) 1) 1) (integer) 12 2) \"[A, D, E, G]\" 2) 1) (integer) 14 2) \"[A, D, C, F, G]\" 3) 1) (integer) 15 2) \"[A, B, E, G]\" 4) 1) (integer) 16 2) \"[A, D, F, G]\" 5) 1) (integer) 16 2) \"[A, C, F, G]\" . Again, instead of traversing all possible paths, you would want to abort some traversals as soon as you are sure that they would not result in the discovery of shorter paths. ",
    "url": "/path_algorithm.html#before-v210",
    
    "relUrl": "/path_algorithm.html#before-v210"
  },"177": {
    "doc": "Path algorithms",
    "title": "algo.SPpaths",
    "content": "Finding shortest paths (in kilometers) by traversing all paths and collecting the shortest ones is highly inefficient, up to the point of being impractical for large graphs, as the number of paths can sometimes grow exponentially relative to the number of relationships. Using the algo.SPpaths procedure (SP stands for single pair) you can traverse the graph, collecting only the required paths in the most efficient manner. algo.SPpaths receives several arguments. The arguments you used in the examples above are: . | sourceNode: the source node . | targetNode: the target node . | relTypes: list of one or more relationship types to traverse . | weightProp: the relationship’s property that represents the weight (for all specified relTypes) . | . You are looking for minimum-weight paths. The weight of the path is the sum of the weights of all relationships composing the path. If a given relationship does not have such a property or its value is not a positive integer or float, the property defaults to 1. The property also yields several results. The results you used in the example above are: . | path: the path . | pathWeight: the path’s weight or sum of weightProp of all the relationships along the path . | . With algo.SPaths, you can solve queries like this. Find the shortest path (in kilometers) from A to G . Set weightProp to dist: . GRAPH.QUERY g \"MATCH (a:City{name:'A'}),(g:City{name:'G'}) CALL algo.SPpaths( {sourceNode: a, targetNode: g, relTypes: ['Road'], weightProp: 'dist'} ) YIELD path, pathWeight RETURN pathWeight, [n in nodes(path) | n.name] as pathNodes\" 1) 1) \"pathWeight\" 2) \"pathNodes\" 2) 1) 1) \"12\" 2) \"[A, D, E, G]\" . Find the fastest path (in minutes) from A to G . Continue as before, but now set weightProp to time. GRAPH.QUERY g \"MATCH (a:City{name:'A'}),(g:City{name:'G'}) CALL algo.SPpaths( {sourceNode: a, targetNode: g, relTypes: ['Road'], weightProp: 'time'} ) YIELD path, pathWeight RETURN pathWeight, [n in nodes(path) | n.name] as pathNodes\" 1) 1) \"pathWeight\" 2) \"pathNodes\" 2) 1) 1) \"10\" 2) \"[A, D, F, G]\" . Find the shortest paths (in kilometers) from A to G . GRAPH.QUERY g \"MATCH (a:City{name:'A'}),(g:City{name:'G'}) CALL algo.SPpaths( {sourceNode: a, targetNode: g, relTypes: ['Road'], pathCount: 0, weightProp: 'dist'} ) YIELD path, pathWeight RETURN pathWeight, [n in nodes(path) | n.name] as pathNodes\" 1) 1) \"pathWeight\" 2) \"pathNodes\" 2) 1) 1) \"12\" 2) \"[A, D, E, G]\" . In the example above, you also specified the pathCount argument, where pathCount is the number of paths to report: . | 0: retrieve all minimum-weight paths (all reported paths have the same weight) . | 1: retrieve a single minimum-weight path (default) . | n&gt;1: retrieve up to n minimum-weight paths (reported paths may have different weights) . | . Find 5 shortest paths (in kilometers) from A to G . GRAPH.QUERY g \"MATCH (a:City{name:'A'}),(g:City{name:'G'}) CALL algo.SPpaths( {sourceNode: a, targetNode: g, relTypes: ['Road'], pathCount: 5, weightProp: 'dist'} ) YIELD path, pathWeight RETURN pathWeight, [n in nodes(path) | n.name] ORDER BY pathWeight\" 1) 1) \"pathWeight\" 2) \"[n in nodes(path) | n.name]\" 2) 1) 1) \"12\" 2) \"[A, D, E, G]\" 2) 1) \"14\" 2) \"[A, D, C, F, G]\" 3) 1) \"15\" 2) \"[A, B, E, G]\" 4) 1) \"16\" 2) \"[A, C, F, G]\" 5) 1) \"16\" 2) \"[A, D, F, G]\" . Find 2 shortest paths (in kilometers) from A to G, where you can reach G in up to 12 minutes . Another interesting feature is the introduction of path constraints (‘bounded-cost’). Suppose that you want to find only paths where you can reach G in 12 minutes or less. GRAPH.QUERY g \"MATCH (a:City{name:'A'}),(g:City{name:'G'}) CALL algo.SPpaths( {sourceNode: a, targetNode: g, relTypes: ['Road'], pathCount: 2, weightProp: 'dist', costProp: 'time', maxCost: 12} ) YIELD path, pathWeight, pathCost RETURN pathWeight, pathCost, [n in nodes(path) | n.name] ORDER BY pathWeight\" 1) 1) \"pathWeight\" 2) \"pathCost\" 3) \"[n in nodes(path) | n.name]\" 2) 1) 1) \"14\" 2) \"12\" 3) \"[A, D, C, F, G]\" 2) 1) \"16\" 2) \"10\" . In the example above, you added the following optional arguments: . | costProp: the relationship’s property that represents the cost. You are looking for minimum-weight bounded-cost paths. If a given relationship does not have such property or its value is not a positive integer/float, costProp defaults to 1. | maxCost: the maximum cost (the bound). If not specified, there is no maximum cost constraint. | . You also yielded: . | pathCost: the path’s cost or the sum of costProp of all relationships along the path. | . Find paths from D to G, assuming you can traverse each road in both directions . Another interesting feature is the ability to revert or ignore the relationship direction. GRAPH.QUERY g \"MATCH (a:City{name:'D'}),(g:City{name:'G'}) CALL algo.SPpaths( {sourceNode: a, targetNode: g, relTypes: ['Road'], relDirection: 'both', pathCount: 1000, weightProp: 'dist'} ) YIELD path, pathWeight RETURN pathWeight, [n in nodes(path) | n.name] as pathNodes ORDER BY pathWeight\" 1) 1) \"pathWeight\" 2) \"pathNodes\" 2) 1) 1) \"10\" 2) \"[D, E, G]\" 2) 1) \"12\" 2) \"[D, C, F, G]\" 3) 1) \"14\" 2) \"[D, F, G]\" 4) 1) \"17\" 2) \"[D, A, B, E, G]\" 5) 1) \"17\" 2) \"[D, B, E, G]\" 6) 1) \"18\" 2) \"[D, A, C, F, G]\" 7) 1) \"24\" 2) \"[D, B, A, C, F, G]\" 8) 1) \"27\" 2) \"[D, C, A, B, E, G]\" 9) 1) \"31\" 2) \"[D, E, B, A, C, F, G]\" 10) 1) \"41\" 2) \"[D, F, C, A, B, E, G]\" . In the example above, you added the following optional argument: . | relDirection: one of incoming, outgoing, or both. If not specified, relDirection defaults to outgoing. | . Find paths with length up to 4 from D to G, assuming you can traverse each road in both directions . Suppose you want to repeat the query above but also limit the path-length (number of relationships along to path) to 4: . GRAPH.QUERY g \"MATCH (a:City{name:'D'}),(g:City{name:'G'}) CALL algo.SPpaths( {sourceNode: a, targetNode: g, relTypes: ['Road'], relDirection: 'both', pathCount: 1000, weightProp: 'dist', maxLen: 4} ) YIELD path, pathWeight RETURN pathWeight, [n in nodes(path) | n.name] as pathNodes ORDER BY pathWeight\" 1) 1) \"pathWeight\" 2) \"pathNodes\" 2) 1) 1) \"10\" 2) \"[D, E, G]\" 2) 1) \"12\" 2) \"[D, C, F, G]\" 3) 1) \"14\" 2) \"[D, F, G]\" 4) 1) \"17\" 2) \"[D, A, B, E, G]\" 5) 1) \"17\" 2) \"[D, B, E, G]\" 6) 1) \"18\" 2) \"[D, A, C, F, G]\" . In the example above, you specified the following optional constraint: . | maxLen: maximum path length (number of roads along the path) | . ",
    "url": "/path_algorithm.html#algosppaths",
    
    "relUrl": "/path_algorithm.html#algosppaths"
  },"178": {
    "doc": "Path algorithms",
    "title": "algo.SSpaths",
    "content": "Some problems involve just one node, the source node, where you ask questions about possible paths or reachable destinations, given some constraints. That’s what the algo.SSpaths procedure (SS stands for single source) is all about. algo.SSpaths accepts the same arguments as algo.SPpaths, except targetNode. It also yields the same results (path, pathCost, and pathWeight). Find all paths from A if the trip is limited to 10 kilometers . GRAPH.QUERY g \"MATCH (a:City{name:'A'}) CALL algo.SSpaths( {sourceNode: a, relTypes: ['Road'], pathCount: 1000, costProp: 'dist', maxCost: 10} ) YIELD path, pathCost RETURN pathCost, [n in nodes(path) | n.name] as pathNodes ORDER BY pathCost\" 1) 1) \"pathCost\" 2) \"pathNodes\" 2) 1) 1) \"2\" 2) \"[A, D]\" 2) 1) \"3\" 2) \"[A, B]\" 3) 1) \"6\" 2) \"[A, D, C]\" 4) 1) \"7\" 2) \"[A, D, E]\" 5) 1) \"8\" 2) \"[A, B, D]\" 6) 1) \"8\" 2) \"[A, C]\" 7) 1) \"10\" 2) \"[A, B, E]\" . Find all paths from A if the trip is limited to 8 minutes . GRAPH.QUERY g \"MATCH (a:City{name:'A'}) CALL algo.SSpaths( {sourceNode: a, relTypes: ['Road'], pathCount: 1000, costProp: 'time', maxCost: 8} ) YIELD path, pathCost RETURN pathCost, [n in nodes(path) | n.name] as pathNodes ORDER BY pathCost\" 1) 1) \"pathCost\" 2) \"pathNodes\" 2) 1) 1) \"3\" 2) \"[A, C]\" 2) 1) \"4\" 2) \"[A, B]\" 3) 1) \"4\" 2) \"[A, D]\" 4) 1) \"5\" 2) \"[A, D, C]\" 5) 1) \"6\" 2) \"[A, D, F]\" 6) 1) \"6\" 2) \"[A, C, F]\" 7) 1) \"8\" 2) \"[A, D, C, F]\" 8) 1) \"8\" 2) \"[A, D, E]\" . Find 5 shortest paths (in kilometers) from A . GRAPH.QUERY g \"MATCH (a:City{name:'A'}) CALL algo.SSpaths( {sourceNode: a, relTypes: ['Road'], pathCount: 5, weightProp: 'dist', costProp: 'cost'} ) YIELD path, pathWeight, pathCost RETURN pathWeight, pathCost, [n in nodes(path) | n.name] as pathNodes ORDER BY pathWeight\" 1) 1) \"pathWeight\" 2) \"pathCost\" 3) \"pathNodes\" 2) 1) 1) \"2\" 2) \"1\" 3) \"[A, D]\" 2) 1) \"3\" 2) \"1\" 3) \"[A, B]\" 3) 1) \"6\" 2) \"2\" 3) \"[A, D, C]\" 4) 1) \"7\" 2) \"2\" 3) \"[A, D, E]\" 5) 1) \"8\" 2) \"1\" 3) \"[A, C]\" . Find 5 shortest paths (in kilometers) from A if the trip is limited to 6 minutes . GRAPH.QUERY g \"MATCH (a:City{name:'A'}) CALL algo.SSpaths( {sourceNode: a, relTypes: ['Road'], pathCount: 5, weightProp: 'dist', costProp: 'time', maxCost: 6} ) YIELD path, pathWeight, pathCost RETURN pathWeight, pathCost, [n in nodes(path) | n.name] as pathNodes ORDER BY pathWeight\" 1) 1) \"pathWeight\" 2) \"pathCost\" 3) \"pathNodes\" 2) 1) 1) \"2\" 2) \"4\" 3) \"[A, D]\" 2) 1) \"3\" 2) \"4\" 3) \"[A, B]\" 3) 1) \"6\" 2) \"5\" 3) \"[A, D, C]\" 4) 1) \"8\" 2) \"3\" 3) \"[A, C]\" 5) 1) \"14\" 2) \"6\" 3) \"[A, D, F]\" . ",
    "url": "/path_algorithm.html#algosspaths",
    
    "relUrl": "/path_algorithm.html#algosspaths"
  },"179": {
    "doc": "Persistence",
    "title": "Configuring FalkorDB Docker for Persistence",
    "content": "FalkorDB supports advanced configurations to enable data persistence, ensuring that your data is safe and remains intact even after container restarts. This guide will walk you through setting up FalkorDB in Docker with persistence enabled. To understand how to customize the persistence configuration with RDB or/and AOF, please check the Persistence section. ",
    "url": "/operations/persistence.html#configuring-falkordb-docker-for-persistence",
    
    "relUrl": "/operations/persistence.html#configuring-falkordb-docker-for-persistence"
  },"180": {
    "doc": "Persistence",
    "title": "Prerequisites",
    "content": "Before you begin, ensure you have the following: . | Docker installed on your machine. | A working FalkorDB Docker image. You can pull it from Docker Hub. | Basic knowledge of Docker commands and configurations. | . ",
    "url": "/operations/persistence.html#prerequisites",
    
    "relUrl": "/operations/persistence.html#prerequisites"
  },"181": {
    "doc": "Persistence",
    "title": "Step 1: Setting Up Persistence",
    "content": "Persistence in FalkorDB allows you to store your data on the host machine, ensuring that it is not lost when the container restarts. 1.1 Create a Persistent Volume . First, create a Docker volume to store the data: . docker volume create falkordb_data . This volume will be used to store the database files. 1.2 Start FalkorDB with the Persistent Volume . You can now run FalkorDB with the volume attached: . docker run -d --name falkordb -v falkordb_data:/data -p 6379:6379 falkordb/falkordb . In this configuration: . The -v falkordb_data:/data flag mounts the volume to the /data directory inside the container. FalkorDB will use the /data directory by default. ",
    "url": "/operations/persistence.html#step-1-setting-up-persistence",
    
    "relUrl": "/operations/persistence.html#step-1-setting-up-persistence"
  },"182": {
    "doc": "Persistence",
    "title": "Step 2: Verifying the Setup",
    "content": "To verify that your setup is working correctly: . | Persistence Check: Stop the FalkorDB container and start it again. The data should persist across restarts. | . redis-cli graph.query mygraph \"CREATE (:Database {name:'falkordb'})\" docker stop falkordb docker start falkordb redis-cli graph.query mygraph \"MATCH (n) return n\" # Output should be: # 1) 1) \"n\" # 2) 1) 1) 1) 1) \"id\" # 2) (integer) 0 # 2) 1) \"labels\" # 2) 1) \"Database\" # 3) 1) \"properties\" # 2) 1) 1) \"name\" # 2) \"falkordb\" # 3) 1) \"Cached execution: 1\" # 2) \"Query internal execution time: 0.122645 milliseconds\" . ",
    "url": "/operations/persistence.html#step-2-verifying-the-setup",
    
    "relUrl": "/operations/persistence.html#step-2-verifying-the-setup"
  },"183": {
    "doc": "Persistence",
    "title": "Conclusion",
    "content": "With persistence configured, FalkorDB is now set up for reliable data storage that remains intact across container restarts. This setup ensures that your data is consistently saved, providing a stable and dependable environment for your applications. If you’re interested in learning more about high availability and replication, be sure to check out the replication chapter in the documentation. ",
    "url": "/operations/persistence.html#conclusion",
    
    "relUrl": "/operations/persistence.html#conclusion"
  },"184": {
    "doc": "Persistence",
    "title": "Persistence",
    "content": " ",
    "url": "/operations/persistence.html",
    
    "relUrl": "/operations/persistence.html"
  },"185": {
    "doc": "Persistence",
    "title": "RDB advantages",
    "content": ". | RDB is a very compact single-file point-in-time representation of your FalkorDB data. RDB files are perfect for backups. For instance you may want to archive your RDB files every hour for the latest 24 hours, and to save an RDB snapshot every day for 30 days. This allows you to easily restore different versions of the data set in case of disasters. | RDB is very good for disaster recovery, being a single compact file that can be transferred to far data centers, or onto Amazon S3 (possibly encrypted). | RDB maximizes FalkorDB performances since the only work the FalkorDB parent process needs to do in order to persist is forking a child that will do all the rest. The parent process will never perform disk I/O or alike. | RDB allows faster restarts with big datasets compared to AOF. | On replicas, RDB supports partial resynchronizations after restarts and failovers. | . ",
    "url": "/management/persistence.html#rdb-advantages",
    
    "relUrl": "/management/persistence.html#rdb-advantages"
  },"186": {
    "doc": "Persistence",
    "title": "RDB disadvantages",
    "content": ". | RDB is NOT good if you need to minimize the chance of data loss in case FalkorDB stops working (for example after a power outage). You can configure different save points where an RDB is produced (for instance after at least five minutes and 100 writes against the data set, you can have multiple save points). However you’ll usually create an RDB snapshot every five minutes or more, so in case of FalkorDB stopping working without a correct shutdown for any reason you should be prepared to lose the latest minutes of data. | RDB needs to fork() often in order to persist on disk using a child process. fork() can be time consuming if the dataset is big, and may result in FalkorDB stopping serving clients for some milliseconds or even for one second if the dataset is very big and the CPU performance is not great. AOF also needs to fork() but less frequently and you can tune how often you want to rewrite your logs without any trade-off on durability. | . ",
    "url": "/management/persistence.html#rdb-disadvantages",
    
    "relUrl": "/management/persistence.html#rdb-disadvantages"
  },"187": {
    "doc": "Persistence",
    "title": "AOF advantages",
    "content": ". | Using AOF FalkorDB is much more durable: you can have different fsync policies: no fsync at all, fsync every second, fsync at every query. With the default policy of fsync every second, write performance is still great. fsync is performed using a background thread and the main thread will try hard to perform writes when no fsync is in progress, so you can only lose one second worth of writes. | The AOF log is an append-only log, so there are no seeks, nor corruption problems if there is a power outage. Even if the log ends with a half-written command for some reason (disk full or other reasons) the FalkorDB-check-aof tool is able to fix it easily. | FalkorDB is able to automatically rewrite the AOF in background when it gets too big. The rewrite is completely safe as while FalkorDB continues appending to the old file, a completely new one is produced with the minimal set of operations needed to create the current data set, and once this second file is ready FalkorDB switches the two and starts appending to the new one. | AOF contains a log of all the operations one after the other in an easy to understand and parse format. You can even easily export an AOF file. For instance even if you’ve accidentally flushed everything using the FLUSHALL command, as long as no rewrite of the log was performed in the meantime, you can still save your data set just by stopping the server, removing the latest command, and restarting FalkorDB again. | . ",
    "url": "/management/persistence.html#aof-advantages",
    
    "relUrl": "/management/persistence.html#aof-advantages"
  },"188": {
    "doc": "Persistence",
    "title": "AOF disadvantages",
    "content": ". | AOF files are usually bigger than the equivalent RDB files for the same dataset. | AOF can be slower than RDB depending on the exact fsync policy. In general with fsync set to every second performance is still very high, and with fsync disabled it should be exactly as fast as RDB even under high load. Still RDB is able to provide more guarantees about the maximum latency even in the case of a huge write load. | . ",
    "url": "/management/persistence.html#aof-disadvantages",
    
    "relUrl": "/management/persistence.html#aof-disadvantages"
  },"189": {
    "doc": "Persistence",
    "title": "Ok, so what should I use?",
    "content": "The general indication you should use both persistence methods is if you want a degree of data safety comparable to what PostgreSQL can provide you. If you care a lot about your data, but still can live with a few minutes of data loss in case of disasters, you can simply use RDB alone. There are many users using AOF alone, but we discourage it since to have an RDB snapshot from time to time is a great idea for doing database backups, for faster restarts, and in the event of bugs in the AOF engine. The following sections will illustrate a few more details about the two persistence models. ",
    "url": "/management/persistence.html#ok-so-what-should-i-use",
    
    "relUrl": "/management/persistence.html#ok-so-what-should-i-use"
  },"190": {
    "doc": "Persistence",
    "title": "Snapshotting",
    "content": "By default FalkorDB saves snapshots of the dataset on disk, in a binary file called dump.rdb. You can configure FalkorDB to have it save the dataset every N seconds if there are at least M changes in the dataset, or you can manually call the SAVE or BGSAVE commands. For example, this configuration will make FalkorDB automatically dump the dataset to disk every 60 seconds if at least 1000 keys changed: . save 60 1000 . This strategy is known as snapshotting. How it works . Whenever FalkorDB needs to dump the dataset to disk, this is what happens: . | FalkorDB forks. We now have a child and a parent process. | The child starts to write the dataset to a temporary RDB file. | When the child is done writing the new RDB file, it replaces the old one. | . This method allows FalkorDB to benefit from copy-on-write semantics. ",
    "url": "/management/persistence.html#snapshotting",
    
    "relUrl": "/management/persistence.html#snapshotting"
  },"191": {
    "doc": "Persistence",
    "title": "Append-only file",
    "content": "Snapshotting is not very durable. If your computer running FalkorDB stops, your power line fails, or you accidentally kill -9 your instance, the latest data written to FalkorDB will be lost. While this may not be a big deal for some applications, there are use cases for full durability, and in these cases FalkorDB snapshotting alone is not a viable option. The append-only file is an alternative, fully-durable strategy for FalkorDB. You can turn on the AOF in your configuration file: . appendonly yes . From now on, every time FalkorDB receives a command that changes the dataset (e.g. SET) it will append it to the AOF. When you restart FalkorDB it will re-play the AOF to rebuild the state. FalkorDB uses a multi part AOF mechanism. That is, the original single AOF file is split into base file (at most one) and incremental files (there may be more than one). The base file represents an initial (RDB or AOF format) snapshot of the data present when the AOF is rewritten. The incremental files contains incremental changes since the last base AOF file was created. All these files are put in a separate directory and are tracked by a manifest file. Log rewriting . The AOF gets bigger and bigger as write operations are performed. For example, if you are incrementing a counter 100 times, you’ll end up with a single key in your dataset containing the final value, but 100 entries in your AOF. 99 of those entries are not needed to rebuild the current state. The rewrite is completely safe. While FalkorDB continues appending to the old file, a completely new one is produced with the minimal set of operations needed to create the current data set, and once this second file is ready FalkorDB switches the two and starts appending to the new one. FalkorDB supports an interesting feature: it is able to rebuild the AOF in the background without interrupting service to clients. Whenever you issue a BGREWRITEAOF, FalkorDB will write the shortest sequence of commands needed to rebuild the current dataset in memory. FalkorDB will automatically trigger log rewriting automatically (see the example configuration file for more information). When an AOF rewrite is scheduled, the FalkorDB parent process opens a new incremental AOF file to continue writing. The child process executes the rewrite logic and generates a new base AOF. FalkorDB will use a temporary manifest file to track the newly generated base file and incremental file. When they are ready, FalkorDB will perform an atomic replacement operation to make this temporary manifest file take effect. In order to avoid the problem of creating many incremental files in case of repeated failures and retries of an AOF rewrite, FalkorDB introduces an AOF rewrite limiting mechanism to ensure that failed AOF rewrites are retried at a slower and slower rate. How durable is the append only file? . You can configure how many times FalkorDB will fsync data on disk. There are three options: . | appendfsync always: fsync every time new commands are appended to the AOF. Very very slow, very safe. Note that the commands are appended to the AOF after a batch of commands from multiple clients or a pipeline are executed, so it means a single write and a single fsync (before sending the replies). | appendfsync everysec: fsync every second. Fast enough and you may lose 1 second of data if there is a disaster. | appendfsync no: Never fsync, just put your data in the hands of the Operating System. The faster and less safe method. Normally Linux will flush data every 30 seconds with this configuration, but it’s up to the kernel’s exact tuning. | . The suggested (and default) policy is to fsync every second. It is both fast and relatively safe. The always policy is very slow in practice, but it supports group commit, so if there are multiple parallel writes FalkorDB will try to perform a single fsync operation. What should I do if my AOF gets truncated? . It is possible the server crashed while writing the AOF file, or the volume where the AOF file is stored was full at the time of writing. When this happens the AOF still contains consistent data representing a given point-in-time version of the dataset (that may be old up to one second with the default AOF fsync policy), but the last command in the AOF could be truncated. The latest major versions of FalkorDB will be able to load the AOF anyway, just discarding the last non well formed command in the file. In this case the server will emit a log like the following: . * Reading RDB preamble from AOF file... * Reading the remaining AOF tail... # !!! Warning: short read while loading the AOF file !!! # !!! Truncating the AOF at offset 439 !!! # AOF loaded anyway because aof-load-truncated is enabled . You can change the default configuration to force FalkorDB to stop in such cases if you want, but the default configuration is to continue regardless of the fact the last command in the file is not well-formed, in order to guarantee availability after a restart. Older versions of FalkorDB may not recover, and may require the following steps: . | Make a backup copy of your AOF file. | Fix the original file using the FalkorDB-check-aof tool that ships with FalkorDB: . $ FalkorDB-check-aof --fix &lt;filename&gt; . | Optionally use diff -u to check what is the difference between two files. | Restart the server with the fixed file. | . What should I do if my AOF gets corrupted? . If the AOF file is not just truncated, but corrupted with invalid byte sequences in the middle, things are more complex. FalkorDB will complain at startup and will abort: . * Reading the remaining AOF tail... # Bad file format reading the append only file: make a backup of your AOF file, then use ./FalkorDB-check-aof --fix &lt;filename&gt; . The best thing to do is to run the FalkorDB-check-aof utility, initially without the --fix option, then understand the problem, jump to the given offset in the file, and see if it is possible to manually repair the file: The AOF uses the same format of the FalkorDB protocol and is quite simple to fix manually. Otherwise it is possible to let the utility fix the file for us, but in that case all the AOF portion from the invalid part to the end of the file may be discarded, leading to a massive amount of data loss if the corruption happened to be in the initial part of the file. How it works . Log rewriting uses the same copy-on-write trick already in use for snapshotting. This is how it works: . FalkorDB multi-part AOF . | FalkorDB forks, so now we have a child and a parent process. | The child starts writing the new base AOF in a temporary file. | The parent opens a new increments AOF file to continue writing updates. If the rewriting fails, the old base and increment files (if there are any) plus this newly opened increment file represent the complete updated dataset, so we are safe. | When the child is done rewriting the base file, the parent gets a signal, and uses the newly opened increment file and child generated base file to build a temp manifest, and persist it. | Profit! Now FalkorDB does an atomic exchange of the manifest files so that the result of this AOF rewrite takes effect. FalkorDB also cleans up the old base file and any unused increment files. | . How I can switch to AOF, if I’m currently using dump.rdb snapshots? . If you want to enable AOF in a server that is currently using RDB snapshots, you need to convert the data by enabling AOF via CONFIG command on the live server first. IMPORTANT: not following this procedure (e.g. just changing the config and restarting the server) can result in data loss! . Preparations: . | Make a backup of your latest dump.rdb file. | Transfer this backup to a safe place. | . Switch to AOF on live database: . | Enable AOF: redis-cli config set appendonly yes | Optionally disable RDB: redis-cli config set save \"\" | Make sure writes are appended to the append only file correctly. | IMPORTANT: Update your FalkorDB.conf (potentially through CONFIG REWRITE) and ensure that it matches the configuration above. If you forget this step, when you restart the server, the configuration changes will be lost and the server will start again with the old configuration, resulting in a loss of your data. | . Next time you restart the server: . | Before restarting the server, wait for AOF rewrite to finish persisting the data. You can do that by watching INFO persistence, waiting for aof_rewrite_in_progress and aof_rewrite_scheduled to be 0, and validating that aof_last_bgrewrite_status is ok. | After restarting the server, check that your database contains the same number of keys it contained previously. | . ",
    "url": "/management/persistence.html#append-only-file",
    
    "relUrl": "/management/persistence.html#append-only-file"
  },"192": {
    "doc": "Persistence",
    "title": "Interactions between AOF and RDB persistence",
    "content": "FalkorDB makes sure to avoid triggering an AOF rewrite when an RDB snapshotting operation is already in progress, or allowing a BGSAVE while the AOF rewrite is in progress. This prevents two FalkorDB background processes from doing heavy disk I/O at the same time. When snapshotting is in progress and the user explicitly requests a log rewrite operation using BGREWRITEAOF the server will reply with an OK status code telling the user the operation is scheduled, and the rewrite will start once the snapshotting is completed. In the case both AOF and RDB persistence are enabled and FalkorDB restarts the AOF file will be used to reconstruct the original dataset since it is guaranteed to be the most complete. ",
    "url": "/management/persistence.html#interactions-between-aof-and-rdb-persistence",
    
    "relUrl": "/management/persistence.html#interactions-between-aof-and-rdb-persistence"
  },"193": {
    "doc": "Persistence",
    "title": "Backing up FalkorDB data",
    "content": "Before starting this section, make sure to read the following sentence: Make Sure to Backup Your Database. Disks break, instances in the cloud disappear, and so forth: no backups means huge risk of data disappearing into /dev/null. FalkorDB is very data backup friendly since you can copy RDB files while the database is running: the RDB is never modified once produced, and while it gets produced it uses a temporary name and is renamed into its final destination atomically using rename(2) only when the new snapshot is complete. This means that copying the RDB file is completely safe while the server is running. This is what we suggest: . | Create a cron job in your server creating hourly snapshots of the RDB file in one directory, and daily snapshots in a different directory. | Every time the cron script runs, make sure to call the find command to make sure too old snapshots are deleted: for instance you can take hourly snapshots for the latest 48 hours, and daily snapshots for one or two months. Make sure to name the snapshots with date and time information. | At least one time every day make sure to transfer an RDB snapshot outside your data center or at least outside the physical machine running your FalkorDB instance. | . Backing up AOF persistence . If you run a FalkorDB instance with only AOF persistence enabled, you can still perform backups. AOF files are split into multiple files which reside in a single directory determined by the appenddirname configuration. During normal operation all you need to do is copy/tar the files in this directory to achieve a backup. However, if this is done during a rewrite, you might end up with an invalid backup. To work around this you must disable AOF rewrites during the backup: . | Turn off automatic rewrites with CONFIG SET auto-aof-rewrite-percentage 0 Make sure you don’t manually start a rewrite (using BGREWRITEAOF) during this time. | Check there’s no current rewrite in progress using INFO persistence and verifying aof_rewrite_in_progress is 0. If it’s 1, then you’ll need to wait for the rewrite to complete. | Now you can safely copy the files in the appenddirname directory. | Re-enable rewrites when done: CONFIG SET auto-aof-rewrite-percentage &lt;prev-value&gt; | . Note: If you want to minimize the time AOF rewrites are disabled you may create hard links to the files in appenddirname (in step 3 above) and then re-enable rewrites (step 4) after the hard links are created. Now you can copy/tar the hardlinks and delete them when done. This works because FalkorDB guarantees that it only appends to files in this directory, or completely replaces them if necessary, so the content should be consistent at any given point in time. Note: If you want to handle the case of the server being restarted during the backup and make sure no rewrite will automatically start after the restart you can change step 1 above to also persist the updated configuration via CONFIG REWRITE. Just make sure to re-enable automatic rewrites when done (step 4) and persist it with another CONFIG REWRITE. ",
    "url": "/management/persistence.html#backing-up-falkordb-data",
    
    "relUrl": "/management/persistence.html#backing-up-falkordb-data"
  },"194": {
    "doc": "Persistence",
    "title": "Disaster recovery",
    "content": "Disaster recovery in the context of FalkorDB is basically the same story as backups, plus the ability to transfer those backups in many different external data centers. This way data is secured even in the case of some catastrophic event affecting the main data center where FalkorDB is running and producing its snapshots. We’ll review the most interesting disaster recovery techniques that don’t have too high costs. | Amazon S3 and other similar services are a good way for implementing your disaster recovery system. Simply transfer your daily or hourly RDB snapshot to S3 in an encrypted form. You can encrypt your data using gpg -c (in symmetric encryption mode). Make sure to store your password in many different safe places (for instance give a copy to the most important people of your organization). It is recommended to use multiple storage services for improved data safety. | Transfer your snapshots using SCP (part of SSH) to far servers. This is a fairly simple and safe route: get a small VPS in a place that is very far from you, install ssh there, and generate a ssh client key without passphrase, then add it in the authorized_keys file of your small VPS. You are ready to transfer backups in an automated fashion. Get at least two VPS in two different providers for best results. | . It is important to understand that this system can easily fail if not implemented in the right way. At least, make absolutely sure that after the transfer is completed you are able to verify the file size (that should match the one of the file you copied) and possibly the SHA1 digest, if you are using a VPS. You also need some kind of independent alert system if the transfer of fresh backups is not working for some reason. ",
    "url": "/management/persistence.html#disaster-recovery",
    
    "relUrl": "/management/persistence.html#disaster-recovery"
  },"195": {
    "doc": "Persistence",
    "title": "Persistence",
    "content": "Persistence refers to the writing of data to durable storage, such as a solid-state disk (SSD). FalkorDB provides a range of persistence options. These include: . | RDB (FalkorDB Database): RDB persistence performs point-in-time snapshots of your dataset at specified intervals. | AOF (Append Only File): AOF persistence logs every write operation received by the server. These operations can then be replayed again at server startup, reconstructing the original dataset. Commands are logged using the same format as the FalkorDB protocol itself. | No persistence: You can disable persistence completely. This is sometimes used when caching. | RDB + AOF: You can also combine both AOF and RDB in the same instance. | . To learn more about how to evaluate your FalkorDB persistence strategy, read on. ",
    "url": "/management/persistence.html",
    
    "relUrl": "/management/persistence.html"
  },"196": {
    "doc": "Procedures",
    "title": "Procedures",
    "content": "Procedures are invoked using the syntax: . GRAPH.QUERY social \"CALL db.labels()\" . Or the variant: . GRAPH.QUERY social \"CALL db.labels() YIELD label\" . YIELD modifiers are only required if explicitly specified; by default the value in the ‘Yields’ column will be emitted automatically. | Procedure | Arguments | Yields | Description | . | db.labels | none | label | Yields all node labels in the graph. | . | db.relationshipTypes | none | relationshipType | Yields all relationship types in the graph. | . | db.propertyKeys | none | propertyKey | Yields all property keys in the graph. | . | db.indexes | none | type, label, properties, language, stopwords, entitytype, info | Yield all indexes in the graph, denoting whether they are exact-match or full-text and which label and properties each covers and whether they are indexing node or relationship attributes. | . | db.constraints | none | type, label, properties, entitytype, status | Yield all constraints in the graph, denoting constraint type (UNIQIE/MANDATORY), which label/relationship-type and properties each enforces. | . | db.idx.fulltext.createNodeIndex | label, property [, property …] | none | Builds a full-text searchable index on a label and the 1 or more specified properties. | . | db.idx.fulltext.drop | label | none | Deletes the full-text index associated with the given label. | . | db.idx.fulltext.queryNodes | label, string | node, score | Retrieve all nodes that contain the specified string in the full-text indexes on the given label. | . | algo.pageRank | label, relationship-type | node, score | Runs the pagerank algorithm over nodes of given label, considering only edges of given relationship type. | . | algo.BFS | source-node, max-level, relationship-type | nodes, edges | Performs BFS to find all nodes connected to the source. A max level of 0 indicates unlimited and a non-NULL relationship-type defines the relationship type that may be traversed. | . | dbms.procedures() | none | name, mode | List all procedures in the DBMS, yields for every procedure its name and mode (read/write). | . ",
    "url": "/cypher/procedures.html",
    
    "relUrl": "/cypher/procedures.html"
  },"197": {
    "doc": "RedisGraph to FalkorDB",
    "title": "FalkorDB is compatible with RedisGraph RDB files.",
    "content": "For the migration, execute the following steps: . | Get the latest RDB file from your RedisGraph instance. Ensure you call SAVE or BGSAVE to capture the latest data snapshot. | Load the RDB file into FalkorDB. When using the FalkorDB Docker image, use the following command: . docker run -it -p 6379:6379 -v $(pwd):/data -e REDIS_ARGS=\"--dir /data --dbfilename dump.rdb\" falkordb/falkordb . Make sure to place the RDB file in the directory mapped to the Docker volume. For FalkorDB Cloud, follow the cloud provider’s instructions for uploading and restoring from an RDB file. | . ",
    "url": "/redisgraph-to-falkordb.html#falkordb-is-compatible-with-redisgraph-rdb-files",
    
    "relUrl": "/redisgraph-to-falkordb.html#falkordb-is-compatible-with-redisgraph-rdb-files"
  },"198": {
    "doc": "RedisGraph to FalkorDB",
    "title": "Additional Tips:",
    "content": ". | Verify the integrity of the RDB file before and after transfer. | Consider downtime and data consistency during the migration process. | Test the migration process in a staging environment before applying it to production. | . ",
    "url": "/redisgraph-to-falkordb.html#additional-tips",
    
    "relUrl": "/redisgraph-to-falkordb.html#additional-tips"
  },"199": {
    "doc": "RedisGraph to FalkorDB",
    "title": "RedisGraph to FalkorDB",
    "content": " ",
    "url": "/redisgraph-to-falkordb.html",
    
    "relUrl": "/redisgraph-to-falkordb.html"
  },"200": {
    "doc": "Replication",
    "title": "Configuring FalkorDB Docker for Replication",
    "content": "FalkorDB supports advanced configurations to enable replication, ensuring that your data is available and synchronized across multiple instances. This guide will walk you through setting up FalkorDB in Docker with replication enabled, providing high availability and data redundancy. ",
    "url": "/operations/replication.html#configuring-falkordb-docker-for-replication",
    
    "relUrl": "/operations/replication.html#configuring-falkordb-docker-for-replication"
  },"201": {
    "doc": "Replication",
    "title": "Prerequisites",
    "content": "Before you begin, ensure you have the following: . | Docker installed on your machine. | A working FalkorDB Docker image. You can pull it from Docker Hub. | Basic knowledge of Docker commands and configurations. | . ",
    "url": "/operations/replication.html#prerequisites",
    
    "relUrl": "/operations/replication.html#prerequisites"
  },"202": {
    "doc": "Replication",
    "title": "Step 1: Configuring Replication",
    "content": "Replication ensures that your data is available across multiple FalkorDB instances. You can configure one instance as the master and others as replicas. For that to work with Docker, we need to first set up a network. 1.1 Creating a Network . First, create a Docker network to allow communication between the FalkorDB nodes. docker network create falkordb-network . 1.1 Setting up the Master Instance . Start the master FalkorDB instance: . docker run -d \\ --name falkordb-master \\ -v falkordb_data:/data \\ -p 6379:6379 \\ --network falkordb-network \\ falkordb/falkordb . This instance will be created in the Standalone mode, as master. 1.2 Setting up the Replica Instance . Next, start the replica instance: . docker run -d \\ --name falkordb-replica1 \\ -p 6380:6379 \\ --network falkordb-network \\ falkordb/falkordb . 1.3 Configuring Replication . Connect to the replica instance and configure it to replicate data from the master: . docker exec -it falkordb-replica1 /bin/bash redis-cli replicaof falkordb-master 6379 . This command tells the replica to replicate data from the master instance. ",
    "url": "/operations/replication.html#step-1-configuring-replication",
    
    "relUrl": "/operations/replication.html#step-1-configuring-replication"
  },"203": {
    "doc": "Replication",
    "title": "Step 2: Verifying the Setup",
    "content": "To verify that your setup is working correctly: . | Replication Check: Insert some data into the master instance and check if it is available in the replica. | . # Connect to the master docker exec -it falkordb-master /bin/bash redis-cli graph.query mygraph \"CREATE (:Database {name:'falkordb'})\" exit # Connect to the replica docker exec -it falkordb-replica1 /bin/bash redis-cli graph.ro_query mygraph \"MATCH (n) return n\" # Output should be: # 1) 1) \"n\" # 2) 1) 1) 1) 1) \"id\" # 2) (integer) 0 # 2) 1) \"labels\" # 2) 1) \"Database\" # 3) 1) \"properties\" # 2) 1) 1) \"name\" # 2) \"falkordb\" # 3) 1) \"Cached execution: 1\" # 2) \"Query internal execution time: 0.122645 milliseconds\" . ",
    "url": "/operations/replication.html#step-2-verifying-the-setup",
    
    "relUrl": "/operations/replication.html#step-2-verifying-the-setup"
  },"204": {
    "doc": "Replication",
    "title": "Conclusion",
    "content": "With replication configured, FalkorDB is now set up for high availability and data redundancy, ensuring that your data is synchronized across multiple instances. This setup provides a robust and fault-tolerant environment for your applications. If you’re interested in learning more about clustering and scaling out, be sure to check out the Cluster chapter in the documentation. ",
    "url": "/operations/replication.html#conclusion",
    
    "relUrl": "/operations/replication.html#conclusion"
  },"205": {
    "doc": "Replication",
    "title": "Replication",
    "content": " ",
    "url": "/operations/replication.html",
    
    "relUrl": "/operations/replication.html"
  },"206": {
    "doc": "Result Set Structure",
    "title": "Result Set Structure",
    "content": "This document describes the format FalkorDB uses to print data when accessed through the redis-cli utility. The language-specific clients retrieve data in a more succinct format, and provide their own functionality for printing result sets. ",
    "url": "/design/result_structure.html",
    
    "relUrl": "/design/result_structure.html"
  },"207": {
    "doc": "Result Set Structure",
    "title": "Top-level members",
    "content": "Queries that return data emit an array with 3 top-level members: . | The header describing the returned records. This is an array which corresponds precisely in order and naming to the RETURN clause of the query. | A nested array containing the actual data returned by the query. | An array of metadata related to the query execution. This includes query runtime as well as data changes, such as the number of entities created, deleted, or modified by the query. | . ",
    "url": "/design/result_structure.html#top-level-members",
    
    "relUrl": "/design/result_structure.html#top-level-members"
  },"208": {
    "doc": "Result Set Structure",
    "title": "Result Set data types",
    "content": "A column in the result set can be populated with graph entities (nodes or relations) or scalar values. Scalars . FalkorDB replies are formatted using the RESP protocol. The current RESP iteration provides fewer data types than FalkorDB supports internally, so displayed results are mapped as follows: . | FalkorDB type | Display format | . | Integer | Integer | . | NULL | NULL (nil) | . | String | String | . | Boolean | String (“true”/”false”) | . | Double | String (15-digit precision) | . Graph Entities . When full entities are specified in a RETURN clause, all data relevant to each entity value is emitted within a nested array. Key-value pairs in the data, such as the combination of a property name and its corresponding value, are represented as 2-arrays. Internal IDs are returned with nodes and relations, but these IDs are not immutable. After entities have been deleted, higher IDs may be migrated to the vacated lower IDs. Nodes . The node representation contains 3 top-level elements: . | The node’s internal ID. | Any labels associated with the node. | The key-value pairs of all properties the node possesses. | . [ [“id”, ID (integer)] [“labels”, [label (string) X label count] ] [properties”, [ [prop_key (string), prop_val (scalar)] X property count] ] ] . Relations . The relation representation contains 5 top-level elements: . | The relation’s internal ID. | The type associated with the relation. | The source node’s internal ID. | The destination node’s internal ID. | The key-value pairs of all properties the relation possesses. | . [ [“id”, ID (integer)] [“type”, type (string)] [“src_node”, source node ID (integer)] [“dest_node”, destination node ID (integer)] [properties”, [ [prop_key (string), prop_val (scalar)] X property count] ] ] . Collections . Arrays . When array values are specified in a RETURN clause, the representation in the response is the array string representation. This is done solely for better readability of the response. The string representation of an array which contains graph entities, will print only their ID. A node string representation is round braces around its ID, and edge string representation is brackets around the edge ID. Paths . Returned path value is the string representation of an array with the path’s nodes and edges, interleaved. ",
    "url": "/design/result_structure.html#result-set-data-types",
    
    "relUrl": "/design/result_structure.html#result-set-data-types"
  },"209": {
    "doc": "Result Set Structure",
    "title": "Example",
    "content": "Given the graph created by the command: . CREATE (:person {name:'Pam', age:27})-[:works {since: 2010}]-&gt;(:employer {name:'Dunder Mifflin'})\"\" . We can run a query that returns a node, a relation, and a scalar value. \"MATCH (n1)-[r]-&gt;(n2) RETURN n1, r, n2.name\" 1) 1) \"n1\" 2) \"r\" 3) \"n2.name\" 2) 1) 1) 1) 1) \"id\" 2) (integer) 0 2) 1) \"labels\" 2) 1) \"person\" 3) 1) \"properties\" 2) 1) 1) \"age\" 2) (integer) 27 2) 1) \"name\" 2) \"Pam\" 2) 1) 1) \"id\" 2) (integer) 0 2) 1) \"type\" 2) \"works\" 3) 1) \"src_node\" 2) (integer) 0 4) 1) \"dest_node\" 2) (integer) 1 5) 1) \"properties\" 2) 1) 1) \"since\" 2) (integer) 2010 3) \"Dunder Mifflin\" 3) 1) \"Query internal execution time: 1.858986 milliseconds\" . ",
    "url": "/design/result_structure.html#example",
    
    "relUrl": "/design/result_structure.html#example"
  },"210": {
    "doc": "RETURN",
    "title": "RETURN",
    "content": "In its simple form, Return defines which properties the returned result-set will contain. Its structure is a list of alias.property separated by commas. For convenience, it’s possible to specify the alias only when you’re interested in every attribute an entity possesses, and don’t want to specify each attribute individually. For example: . RETURN movie.title, actor . Use the DISTINCT keyword to remove duplications within the result-set: . RETURN DISTINCT friend_of_friend.name . In the above example, suppose we have two friends, Joe and Miesha, and both know Dominick. DISTINCT will make sure Dominick will only appear once in the final result set. Return can also be used to aggregate data, similar to group by in SQL. Once an aggregation function is added to the return list, all other “none” aggregated values are considered as group keys, for example: . RETURN movie.title, MAX(actor.age), MIN(actor.age) . Here we group data by movie title and for each movie, and we find its youngest and oldest actor age. ",
    "url": "/cypher/return.html",
    
    "relUrl": "/cypher/return.html"
  },"211": {
    "doc": "RETURN",
    "title": "Aggregations",
    "content": "Supported aggregation functions include: . | avg | collect | count | max | min | percentileCont | percentileDisc | stDev | sum | . ",
    "url": "/cypher/return.html#aggregations",
    
    "relUrl": "/cypher/return.html#aggregations"
  },"212": {
    "doc": "SET",
    "title": "SET",
    "content": "SET is used to create or update properties on nodes and relationships. To set a property on a node, use SET. GRAPH.QUERY DEMO_GRAPH \"MATCH (n { name: 'Jim' }) SET n.name = 'Bob'\" . If you want to set multiple properties in one go, simply separate them with a comma to set multiple properties using a single SET clause. GRAPH.QUERY DEMO_GRAPH \"MATCH (n { name: 'Jim', age:32 }) SET n.age = 33, n.name = 'Bob'\" . The same can be accomplished by setting the graph entity variable to a map: . GRAPH.QUERY DEMO_GRAPH \"MATCH (n { name: 'Jim', age:32 }) SET n = {age: 33, name: 'Bob'}\" . Using = in this way replaces all of the entity’s previous properties, while += will only set the properties it explicitly mentions. In the same way, the full property set of a graph entity can be assigned or merged: . GRAPH.QUERY DEMO_GRAPH \"MATCH (jim {name: 'Jim'}), (pam {name: 'Pam'}) SET jim = pam\" . After executing this query, the jim node will have the same property set as the pam node. To remove a node’s property, simply set property value to NULL. GRAPH.QUERY DEMO_GRAPH \"MATCH (n { name: 'Jim' }) SET n.name = NULL\" . ",
    "url": "/cypher/set.html",
    
    "relUrl": "/cypher/set.html"
  },"213": {
    "doc": "SKIP",
    "title": "SKIP",
    "content": "The optional skip clause allows a specified number of records to be omitted from the result set. SKIP &lt;number of records to skip&gt; . This can be useful when processing results in batches. A query that would examine the second 100-element batch of nodes with the label Person, for example, would be: . GRAPH.QUERY DEMO_GRAPH \"MATCH (p:Person) RETURN p ORDER BY p.name SKIP 100 LIMIT 100\" . ",
    "url": "/cypher/skip.html",
    
    "relUrl": "/cypher/skip.html"
  },"214": {
    "doc": "UNION",
    "title": "UNION",
    "content": "The UNION clause is used to combine the result of multiple queries. UNION combines the results of two or more queries into a single result set that includes all the rows that belong to all queries in the union. The number and the names of the columns must be identical in all queries combined by using UNION. To keep all the result rows, use UNION ALL. Using just UNION will combine and remove duplicates from the result set. GRAPH.QUERY DEMO_GRAPH \"MATCH (n:Actor) RETURN n.name AS name UNION ALL MATCH (n:Movie) RETURN n.title AS name\" . ",
    "url": "/cypher/union.html",
    
    "relUrl": "/cypher/union.html"
  },"215": {
    "doc": "UNWIND",
    "title": "UNWIND",
    "content": "The UNWIND clause breaks down a given list into a sequence of records; each contains a single element in the list. The order of the records preserves the original list order. GRAPH.QUERY DEMO_GRAPH \"CREATE (p {array:[1,2,3]})\" . GRAPH.QUERY DEMO_GRAPH \"MATCH (p) UNWIND p.array AS y RETURN y\" . ",
    "url": "/cypher/unwind.html",
    
    "relUrl": "/cypher/unwind.html"
  },"216": {
    "doc": "WHERE",
    "title": "WHERE",
    "content": "This clause is not mandatory, but if you want to filter results, you can specify your predicates here. Supported operations: . | = | &lt;&gt; | &lt; | &lt;= | &gt; | &gt;= | CONTAINS | ENDS WITH | IN | STARTS WITH | . Predicates can be combined using AND / OR / NOT. Be sure to wrap predicates within parentheses to control precedence. Examples: . WHERE (actor.name = \"john doe\" OR movie.rating &gt; 8.8) AND movie.votes &lt;= 250) . WHERE actor.age &gt;= director.age AND actor.age &gt; 32 . It is also possible to specify equality predicates within nodes using the curly braces as such: . (:President {name:\"Jed Bartlett\"})-[:WON]-&gt;(:State) . Here we’ve required that the president node’s name will have the value “Jed Bartlett”. There’s no difference between inline predicates and predicates specified within the WHERE clause. It is also possible to filter on graph patterns. The following queries, which return all presidents and the states they won in, produce the same results: . MATCH (p:President), (s:State) WHERE (p)-[:WON]-&gt;(s) RETURN p, s . and . MATCH (p:President)-[:WON]-&gt;(s:State) RETURN p, s . Pattern predicates can be also negated and combined with the logical operators AND, OR, and NOT. The following query returns all the presidents that did not win in the states where they were governors: . MATCH (p:President), (s:State) WHERE NOT (p)-[:WON]-&gt;(s) AND (p)-&gt;[:governor]-&gt;(s) RETURN p, s . Nodes can also be filtered by label: . MATCH (n)-[:R]-&gt;() WHERE n:L1 OR n:L2 RETURN n . When possible, it is preferable to specify the label in the node pattern of the MATCH clause. ",
    "url": "/cypher/where.html",
    
    "relUrl": "/cypher/where.html"
  },"217": {
    "doc": "WITH",
    "title": "WITH",
    "content": "The WITH clause allows parts of queries to be independently executed and have their results handled uniquely. This allows for more flexible query composition as well as data manipulations that would otherwise not be possible in a single query. If, for example, we wanted to find all children in our graph who are above the average age of all people: . GRAPH.QUERY DEMO_GRAPH \"MATCH (p:Person) WITH AVG(p.age) AS average_age MATCH (:Person)-[:PARENT_OF]-&gt;(child:Person) WHERE child.age &gt; average_age return child . This also allows us to use modifiers like DISTINCT, SKIP, LIMIT, and ORDER that otherwise require RETURN clauses. GRAPH.QUERY DEMO_GRAPH \"MATCH (u:User) WITH u AS nonrecent ORDER BY u.lastVisit LIMIT 3 SET nonrecent.should_contact = true\" . ",
    "url": "/cypher/with.html",
    
    "relUrl": "/cypher/with.html"
  }
}
